{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1lPfpKyINT7"
   },
   "source": [
    "# Ablation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPITQXTZKCHU"
   },
   "source": [
    "## Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 37897,
     "status": "ok",
     "timestamp": 1749393236794,
     "user": {
      "displayName": "曾聪聪",
      "userId": "09963294123882050219"
     },
     "user_tz": -480
    },
    "id": "Bd-O0P3VJ97X",
    "outputId": "4a9dc141-ddec-4ccf-cbab-0d85ce12045d"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "import pandas as pd\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain.vectorstores import FAISS\n",
    "from typing import List, Dict\n",
    "from openai import OpenAI      # pip install openai>=1.14\n",
    "import openai\n",
    "from langchain.agents import Tool, initialize_agent, AgentType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWc5zr1lKJv1"
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUV5FZV1KMpc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "user_api_key = \"YOUR_OPENAI_API_KEY\"  # Replace with your OpenAI API key\n",
    "\n",
    "def LoadFiles():\n",
    "  v1 = pd.read_csv('Test_Dataset/Air_NRM/v1.csv')\n",
    "  v2 = pd.read_csv('Test_Dataset/Air_NRM/v2.csv')\n",
    "  demand = pd.read_csv('Test_Dataset/Air_NRM/od_demand.csv')\n",
    "  flight = pd.read_csv('Test_Dataset/Air_NRM/flight.csv')\n",
    "  return v1,v2,demand,flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classification_Agent(file_path=\"Large_Scale_Or_Files/RefData.csv\"):\n",
    "    llm1 = ChatOpenAI(\n",
    "        temperature=0.0, model_name=\"gpt-4.1\", openai_api_key=user_api_key\n",
    "    )\n",
    "\n",
    "    # Load and process the data\n",
    "    loader1 = CSVLoader(file_path=\"Large_Scale_Or_Files/RefData.csv\", encoding=\"utf-8\")\n",
    "    refdata = loader1.load()\n",
    "\n",
    "    # Each line is a document\n",
    "    refdocuments = refdata\n",
    "\n",
    "    # Create embeddings and vector store\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors1 = FAISS.from_documents(refdocuments, embeddings)\n",
    "\n",
    "    # Create a retriever\n",
    "    retriever1 = vectors1.as_retriever(search_kwargs={'k': 5})\n",
    "\n",
    "    # Create the RetrievalQA chain\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm1,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever1,\n",
    "        return_source_documents=True,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Create a tool using the RetrievalQA chain\n",
    "    qa_tool1 = Tool(\n",
    "        name=\"FileQA\",\n",
    "        func=qa_chain.invoke,\n",
    "        description=(\n",
    "            \"Use this tool to answer questions about the problem type of the text. \"\n",
    "            \"Provide the question as input, and the tool will retrieve the relevant information from the file and use it to answer the question.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Define few-shot examples as a string\n",
    "    few_shot_examples = \"\"\"\n",
    "\n",
    "    Question: What is the problem type in operation of the text? Please give the answer directly. Text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1,w_2,w_3.There is an independent demand stream for each of the products. The objective of the company is to decide which demands to be fufilled over a ﬁnite sales horizon [0,10] to maximize the total expected revenue from ﬁxed initial inventories. The on-hand inventories for the three items are c_1,c_2,c_3 respectively. During the sales horizon, replenishment is not allowed and there is no any in-transit inventories. Customers who want to purchase P1,P2,P3 arrive at each period accoring to a Poisson process with a_1,a_2,a_3 the arrival rates respectively. Decision variables y_1,y_2,y_3 correspond to the number of requests that the firm plans to fulfill for product 1,2,3. These variables are all positive integers.\n",
    "\n",
    "    Thought: I need to determine the problem type of the text. I'll use the FileQA tool to retrieve the relevant information.\n",
    "\n",
    "    Action: FileQA\n",
    "\n",
    "    Action Input: \"What is the problem type in operation of the text? text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1, w_2, w_3. ...\"\n",
    "\n",
    "    Observation: The problem type of the text is Network Revenue Management.\n",
    "\n",
    "    Final Answer: Network Revenue Management.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the prefix and suffix for the agent's prompt\n",
    "    prefix = f\"\"\"You are a helpful assistant that can answer questions about operation problems.\n",
    "\n",
    "    Use the following examples as a guide. Always use the FileQA tool when you need to retrieve information from the file:\n",
    "\n",
    "\n",
    "    {few_shot_examples}\n",
    "\n",
    "    When you need to find information from the file, use the provided tools. And answer the question by given the answer directly. For example,\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    suffix = \"\"\"\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    Question: {input}\n",
    "    {agent_scratchpad}\"\"\"\n",
    "\n",
    "    agent_pc = initialize_agent(\n",
    "        tools=[qa_tool1],\n",
    "        llm=llm1,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        agent_kwargs={\n",
    "            \"prefix\": prefix.format(few_shot_examples=few_shot_examples),\n",
    "            \"suffix\": suffix,\n",
    "        },\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True,  # Enable error handling\n",
    "    )\n",
    "\n",
    "    openai.api_request_timeout = 60 \n",
    "    return agent_pc\n",
    "\n",
    "def Problemtype(query):\n",
    "    agent_pc = Classification_Agent(file_path=\"Large_Scale_Or_Files/RefData.csv\")\n",
    "    category_original=agent_pc.invoke(f\"What is the problem type in operation of the text? text:{query}\")\n",
    "    type_output = category_original['output']\n",
    "    return type_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7MyCmWnIWu3"
   },
   "source": [
    "## Fewshot-Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4dzi_P6INoF"
   },
   "outputs": [],
   "source": [
    "file_path_list = [\"Test_Dataset/Air_NRM/flight.csv\", \"Test_Dataset/Air_NRM/od_demand.csv\", \"Test_Dataset/Air_NRM/v1.csv\", \"Test_Dataset/Air_NRM/v2.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────\n",
    "# 1)  Upload all CSVs once and cache their IDs\n",
    "# ──────────────────────────────────────────────\n",
    "client = OpenAI(api_key=user_api_key)\n",
    "\n",
    "FILE_MAP: Dict[str, str] = {\n",
    "    \"flight\":  \"Test_Dataset/Air_NRM/flight.csv\",\n",
    "    \"demand\":  \"Test_Dataset/Air_NRM/od_demand.csv\",\n",
    "    \"v1\":      \"Test_Dataset/Air_NRM/v1.csv\",\n",
    "    \"v2\":      \"Test_Dataset/Air_NRM/v2.csv\",\n",
    "}\n",
    "\n",
    "def upload_files(paths: List[str]) -> List[str]:\n",
    "    \"\"\"Return a list of file-ids after uploading each path to OpenAI.\"\"\"\n",
    "    ids: List[str] = []\n",
    "    for p in paths:\n",
    "        with open(p, \"rb\") as f:\n",
    "            ids.append(client.files.create(file=f, purpose=\"assistants\").id)\n",
    "    return ids\n",
    "\n",
    "FILE_IDS: Dict[str, str] = {\n",
    "    name: upload_files([path])[0] for name, path in FILE_MAP.items()\n",
    "}\n",
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 2)  Minimal tools – they just hand back IDs\n",
    "# ──────────────────────────────────────────────\n",
    "def _fmt(k: str) -> str:\n",
    "  return f\"{k}_file_id={FILE_IDS[k]}\"\n",
    "\n",
    "csv_tool_flight = Tool(\n",
    "    name=\"GetFlightFile\",\n",
    "    func=lambda _: _fmt(\"flight\"),\n",
    "    description=\"Returns the file-id for flight.csv so the model can load it.\",\n",
    ")\n",
    "\n",
    "csv_tool_demand = Tool(\n",
    "    name=\"GetDemandFile\",\n",
    "    func=lambda _: _fmt(\"demand\"),\n",
    "    description=\"Returns the file-id for od_demand.csv so the model can load it.\",\n",
    ")\n",
    "\n",
    "csv_tool_v1v2 = Tool(\n",
    "    name=\"GetV1V2Files\",\n",
    "    func=lambda _: f\"v1_file_id={FILE_IDS['v1']}, v2_file_id={FILE_IDS['v2']}\",\n",
    "    description=\"Returns the file-ids for v1.csv and v2.csv.\",\n",
    ")\n",
    "\n",
    "TOOLS = [csv_tool_flight, csv_tool_demand, csv_tool_v1v2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ──────────────────────────────────────────────\n",
    "# 3)  Few-shot prompt pieces\n",
    "# ──────────────────────────────────────────────\n",
    "\n",
    "example_data_description_NP = \"avg_price={{'(AB,11:20,f)': '1140.3', '(AB,11:20,l)': '429.26'}} \\n value_list ={{'(CA,7:40,f)': 0.228917, '(CA,7:40,l)': 0.54522, '(CB,7:40,f)': 0, '(CB,7:40,l)': 0, '(BA,9:05,f)': 1.043622, '(BA,9:05,l)': 0.0625, '(BC,9:05,f)': 0, '(BC,9:05,l)': 0, '(CB,10:45,f)': 0, '(CB,10:45,l)': 0, '(AB,11:20,f)': 0.342687, '(AB,11:20,l)': 0.24677, '(BC,11:20,f)': 0, '(BC,11:20,l)': 0}}\\n ratio_list={{'(CA,7:40,f)': 1.0, '(CA,7:40,l)': 0.97, '(CB,7:40,f)': 0, '(CB,7:40,l)': 0, '(BA,9:05,f)': 1.0, '(BA,9:05,l)': 0.29, '(BC,9:05,f)': 0, '(BC,9:05,l)': 0, '(CB,10:45,f)': 0, '(CB,10:45,l)': 0, '(AB,11:20,f)': 0.67, '(AB,11:20,l)': 1.0, '(BC,11:20,f)': 0, '(BC,11:20,l)': 0}}\\nvalue_0_list={{'CA': 1, 'CB': 0, 'BA': 1, 'BC': 0, 'AB': 1}}\\n ratio_0_list={{'CA': 1.4, 'CB': 0, 'BA': 1.53, 'BC': 0, 'AB': 1.41}}\\navg_pax={{'CA': '4807.43', 'CB': '4807.43', 'BC': '38965.86', 'AB': '38965.86', 'BA': '33210.71'}}\\ncapacity_consum=1.2\\noption_num=None\\nsigma_inflow_A=['(CA,7:40)', '(BA,9:05)']\\nsigma_outflow_A=['(AB,11:20)']\\nsigma_inflow_B=['(CB,7:40)', '(CB,10:45)', '(AB,11:20)']\\nsigma_outflow_B=['(BA,9:05)', '(BC,9:05)', '(BC,11:20)']\\nsigma_inflow_C=['(BC,9:05)', '(BC,11:20)']\\nsigma_outflow_C=['(CA,7:40)', '(CB,7:40)', '(CB,10:45)']\\nM = 10000000\\nflight_capacity=187\\n\"\n",
    "\n",
    "fewshot_only_NP = f\"\"\"\n",
    "Question: Based on flight ticket options provided in file \"\"./Test_Dataset/Air_NRM/information.csv\"\", along with their average passengers (Avg Pax), average prices (Avg Price), and capacity coefficients (Flex Cpy Coef), considering that each Eco_flex ticket consumes 2 units of flight capacity and each Eco_lite ticket consumes 1 unit of capacity, while enforcing flow conservation constraints at each airport for long-term planning model, develop a Sales-Based Linear Programming (SBLP) model. \n",
    "\n",
    "The goal of this model is to recommend the optimal 3 flights that maximize total ticket sale revenue, specifically among flights where the origin-destination pairs are: \n",
    "OD = ('A', 'B') or OD = ('A', 'C') or OD = ('B', 'A') or OD = ('B', 'C') or ('C', 'A') or ('C', 'B') in a departure period (7am-12:00am) in which the optional flights are:\n",
    "[(OD = ('C', 'A') AND Departure Time='7:40'),\n",
    "(OD = ('C', 'B') AND Departure Time='7:40'),\n",
    "(OD = ('B', 'A') AND Departure Time='9:05'),\n",
    "(OD = ('B', 'C') AND Departure Time='9:05'),\n",
    "(OD = ('C', 'B') AND Departure Time='10:45'),\n",
    "(OD = ('A', 'B') AND Departure Time='11:20'),\n",
    "(OD = ('B', 'C') AND Departure Time='11:20')]\n",
    "\n",
    "Thought: First, I have known the capacity_consum = 2, option_num = 3, sigma_inflow_A=['(CA,7:40)', '(BA,9:05)'], sigma_outflow_A=['(AB,11:20)'], sigma_inflow_B=['(CB,7:40)', '(CB,10:45)', '(AB,11:20)'], sigma_outflow_B=['(BA,9:05)', '(BC,9:05)', '(BC,11:20)']\\nsigma_inflow_C=['(BC,9:05)', '(BC,11:20)'], sigma_outflow_C=['(CA,7:40)', '(CB,7:40)', '(CB,10:45)'], M = 10000000, flight_capacity=187. Then, I need to have access to flight.csv for the model.\n",
    "Action:csv_tool_flight\n",
    "Action Input: Returns the file-id for flight.csv so the model can load it.\n",
    "Observation:\n",
    "flight_file_id=file-5fy2hgfr7YWZJ6AzmifHhj\n",
    "Thought: With the file, I can get the flight data for the flight options and organize them in dicts.\n",
    "Observation:\n",
    "avg_price={{'(AB,11:20,f)': '1140.3', '(AB,11:20,l)': '429.26'}}\n",
    "Thought: Now I need to have access to od_demand.csv for the model.\n",
    "Action:csv_tool_demand\n",
    "Action Input: Returns the file-id for od_demand.csv so the model can load it.\n",
    "Observation:\n",
    "demand_file_id=file-8dY7Ug4zdwi5xvC3dfbLRy\n",
    "Thought: With the file, I can get the demand data for the flight options and organize them in dicts.\n",
    "Observation:\n",
    "avg_pax={{'CA': '4807.43', 'CB': '4807.43', 'BC': '38965.86', 'AB': '38965.86', 'BA': '33210.71'}}\n",
    "Thought: Now I need to have access to v1.csv and v2.csv for the model.\n",
    "Action:csv_tool_v1v2\n",
    "Action Input: Returns the file-ids for v1.csv and v2.csv.\n",
    "Observation:\n",
    "v1_file_id=file-XvUswUf66ri7i1g561z43J, v2_file_id=file-26WPsKutxJnXPp7uMK8uWC\n",
    "Thought: With the file, I can get the attraction values and shadow attraction ratios for the flight options and organize them in dicts.\n",
    "\n",
    "Obseravtion:\n",
    "value_list ={{'(CA,7:40,f)': 0.228917, '(CA,7:40,l)': 0.54522, '(CB,7:40,f)': 0, '(CB,7:40,l)': 0, '(BA,9:05,f)': 1.043622, '(BA,9:05,l)': 0.0625, '(BC,9:05,f)': 0, '(BC,9:05,l)': 0, '(CB,10:45,f)': 0, '(CB,10:45,l)': 0, '(AB,11:20,f)': 0.342687, '(AB,11:20,l)': 0.24677, '(BC,11:20,f)': 0, '(BC,11:20,l)': 0}}\n",
    "\n",
    "ratio_list={{'(CA,7:40,f)': 1.0, '(CA,7:40,l)': 0.97, '(CB,7:40,f)': 0, '(CB,7:40,l)': 0, '(BA,9:05,f)': 1.0, '(BA,9:05,l)': 0.29, '(BC,9:05,f)': 0, '(BC,9:05,l)': 0, '(CB,10:45,f)': 0, '(CB,10:45,l)': 0, '(AB,11:20,f)': 0.67, '(AB,11:20,l)': 1.0, '(BC,11:20,f)': 0, '(BC,11:20,l)': 0}}\n",
    "\n",
    "value_0_list={{'CA': 1, 'CB': 0, 'BA': 1, 'BC': 0, 'AB': 1}}\n",
    "\n",
    "ratio_0_list={{'CA': 1.4, 'CB': 0, 'BA': 1.53, 'BC': 0, 'AB': 1.41}}\n",
    "\n",
    "Thought: Now I know the final answer.\n",
    "Final Answer:\n",
    "### Objective Function\n",
    "\n",
    "\\[\n",
    "\\max \\quad \\sum_(l,k,j) avg\\_price[(l,k,j)] \\cdot x[(l,k,j)]\n",
    "\\]\n",
    "\n",
    "### Constraints\n",
    "\n",
    "#### 1. Capacity Constraints\n",
    "\n",
    "For each flight (OD pair \\( l \\), departure time \\( k \\)):\n",
    "\n",
    "\\[\n",
    "capacity\\_consum \\cdot x[(l,k,f)] + x[(l,k,l)] \\leq flight\\_capacity\n",
    "\\]\n",
    "\n",
    "#### 2. Balance Constraints\n",
    "\n",
    "For each OD pair \\( l \\):\n",
    "\n",
    "\\[\n",
    "ratio\\_0\\_list[l] \\cdot x_o[l] + \\sum_k \\sum_j ratio\\_list[(l,k,j)] \\cdot x[(l,k,j)] = avg\\_pax[l]\n",
    "\\]\n",
    "\n",
    "#### 3. Scale Constraints\n",
    "\n",
    "For each ticket option \\((l,k,j)\\):\n",
    "\n",
    "\\[\n",
    "x[(l,k,j)]/value\\_list[(l,k,j)] - x_o[l]/value\\_0\\_list[l] \\leq 0\n",
    "\\]\n",
    "\n",
    "#### 4. Nonnegativity Constraints\n",
    "\n",
    "\\[\n",
    "x[(l,k,j)] \\geq 0, \\quad x_o[l] \\geq 0\n",
    "\\]\n",
    "- x = avg_price.keys()\n",
    "- x_o = avg_pax.keys()\n",
    "\n",
    "### Retrieved Information\n",
    "{example_data_description_NP}\n",
    "\n",
    "### Generated Code\n",
    "\n",
    "```python\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "{example_data_description_NP}\n",
    "\n",
    "model = gp.Model(\"sales_based_lp\")\n",
    "x = model.addVars(avg_price.keys(), lb=0, name=\"x\")\n",
    "x_o = model.addVars(value_0_list.keys(), lb=0, name=\"x_o\")\n",
    "\n",
    "model.setObjective(gp.quicksum(avg_price[key] * x[key] for key in avg_price.keys()), GRB.MAXIMIZE)\n",
    "\n",
    "paired_keys = []\n",
    "for i in range(0, len(avg_price.keys()), 2):\n",
    "    if i + 1 < len(avg_price.keys()):\n",
    "        names = list(avg_price.keys())\n",
    "        model.addConstr(\n",
    "            capacity_consum* x[names[i]] + x[names[i + 1]] <= 187,\n",
    "            name=f\"capacity_constraint\"\n",
    "        )\n",
    "\n",
    "for l in ratio_0_list.keys():\n",
    "    temp = 0\n",
    "    for key in ratio_list.keys():\n",
    "        if l in key:\n",
    "            temp += ratio_list[key] * x[key]\n",
    "    model.addConstr(\n",
    "        float(ratio_0_list[l]) * x_o[l] + temp == float(avg_pax[l])\n",
    "    )\n",
    "\n",
    "for i in value_list.keys():\n",
    "    for l in ratio_0_list.keys():\n",
    "        if l in i:\n",
    "            model.addConstr(\n",
    "                value_0_list[l]  * x[i] <= value_list[i] * x_o[l]\n",
    "            )\n",
    "\n",
    "model.optimize()\n",
    "\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(\"Optimal solution found:\")\n",
    "    for v in model.getVars():\n",
    "        print(v.varName, v.x)\n",
    "    print(\"Optimal objective value:\", model.objVal)\n",
    "else:\n",
    "    print(\"No optimal solution found.\")\n",
    "\n",
    "Note: Please retrieve all neccessary information from the CSV file to generate the answer. When you generate the answer, please output required parameters in a whole text, including all vectors and matrices.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_data_description_CA = \"avg_price={{'(BA,20:25,f)': '1133.9', '(BA,20:25,l)': '410.31'}} \\n value_list ={{'(BA,12:25,f)': 0.177309, '(BA,12:25,l)': 0.471942, '(CB,14:15,f)': 0, '(CB,14:15,l)': 0, '(BA,20:25,f)': 0.780656, '(BA,20:25,l)': 1.332733}}\\n ratio_list={{'(BA,12:25,f)': 1.0, '(BA,12:25,l)': 0.0, '(CB,14:15,f)': 0, '(CB,14:15,l)': 0, '(BA,20:25,f)': 0.74, '(BA,20:25,l)': 0.97}}\\nvalue_0_list={{'BA': 1, 'CB': 0}}\\n ratio_0_list={{'BA': 1.53, 'CB': 0}}\\navg_pax={{'BA': '33210.71', 'CB': '4807.43'}}\\ncapacity_consum = 1.2\\nflight_capacity = 187 \\n\"\n",
    "\n",
    "fewshot_only_CA = f\"\"\"\n",
    "Question: Based on all flight ticket choices in 'information1_addB_2.csv' with attraction values in v1 and shadow attraction value ratios in v2, develop the SBLP(sales-based linear programming) formulation  with flights (OD = ('B', 'A') AND Departure Time='12:25'), (OD = ('C', 'B') AND Departure Time='14:15'), (OD = ('B', 'A') AND Departure Time='20:25') that maximize the total revenue of flight ticket sales. The SBLP should include decision variables, objective function, balance constraints, scale constraints, nonnegative constraints.\n",
    "\n",
    "Thought: First, I have known the capacity_consum = 1.2, flight_capacity = 187. Then, I need to have access to flight.csv for the model.\n",
    "Action:csv_tool_flight\n",
    "Action Input: Returns the file-id for flight.csv so the model can load it.\n",
    "Observation:\n",
    "flight_file_id=file-5fy2hgfr7YWZJ6AzmifHhj\n",
    "Thought: With the file, I can get the flight data for the flight options and organize them in dicts.\n",
    "Observation:\n",
    "avg_price={{'(BA,20:25,f)': '1133.9', '(BA,20:25,l)': '410.31'}}\n",
    "Thought: Now I need to have access to od_demand.csv for the model.\n",
    "Action:csv_tool_demand\n",
    "Action Input: Returns the file-id for od_demand.csv so the model can load it.\n",
    "Observation:\n",
    "demand_file_id=file-8dY7Ug4zdwi5xvC3dfbLRy\n",
    "Thought: With the file, I can get the demand data for the flight options and organize them in dicts.\n",
    "Observation:\n",
    "avg_pax={{'BA': '33210.71', 'CB': '4807.43'}}\n",
    "Thought: Now I need to have access to v1.csv and v2.csv for the model.\n",
    "Action:csv_tool_v1v2\n",
    "Action Input: Returns the file-ids for v1.csv and v2.csv.\n",
    "Observation:\n",
    "v1_file_id=file-XvUswUf66ri7i1g561z43J, v2_file_id=file-26WPsKutxJnXPp7uMK8uWC\n",
    "Thought: With the file, I can get the attraction values and shadow attraction ratios for the flight options and organize them in dicts.\n",
    "\n",
    "Obseravtion:\n",
    "value_list ={{'(BA,12:25,f)': 0.177309, '(BA,12:25,l)': 0.471942, '(CB,14:15,f)': 0, '(CB,14:15,l)': 0, '(BA,20:25,f)': 0.780656, '(BA,20:25,l)': 1.332733}}\n",
    "ratio_list={{'(BA,12:25,f)': 1.0, '(BA,12:25,l)': 0.0, '(CB,14:15,f)': 0, '(CB,14:15,l)': 0, '(BA,20:25,f)': 0.74, '(BA,20:25,l)': 0.97}}\n",
    "value_0_list={{'BA': 1, 'CB': 0}}\n",
    "ratio_0_list={{'BA': 1.53, 'CB': 0}}\n",
    "\n",
    "\n",
    "Thought: Now I know the final answer.\n",
    "Final Answer:\n",
    "### Objective Function\n",
    "\n",
    "\\[\n",
    "\\max \\quad \\sum_(l,k,j) avg\\_price[(l,k,j)] \\cdot x[(l,k,j)]\n",
    "\\]\n",
    "\n",
    "### Constraints\n",
    "\n",
    "#### 1. Capacity Constraints\n",
    "\n",
    "For each flight (OD pair \\( l \\), departure time \\( k \\)):\n",
    "\n",
    "\\[\n",
    "capacity\\_consum \\cdot x[(l,k,f)] + x[(l,k,l)] \\leq flight\\_capacity\n",
    "\\]\n",
    "\n",
    "#### 2. Balance Constraints\n",
    "\n",
    "For each OD pair \\( l \\):\n",
    "\n",
    "\\[\n",
    "ratio\\_0\\_list[l] \\cdot x_o[l] + \\sum_k \\sum_j ratio\\_list[(l,k,j)] \\cdot x[(l,k,j)] = avg\\_pax[l]\n",
    "\\]\n",
    "\n",
    "#### 3. Scale Constraints\n",
    "\n",
    "For each ticket option \\((l,k,j)\\):\n",
    "\n",
    "\\[\n",
    "x[(l,k,j)]/value\\_list[(l,k,j)] - x_o[l]/value\\_0\\_list[l] \\leq 0\n",
    "\\]\n",
    "\n",
    "#### 4. Nonnegativity Constraints\n",
    "\n",
    "\\[\n",
    "x[(l,k,j)] \\geq 0, \\quad x_o[l] \\geq 0\n",
    "\\]\n",
    "- x = avg_price.keys()\n",
    "- x_o = avg_pax.keys()\n",
    "\n",
    "### Retrieved Information\n",
    "{example_data_description_CA}\n",
    "\n",
    "### Generated Code\n",
    "\n",
    "```python\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "{example_data_description_CA}\n",
    "\n",
    "model = gp.Model(\"sales_based_lp\")\n",
    "x = model.addVars(avg_price.keys(), lb=0, name=\"x\")\n",
    "x_o = model.addVars(value_0_list.keys(), lb=0, name=\"x_o\")\n",
    "\n",
    "model.setObjective(gp.quicksum(avg_price[key] * x[key] for key in avg_price.keys()), GRB.MAXIMIZE)\n",
    "\n",
    "paired_keys = []\n",
    "for i in range(0, len(avg_price.keys()), 2):\n",
    "    if i + 1 < len(avg_price.keys()):\n",
    "        names = list(avg_price.keys())\n",
    "        model.addConstr(\n",
    "            capacity_consum* x[names[i]] + x[names[i + 1]] <= 187,\n",
    "            name=f\"capacity_constraint\"\n",
    "        )\n",
    "\n",
    "for l in ratio_0_list.keys():\n",
    "    temp = 0\n",
    "    for key in ratio_list.keys():\n",
    "        if l in key:\n",
    "            temp += ratio_list[key] * x[key]\n",
    "    model.addConstr(\n",
    "        float(ratio_0_list[l]) * x_o[l] + temp == float(avg_pax[l])\n",
    "    )\n",
    "\n",
    "for i in value_list.keys():\n",
    "    for l in ratio_0_list.keys():\n",
    "        if l in i:\n",
    "            model.addConstr(\n",
    "                value_0_list[l]  * x[i] <= value_list[i] * x_o[l]\n",
    "            )\n",
    "\n",
    "model.optimize()\n",
    "\n",
    "if model.status == GRB.OPTIMAL:\n",
    "    print(\"Optimal solution found:\")\n",
    "    for v in model.getVars():\n",
    "        print(v.varName, v.x)\n",
    "    print(\"Optimal objective value:\", model.objVal)\n",
    "else:\n",
    "    print(\"No optimal solution found.\")\n",
    "\n",
    "Note: Please retrieve all neccessary information from the CSV file to generate the answer. When you generate the answer, please output required parameters in a whole text, including all vectors and matrices.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id_listing = \"\\n\".join(f\"{k}: {v}\" for k, v in FILE_IDS.items())\n",
    "escaped_fewshot_CA = fewshot_only_CA.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "escaped_fewshot_NP = fewshot_only_NP.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "\n",
    "PREFIX_CA = f\"\"\"\n",
    "You are an assistant that generates a SBLP mathematical model and the corresponding Gurobi Python code based on the user's description and provided CSV data.  When you need to retrieve information from the CSV file, please use the GetFlightFile tool, GetDemandFile tool and GetV1V2Files tool. Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "{escaped_fewshot_CA}\n",
    "\n",
    "Note: Please retrieve all neccessary information from the CSV file to generate the answer. When you generate the answer, please output required parameters in a whole text, including all vectors and matrices.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "PREFIX_NP = f\"\"\"\n",
    "You are an assistant that generates a SBLP mathematical model and the corresponding Gurobi Python code based on the user's description and provided CSV data.  When you need to retrieve information from the CSV file, please use the GetFlightFile tool, GetDemandFile tool and GetV1V2Files tool. Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "{escaped_fewshot_NP}\n",
    "\n",
    "Note: Please retrieve all neccessary information from the CSV file to generate the answer. When you generate the answer, please output required parameters in a whole text, including all vectors and matrices.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SUFFIX = \"\"\"\n",
    "\n",
    "Begin!\n",
    "\n",
    "User Description: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fewshot_Only_CA(query: str) -> str:\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0.0, model_name='gpt-4.1',top_p = 1,n = 1, openai_api_key=user_api_key)\n",
    "\n",
    "    agent_fewshot = initialize_agent(\n",
    "    tools=TOOLS,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\"prefix\": PREFIX_CA, \"suffix\": SUFFIX},\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    )\n",
    "\n",
    "    result = agent_fewshot.invoke({\"input\": query})\n",
    "    output_model = result['output']\n",
    "\n",
    "    return output_model\n",
    "\n",
    "\n",
    "def Fewshot_Only_NP(query: str) -> str:\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0.0, model_name='gpt-4.1',top_p = 1,n = 1, openai_api_key=user_api_key)\n",
    "\n",
    "    agent_fewshot = initialize_agent(\n",
    "    tools=TOOLS,\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\"prefix\": PREFIX_NP, \"suffix\": SUFFIX},\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    )\n",
    "\n",
    "    result = agent_fewshot.invoke({\"input\": query})\n",
    "    output_model = result['output']\n",
    "\n",
    "    return output_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2342,
     "status": "ok",
     "timestamp": 1749393386684,
     "user": {
      "displayName": "曾聪聪",
      "userId": "09963294123882050219"
     },
     "user_tz": -480
    },
    "id": "YCMukSvpkSRL",
    "outputId": "ef0c8171-b828-4e35-b9a1-2ddfcefa4229"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def Process_Input(query):\n",
    "  category_original = Problemtype(query)\n",
    "  print(f\"Problem type classification finished, it belongs to {category_original}.\")\n",
    "  if \"Sales-Based Linear Programming\" in    category_original:\n",
    "    print(\"Processing AirNRM queries\")\n",
    "    if \"flow conservation constraints\" in query or \"flow conservation constraint\" in query:\n",
    "        print('----------Flow Constraints----------')\n",
    "        print(\"Recommend Optimal Flights With Flow Conervation Constraints\")\n",
    "        output_model= Fewshot_Only_NP(query)\n",
    "        Type = \"Policy_Flow\"\n",
    "\n",
    "    else:\n",
    "        print('----------CA----------')\n",
    "        print(\"Only Develop Mathematic Formulations. No Recommendation for Flights.\")\n",
    "        output_model = Fewshot_Only_CA(query)\n",
    "        Type = \"CA\"\n",
    "  return Type,output_model\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def Batch_Process_Queries(df, query_column='Query'):\n",
    "    \"\"\"Process in Batches\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for query in tqdm(df['Query'], desc=\"Processing Queries\"):\n",
    "        category, output_model = Process_Input(query)\n",
    "        record = {\n",
    "            \"Category\": category,\n",
    "            \"Original_Query\": query,\n",
    "            \"Output\": output_model,\n",
    "        }\n",
    "        results.append(record)\n",
    "        time.sleep(10)  # Optional: to avoid hitting API rate limits\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1749393627725,
     "user": {
      "displayName": "曾聪聪",
      "userId": "09963294123882050219"
     },
     "user_tz": -480
    },
    "id": "7Y34PmNNug65"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "def extract_objective(log_text):\n",
    "\n",
    "    if \"Optimal objective\" in log_text:\n",
    "        pattern = r\"Optimal objective value: ([-+]?\\d*\\.?\\d+)\"\n",
    "        match = re.search(pattern, log_text)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "    elif \"Best objective\" in log_text:\n",
    "        pattern = r\"Best objective\\s+([-+]?\\d*\\.?\\d+e[-+]?\\d+)\"\n",
    "        match = re.search(pattern, log_text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def gain_obj(df_out):\n",
    "    output_code = df_out['Code'].tolist()\n",
    "    obj = []\n",
    "    i = 1\n",
    "  \n",
    "    for code in output_code:\n",
    "        print(i)\n",
    "      \n",
    "        namespace = {'gp': gp, 'GRB': GRB}\n",
    "\n",
    "      \n",
    "        log_output = []\n",
    "\n",
    "  \n",
    "        class LogCapture:\n",
    "            def write(self, message):\n",
    "                log_output.append(message)\n",
    "\n",
    "            def flush(self):  \n",
    "                pass\n",
    "\n",
    "        import sys\n",
    "        log_capture = LogCapture()\n",
    "        original_stdout = sys.stdout \n",
    "        sys.stdout = log_capture \n",
    "\n",
    "        try:\n",
    "            exec(code, namespace)\n",
    "        except Exception as e:\n",
    "            log_output.append(f\"Error: {e}\\n\")\n",
    "            print(f\"Error executing code block {i}: {e}\")\n",
    "        finally:\n",
    "            sys.stdout = original_stdout  \n",
    "\n",
    "   \n",
    "        log_text = ''.join(log_output)\n",
    "\n",
    "  \n",
    "        optimal_value = extract_objective(log_text)\n",
    "        if optimal_value is not None:\n",
    "            obj.append(optimal_value)\n",
    "            print(f\"Optimal Value: {optimal_value}\")\n",
    "        else:\n",
    "\n",
    "            obj.append(\"No optimal value found.\")\n",
    "            print(\"No optimal value found.\")\n",
    "        i += 1\n",
    "    return obj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 48681,
     "status": "ok",
     "timestamp": 1749393728770,
     "user": {
      "displayName": "曾聪聪",
      "userId": "09963294123882050219"
     },
     "user_tz": -480
    },
    "id": "zZEG0Gixug65",
    "outputId": "34876c5a-936f-43c0-a2ab-43b295ee8530"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Test_Dataset/Air_NRM/query_CA.csv')\n",
    "result_df = Batch_Process_Queries(df)\n",
    "result_df.to_csv(\"FewshotOnly_CA_test_GPT4.1_New.csv\", index=False)\n",
    "\n",
    "Code = []\n",
    "for i in range(len(result_df['Output'])):\n",
    "    text = result_df['Output'][i]\n",
    "    pattern = r'```python(.*?)```'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    code = matches[0]\n",
    "    if 'gurobipy' in code:\n",
    "        Code.append(code)\n",
    "    else:\n",
    "        if len(matches) > 0:\n",
    "            Code.append(matches[1])\n",
    "        else:\n",
    "            Code.append(\"No code found\")\n",
    "\n",
    "code_df = pd.DataFrame(Code, columns=['Code'])\n",
    "code_df.to_csv(\"FewshotOnly_code_CA_test_GPT4.1_New.csv\", index=False)\n",
    "\n",
    "obj = gain_obj(code_df)\n",
    "obj_df = pd.DataFrame({'Optimal Value': obj})\n",
    "obj_df.to_csv('OBJ_CA_4.1_FewshotOnly.csv', index=False)\n",
    "\n",
    "combined_df = pd.concat([result_df, code_df,obj_df], axis=1)\n",
    "combined_df.to_csv(\"final_answer_CA_test_GPT4.1_FewshotOnly.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Test_Dataset/Air_NRM/query_NP_Flow.csv')\n",
    "result_df = Batch_Process_Queries(df)\n",
    "result_df.to_csv(\"FewshotOnly_NP_test_GPT4.1_New.csv\", index=False)\n",
    "\n",
    "Code = []\n",
    "for i in range(len(result_df['Output'])):\n",
    "    text = result_df['Output'][i]\n",
    "    pattern = r'```python(.*?)```'\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    code = matches[0]\n",
    "    if 'gurobipy' in code:\n",
    "        Code.append(code)\n",
    "    else:\n",
    "        if len(matches) > 0:\n",
    "            Code.append(matches[1])\n",
    "        else:\n",
    "            Code.append(\"No code found\")\n",
    "\n",
    "code_df = pd.DataFrame(Code, columns=['Code'])\n",
    "code_df.to_csv(\"FewshotOnly_code_NP_test_GPT4.1_New.csv\", index=False)\n",
    "\n",
    "obj = gain_obj(code_df)\n",
    "obj_df = pd.DataFrame({'Optimal Value': obj})\n",
    "obj_df.to_csv('OBJ_NP_4.1_FewshotOnly.csv', index=False)\n",
    "\n",
    "combined_df = pd.concat([result_df, code_df,obj_df], axis=1)\n",
    "combined_df.to_csv(\"final_answer_NP_test_GPT4.1_FewshotOnly.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "test_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
