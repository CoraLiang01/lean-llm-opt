{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_ollama import ChatOllama\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "import re\n",
    "from datetime import time\n",
    "from langchain.schema import HumanMessage\n",
    "import openai\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "from io import StringIO\n",
    "import contextlib\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import List\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from typing import List, Dict\n",
    "from langchain_openai import ChatOpenAI\n",
    "user_api_key = \"YOUR API KEY HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing import List\n",
    "\n",
    "def build_llm(model: str = \"gpt-oss:20b\", temperature: float = 0.0) -> ChatOllama:\n",
    "    \"\"\"Initializes the ChatOllama model instance.\"\"\"\n",
    "    return ChatOllama(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        timeout=500\n",
    "    )\n",
    "\n",
    "# def build_llm(model: str = \"gpt-4.1\", temperature: float = 0.0) -> ChatOpenAI:\n",
    "#     return ChatOpenAI(\n",
    "#         model=model,\n",
    "#         temperature=temperature,\n",
    "#         openai_api_key=user_api_key\n",
    "#     )\n",
    "\n",
    "# def build_llm(model: str = \"gpt-5\", temperature: float = 1.0) -> ChatOpenAI:\n",
    "#     return ChatOpenAI(\n",
    "#         model=model,\n",
    "#         temperature=temperature,\n",
    "#         openai_api_key=user_api_key\n",
    "#     )\n",
    "\n",
    "def run_test(df: pd.DataFrame, llm: ChatOpenAI) -> List[str]:\n",
    "    \"\"\"\n",
    "    Runs the test by sending queries from the DataFrame to the LLM.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing a 'Query' column.\n",
    "        llm: The initialized ChatOllama instance.\n",
    "\n",
    "    Returns:\n",
    "        A list of string responses from the LLM.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for row_idx, row in df.iterrows():\n",
    "        query = row['Query'] \n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Below is an operations research question. Build a mathematical model and corresponding python code using 'gurobipy' that appropriately addresses the question.\n",
    "\n",
    "# Question\n",
    "{query}\n",
    "\n",
    "# Response\n",
    "        \"\"\"\n",
    "\n",
    "        messages = [\n",
    "            HumanMessage(content=prompt)\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            response = llm(messages)\n",
    "            response_content = response.content\n",
    "            \n",
    "            print(response_content)\n",
    "            \n",
    "            result.append(response_content)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query at Index {row_idx}: {e}\")\n",
    "            result.append(f\"Error: {e}\") \n",
    "            \n",
    "    return result\n",
    "\n",
    "llm1 = build_llm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_combine_csvs(file_order):\n",
    "    dfs = []\n",
    "    for fname in file_order:\n",
    "        if os.path.exists(fname):\n",
    "            df = pd.read_csv(fname)\n",
    "            dfs.append(df)\n",
    "            print(f\"Read file: {fname} (Row length: {len(df)})\")\n",
    "        else:\n",
    "            print(f\"File doesn't exist: {fname}, already skipped\")\n",
    "    \n",
    "    if not dfs:\n",
    "        raise ValueError(\"No effective files\")\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def run_gurobi_code(code_str):\n",
    " \n",
    "    try:\n",
    "      \n",
    "        with StringIO() as buf, contextlib.redirect_stdout(buf), contextlib.redirect_stderr(buf):\n",
    "            env = {\n",
    "                '__builtins__': __builtins__,\n",
    "                'gp': gp,\n",
    "                'GRB': GRB\n",
    "            }\n",
    "            \n",
    "           \n",
    "            code_str += \"\\n\\n# Added by executor\\n\"\n",
    "            code_str += \"if hasattr(m, 'status') and m.status == GRB.OPTIMAL:\\n\"\n",
    "            code_str += \"    __result__ = m.ObjVal\\n\"\n",
    "            code_str += \"else:\\n\"\n",
    "            code_str += \"    __result__ = None\\n\"\n",
    "            \n",
    "            \n",
    "            exec(code_str, env)\n",
    "            result = env.get('__result__', None)\n",
    "            \n",
    "     \n",
    "            if 'm' in env:\n",
    "                env['m'].dispose()\n",
    "                del env['m']\n",
    "            \n",
    "            return result\n",
    "    except Exception as e:\n",
    "        print(f\"Execution error: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "def extract_python_code(text):\n",
    "    if not isinstance(text, str) or not text:\n",
    "        return None\n",
    "    patterns = [\n",
    "        r'```python\\s*(.*?)\\s*```',\n",
    "        r'```\\s*(.*?)\\s*```'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, flags=re.DOTALL)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "            \n",
    "    return None\n",
    "\n",
    "def run_gurobi_code(code):\n",
    "    if not code:\n",
    "        return None\n",
    "        \n",
    "    try:\n",
    "        local_vars = {\n",
    "            'gp': gp, \n",
    "            'GRB': GRB, \n",
    "            '__builtins__': __builtins__\n",
    "        }\n",
    "        \n",
    "        exec(code, local_vars)\n",
    "        \n",
    "        models = [v for v in local_vars.values() if isinstance(v, gp.Model)]\n",
    "        \n",
    "        if not models:\n",
    "            print(\"Warning: No Gurobi model found in the code.\")\n",
    "            return None\n",
    "        \n",
    "        model = models[-1]\n",
    "        \n",
    "        if model.status == GRB.LOADED:\n",
    "            model.optimize()\n",
    "            \n",
    "        if model.status == GRB.OPTIMAL:\n",
    "            return model.objVal\n",
    "        elif model.status == GRB.INFEASIBLE:\n",
    "            print(\"Model is Infeasible\")\n",
    "            return \"Infeasible\"\n",
    "        else:\n",
    "            print(f\"Model finished with status: {model.status}\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running Gurobi code: {type(e).__name__}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MAMOE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MAMO Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_MAMOc = pd.read_csv('Test_Dataset/Small-scale/MAMO_ComplexLP_fixed.csv')\n",
    "test_MAMOc1=test_MAMOc[:25]\n",
    "test_MAMOc2=test_MAMOc[25:50]\n",
    "test_MAMOc3=test_MAMOc[50:75]\n",
    "test_MAMOc4=test_MAMOc[75:100]\n",
    "test_MAMOc5=test_MAMOc[100:125]\n",
    "test_MAMOc6=test_MAMOc[125:150]\n",
    "test_MAMOc7=test_MAMOc[150:175]\n",
    "test_MAMOc8=test_MAMOc[175:]\n",
    "test_MAMOc8\n",
    "\n",
    "classify_problem = llm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc1 = run_test(test_MAMOc1,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc1['Query'], 'model_output':output_model_MAMOc1})\n",
    "output_df.to_csv(\"MAMOc_1-25_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc2 = run_test(test_MAMOc2,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc2['Query'], 'model_output':output_model_MAMOc2})\n",
    "output_df.to_csv(\"MAMOc_26-50_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc3 = run_test(test_MAMOc3,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc3['Query'], 'model_output':output_model_MAMOc3})\n",
    "output_df.to_csv(\"MAMOc_51-75_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc4 = run_test(test_MAMOc4,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc4['Query'], 'model_output':output_model_MAMOc4})\n",
    "output_df.to_csv(\"MAMOc_76-100_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOc6 = run_test(test_MAMOc5,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc5['Query'], 'model_output':output_model_MAMOc6})\n",
    "output_df.to_csv(\"MAMOc_101-125_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc6 = run_test(test_MAMOc6,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc6['Query'], 'model_output':output_model_MAMOc6})\n",
    "output_df.to_csv(\"MAMOc_126-150_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc7 = run_test(test_MAMOc7,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc7['Query'], 'model_output':output_model_MAMOc7})\n",
    "output_df.to_csv(\"MAMOc_151-175_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc8 = run_test(test_MAMOc8,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc8['Query'], 'model_output':output_model_MAMOc8})\n",
    "output_df.to_csv(\"MAMOc_176-202_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order=[\n",
    "    \"MAMOc_1-25_5.2.csv\",\n",
    "    \"MAMOc_26-50_5.2.csv\",\n",
    "    \"MAMOc_51-75_5.2.csv\",\n",
    "    \"MAMOc_76-100_5.2.csv\",\n",
    "    \"MAMOc_101-125_5.2.csv\",\n",
    "    \"MAMOc_126-150_5.2.csv\",\n",
    "    \"MAMOc_151-175_5.2.csv\",\n",
    "    \"MAMOc_176-202_5.2.csv\",\n",
    "]\n",
    "try:\n",
    "    combined_df = read_and_combine_csvs(file_order)\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "    output_file = \"MAMOc_result_5.2.csv\"\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "except Exception as e:\n",
    "    print(f\"File processing failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "print(\"\\nRunning Gurobi Code...\")\n",
    "objective_values = []\n",
    "start_time = time.time()\n",
    "success_count = 0\n",
    "\n",
    "for i, row in combined_df.iterrows():\n",
    "    full_text = row['model_output']\n",
    "    \n",
    "    code = extract_python_code(full_text)\n",
    "    \n",
    "    if code:\n",
    "        print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
    "        result = run_gurobi_code(code)\n",
    "        objective_values.append(result)\n",
    "        if result is not None:\n",
    "            success_count += 1\n",
    "    else:\n",
    "        print(f\"Warning: No Python code found in row {i+1}\")\n",
    "        objective_values.append(None)\n",
    "\n",
    "combined_df['best_objective'] = objective_values\n",
    "\n",
    "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
    "print(f\"Success: {success_count}/{len(combined_df)}\")\n",
    "\n",
    "print(\"\\nFirst few objective values:\")\n",
    "for i in range(min(5, len(combined_df))):\n",
    "    print(f\"Row {i+1}: Best objective = {objective_values[i]}\")\n",
    "\n",
    "output_file = \"MAMOc_result_oss.xlsx\"\n",
    "combined_df.to_excel(output_file, index=False)\n",
    "print(f\"\\nResults saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lean_final_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
