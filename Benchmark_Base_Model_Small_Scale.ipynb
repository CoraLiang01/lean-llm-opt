{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "# from langchain_openai import ChatOpenAI\n",
    "# from langchain_ollama import ChatOllama\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "import re\n",
    "from datetime import time\n",
    "from langchain.schema import HumanMessage\n",
    "import openai\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "from io import StringIO\n",
    "import contextlib\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from langchain.schema import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import List\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from typing import List, Dict\n",
    "from langchain_openai import ChatOpenAI\n",
    "user_api_key = \"YOUR_OPENAI_API_KEY\"  # Replace with your OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing import List\n",
    "\n",
    "# def build_llm(model: str = \"gpt-oss:20b\", temperature: float = 0.0) -> ChatOllama:\n",
    "#     \"\"\"Initializes the ChatOllama model instance.\"\"\"\n",
    "#     return ChatOllama(\n",
    "#         model=model,\n",
    "#         temperature=temperature,\n",
    "#         base_url=\"http://localhost:11434\",\n",
    "#         timeout=500\n",
    "#     )\n",
    "\n",
    "\n",
    "# def build_llm(model: str = \"gpt-4.1\", temperature: float = 0.0) -> ChatOpenAI:\n",
    "#     return ChatOpenAI(\n",
    "#         model=model,\n",
    "#         temperature=temperature,\n",
    "#         openai_api_key=user_api_key\n",
    "#     )\n",
    "\n",
    "# def build_llm(model: str = \"gpt-5\", temperature: float = 1.0) -> ChatOpenAI:\n",
    "#     return ChatOpenAI(\n",
    "#         model=model,\n",
    "#         temperature=temperature,\n",
    "#         openai_api_key=user_api_key\n",
    "#     )\n",
    "\n",
    "def build_llm(model: str = \"gpt-5.2\", temperature: float = 0.0) -> ChatOpenAI:\n",
    "    return ChatOpenAI(\n",
    "        model=model,\n",
    "        temperature=temperature,\n",
    "        openai_api_key=user_api_key\n",
    "    )\n",
    "\n",
    "def run_test(df: pd.DataFrame, llm: ChatOpenAI) -> List[str]:\n",
    "    \"\"\"\n",
    "    Runs the test by sending queries from the DataFrame to the LLM.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing a 'Query' column.\n",
    "        llm: The initialized ChatOllama instance.\n",
    "\n",
    "    Returns:\n",
    "        A list of string responses from the LLM.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    for row_idx, row in df.iterrows():\n",
    "        query = row['Query'] \n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "Below is an operations research question. Build a mathematical model and corresponding python code using 'gurobipy' that appropriately addresses the question.\n",
    "\n",
    "# Question\n",
    "{query}\n",
    "\n",
    "# Response\n",
    "        \"\"\"\n",
    "\n",
    "        messages = [\n",
    "            HumanMessage(content=prompt)\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            response = llm(messages)\n",
    "            response_content = response.content\n",
    "            \n",
    "            print(response_content)\n",
    "            \n",
    "            result.append(response_content)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing query at Index {row_idx}: {e}\")\n",
    "            result.append(f\"Error: {e}\") \n",
    "            \n",
    "    return result\n",
    "\n",
    "llm1 = build_llm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_combine_csvs(file_order):\n",
    "    dfs = []\n",
    "    for fname in file_order:\n",
    "        if os.path.exists(fname):\n",
    "            df = pd.read_csv(fname)\n",
    "            dfs.append(df)\n",
    "            print(f\"Read file: {fname} (Row length: {len(df)})\")\n",
    "        else:\n",
    "            print(f\"File doesn't exist: {fname}, already skipped\")\n",
    "    \n",
    "    if not dfs:\n",
    "        raise ValueError(\"No effective files\")\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def run_gurobi_code(code_str):\n",
    " \n",
    "    try:\n",
    "      \n",
    "        with StringIO() as buf, contextlib.redirect_stdout(buf), contextlib.redirect_stderr(buf):\n",
    "            env = {\n",
    "                '__builtins__': __builtins__,\n",
    "                'gp': gp,\n",
    "                'GRB': GRB\n",
    "            }\n",
    "            \n",
    "           \n",
    "            code_str += \"\\n\\n# Added by executor\\n\"\n",
    "            code_str += \"if hasattr(m, 'status') and m.status == GRB.OPTIMAL:\\n\"\n",
    "            code_str += \"    __result__ = m.ObjVal\\n\"\n",
    "            code_str += \"else:\\n\"\n",
    "            code_str += \"    __result__ = None\\n\"\n",
    "            \n",
    "            \n",
    "            exec(code_str, env)\n",
    "            result = env.get('__result__', None)\n",
    "            \n",
    "     \n",
    "            if 'm' in env:\n",
    "                env['m'].dispose()\n",
    "                del env['m']\n",
    "            \n",
    "            return result\n",
    "    except Exception as e:\n",
    "        print(f\"Execution error: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_python_code(text):\n",
    "    pattern = r'```python(.*?)```'\n",
    "    match = re.search(pattern, text, flags=re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def run_gurobi_code(code):\n",
    "    try:\n",
    "        \n",
    "        local_vars = {'gp': gp, 'GRB': GRB, '__builtins__': __builtins__}\n",
    "        \n",
    "        exec(code, local_vars)\n",
    "        \n",
    "        models = []\n",
    "        for var_name, var_value in local_vars.items():\n",
    "            if isinstance(var_value, gp.Model):\n",
    "                models.append(var_value)\n",
    "        \n",
    "        if models:\n",
    "            model = models[-1] \n",
    "            if model.status == GRB.OPTIMAL:\n",
    "                return model.objVal\n",
    "            else:\n",
    "                print(f\"Model status is not optimal: {model.status}\")\n",
    "                return None\n",
    "        \n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error running Gurobi code: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test NL4OPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nl4opt = pd.read_csv('Test_Dataset/Small-scale/NL4OPT NEW.csv')\n",
    "test_nl4opt1=test_nl4opt[:50]\n",
    "test_nl4opt2=test_nl4opt[50:100]\n",
    "test_nl4opt3=test_nl4opt[100:150]\n",
    "test_nl4opt4=test_nl4opt[150:200]\n",
    "test_nl4opt5=test_nl4opt[200:]\n",
    "test_nl4opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_nl4opt1 = run_test(test_nl4opt1,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt1['Query'], 'model_output':output_model_nl4opt1})\n",
    "output_df.to_csv(\"nl4opt_1-50_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_nl4opt2 = run_test(test_nl4opt2,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt2['Query'], 'model_output':output_model_nl4opt2})\n",
    "output_df.to_csv(\"nl4opt_51-100_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_nl4opt3 = run_test(test_nl4opt3,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt3['Query'], 'model_output':output_model_nl4opt3})\n",
    "output_df.to_csv(\"nl4opt_101-150_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_nl4opt4 = run_test(test_nl4opt4,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt4['Query'], 'model_output':output_model_nl4opt4})\n",
    "output_df.to_csv(\"nl4opt_151-200_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_nl4opt5= run_test(test_nl4opt5,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt5['Query'], 'model_output':output_model_nl4opt5})\n",
    "output_df.to_csv(\"nl4opt_201-_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order=[\n",
    "    \"nl4opt_1-50_5.2.csv\",\n",
    "    \"nl4opt_51-100_5.2.csv\",\n",
    "    \"nl4opt_101-150_5.2.csv\",\n",
    "    \"nl4opt_151-200_5.2.csv\",\n",
    "    \"nl4opt_201-_5.2.csv\",\n",
    "]\n",
    "try:\n",
    "    combined_df = read_and_combine_csvs(file_order)\n",
    "    combined_df.to_csv('nl4opt_5.2_Base_Model.csv')\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "except Exception as e:\n",
    "    print(f\"File processing failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "print(\"\\nRunning Gurobi Code...\")\n",
    "objective_values = []\n",
    "start_time = time.time()\n",
    "success_count = 0\n",
    "\n",
    "for i, row in combined_df.iterrows():\n",
    "    full_text = row['model_output']\n",
    "    \n",
    "    code = extract_python_code(full_text)\n",
    "    \n",
    "    if code:\n",
    "        print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
    "        result = run_gurobi_code(code)\n",
    "        objective_values.append(result)\n",
    "        if result is not None:\n",
    "            success_count += 1\n",
    "    else:\n",
    "        print(f\"Warning: No Python code found in row {i+1}\")\n",
    "        objective_values.append(None)\n",
    "\n",
    "combined_df['best_objective'] = objective_values\n",
    "\n",
    "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
    "print(f\"Success: {success_count}/{len(combined_df)}\")\n",
    "\n",
    "print(\"\\nFirst few objective values:\")\n",
    "for i in range(min(5, len(combined_df))):\n",
    "    print(f\"Row {i+1}: Best objective = {objective_values[i]}\")\n",
    "\n",
    "output_file = \"nl4opt_5.2_Base_Model.xlsx\"\n",
    "combined_df.to_excel(output_file, index=False)\n",
    "print(f\"\\nResults saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test IndustryOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_industryOR = pd.read_csv('Test_Dataset/Small-scale/IndustryOR_fixedV2.csv')\n",
    "test_industryOR1_=test_industryOR[:25]\n",
    "test_industryOR2=test_industryOR[25:50]\n",
    "test_industryOR3=test_industryOR[50:75]\n",
    "test_industryOR4=test_industryOR[75:]\n",
    "test_industryOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_industryOR1= run_test(test_industryOR1_,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_industryOR1_['Query'], 'model_output':output_model_industryOR1})\n",
    "output_df.to_csv(\"IndustryOR_1-25_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_industryOR2 = run_test(test_industryOR2,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_industryOR2['Query'], 'model_output':output_model_industryOR2})\n",
    "output_df.to_csv(\"IndustryOR_26-50_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_industryOR3 = run_test(test_industryOR3,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_industryOR3['Query'], 'model_output':output_model_industryOR3})\n",
    "output_df.to_csv(\"IndustryOR_51-75_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_industryOR4 = run_test(test_industryOR4,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_industryOR4['Query'], 'model_output':output_model_industryOR4})\n",
    "output_df.to_csv(\"IndustryOR_76-100_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order=[\n",
    "    \"IndustryOR_1-25_5.2.csv\",\n",
    "    \"IndustryOR_26-50_5.2.csv\",\n",
    "    \"IndustryOR_51-75_5.2.csv\",\n",
    "    \"IndustryOR_76-100_5.2.csv\",\n",
    "]\n",
    "try:\n",
    "    combined_df = read_and_combine_csvs(file_order)\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "    output_file = \"IndustryOR_result_5.2.csv\"\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "except Exception as e:\n",
    "    print(f\"File processing failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "print(\"\\nRunning Gurobi Code...\")\n",
    "objective_values = []\n",
    "start_time = time.time()\n",
    "success_count = 0\n",
    "\n",
    "for i, row in combined_df.iterrows():\n",
    "    full_text = row['model_output']\n",
    "    \n",
    "    code = extract_python_code(full_text)\n",
    "    \n",
    "    if code:\n",
    "        print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
    "        result = run_gurobi_code(code)\n",
    "        objective_values.append(result)\n",
    "        if result is not None:\n",
    "            success_count += 1\n",
    "    else:\n",
    "        print(f\"Warning: No Python code found in row {i+1}\")\n",
    "        objective_values.append(None)\n",
    "\n",
    "combined_df['best_objective'] = objective_values\n",
    "\n",
    "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
    "print(f\"Success: {success_count}/{len(combined_df)}\")\n",
    "\n",
    "print(\"\\nFirst few objective values:\")\n",
    "for i in range(min(5, len(combined_df))):\n",
    "    print(f\"Row {i+1}: Best objective = {objective_values[i]}\")\n",
    "\n",
    "output_file = \"IndustryOR_result_5.2.xlsx\"\n",
    "combined_df.to_excel(output_file, index=False)\n",
    "print(f\"\\nResults saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MAMO easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_MAMOe = pd.read_csv('Test_Dataset/Small-scale/MAMO_EasyLP_fixed.csv')\n",
    "test_MAMOe1=test_MAMOe[:100]\n",
    "test_MAMOe2=test_MAMOe[100:200]\n",
    "test_MAMOe3=test_MAMOe[200:300]\n",
    "test_MAMOe4=test_MAMOe[300:400]\n",
    "test_MAMOe5=test_MAMOe[400:500]\n",
    "test_MAMOe6=test_MAMOe[500:600]\n",
    "test_MAMOe7=test_MAMOe[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOe1 = run_test(test_MAMOe1,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe1['Query'], 'model_output':output_model_MAMOe1})\n",
    "output_df.to_csv(\"MAMOe1_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOe2 = run_test(test_MAMOe2,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe2['Query'], 'model_output':output_model_MAMOe2})\n",
    "output_df.to_csv(\"MAMOe2_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOe3 = run_test(test_MAMOe3,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe3['Query'], 'model_output':output_model_MAMOe3})\n",
    "output_df.to_csv(\"MAMOe3_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOe4 = run_test(test_MAMOe4,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe4['Query'], 'model_output':output_model_MAMOe4})\n",
    "output_df.to_csv(\"MAMOe4_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOe5 = run_test(test_MAMOe5,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe5['Query'], 'model_output':output_model_MAMOe5})\n",
    "output_df.to_csv(\"MAMOe5_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOe6 = run_test(test_MAMOe6,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe6['Query'], 'model_output':output_model_MAMOe6})\n",
    "output_df.to_csv(\"MAMOe6_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOe7 = run_test(test_MAMOe7,llm1)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe7['Query'], 'model_output':output_model_MAMOe7})\n",
    "output_df.to_csv(\"MAMOe7_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order=[\n",
    "    \"MAMOe1_5.2.csv\",\n",
    "    \"MAMOe2_5.2.csv\",\n",
    "    \"MAMOe3_5.2.csv\",\n",
    "    \"MAMOe4_5.2.csv\",\n",
    "    \"MAMOe5_5.2.csv\",\n",
    "    \"MAMOe6_5.2.csv\",\n",
    "    \"MAMOe7_5.2.csv\",\n",
    "]\n",
    "try:\n",
    "    combined_df = read_and_combine_csvs(file_order)\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "except Exception as e:\n",
    "    print(f\"File processing failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "print(\"\\nRunning Gurobi Code...\")\n",
    "objective_values = []\n",
    "start_time = time.time()\n",
    "success_count = 0\n",
    "\n",
    "for i, row in combined_df.iterrows():\n",
    "    full_text = row['model_output']\n",
    "    \n",
    "    code = extract_python_code(full_text)\n",
    "    \n",
    "    if code:\n",
    "        print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
    "        result = run_gurobi_code(code)\n",
    "        objective_values.append(result)\n",
    "        if result is not None:\n",
    "            success_count += 1\n",
    "    else:\n",
    "        print(f\"Warning: No Python code found in row {i+1}\")\n",
    "        objective_values.append(None)\n",
    "\n",
    "combined_df['best_objective'] = objective_values\n",
    "\n",
    "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
    "print(f\"Success: {success_count}/{len(combined_df)}\")\n",
    "\n",
    "print(\"\\nFirst few objective values:\")\n",
    "for i in range(min(5, len(combined_df))):\n",
    "    print(f\"Row {i+1}: Best objective = {objective_values[i]}\")\n",
    "\n",
    "output_file = \"MAMOe_Base_5.2.xlsx\"\n",
    "combined_df.to_excel(output_file, index=False)\n",
    "print(f\"\\nResults saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MAMO Complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_MAMOc = pd.read_csv('Test_Dataset/Small-scale/MAMO_ComplexLP_fixed.csv')\n",
    "test_MAMOc1=test_MAMOc[:25]\n",
    "test_MAMOc2=test_MAMOc[25:50]\n",
    "test_MAMOc3=test_MAMOc[50:75]\n",
    "test_MAMOc4=test_MAMOc[75:100]\n",
    "test_MAMOc5=test_MAMOc[100:125]\n",
    "test_MAMOc6=test_MAMOc[125:150]\n",
    "test_MAMOc7=test_MAMOc[150:175]\n",
    "test_MAMOc8=test_MAMOc[175:]\n",
    "test_MAMOc8\n",
    "\n",
    "classify_problem = llm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc1 = run_test(test_MAMOc1,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc1['Query'], 'model_output':output_model_MAMOc1})\n",
    "output_df.to_csv(\"MAMOc_1-25_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc2 = run_test(test_MAMOc2,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc2['Query'], 'model_output':output_model_MAMOc2})\n",
    "output_df.to_csv(\"MAMOc_26-50_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc3 = run_test(test_MAMOc3,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc3['Query'], 'model_output':output_model_MAMOc3})\n",
    "output_df.to_csv(\"MAMOc_51-75_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc4 = run_test(test_MAMOc4,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc4['Query'], 'model_output':output_model_MAMOc4})\n",
    "output_df.to_csv(\"MAMOc_76-100_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOc6 = run_test(test_MAMOc5,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc5['Query'], 'model_output':output_model_MAMOc6})\n",
    "output_df.to_csv(\"MAMOc_101-125_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc6 = run_test(test_MAMOc6,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc6['Query'], 'model_output':output_model_MAMOc6})\n",
    "output_df.to_csv(\"MAMOc_126-150_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc7 = run_test(test_MAMOc7,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc7['Query'], 'model_output':output_model_MAMOc7})\n",
    "output_df.to_csv(\"MAMOc_151-175_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOc8 = run_test(test_MAMOc8,classify_problem)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc8['Query'], 'model_output':output_model_MAMOc8})\n",
    "output_df.to_csv(\"MAMOc_176-202_5.2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order=[\n",
    "    \"MAMOc_1-25_5.2.csv\",\n",
    "    \"MAMOc_26-50_5.2.csv\",\n",
    "    \"MAMOc_51-75_5.2.csv\",\n",
    "    \"MAMOc_76-100_5.2.csv\",\n",
    "    \"MAMOc_101-125_5.2.csv\",\n",
    "    \"MAMOc_126-150_5.2.csv\",\n",
    "    \"MAMOc_151-175_5.2.csv\",\n",
    "    \"MAMOc_176-202_5.2.csv\",\n",
    "]\n",
    "try:\n",
    "    combined_df = read_and_combine_csvs(file_order)\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "    output_file = \"MAMOc_result_5.2.csv\"\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "except Exception as e:\n",
    "    print(f\"File processing failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "print(\"\\nRunning Gurobi Code...\")\n",
    "objective_values = []\n",
    "start_time = time.time()\n",
    "success_count = 0\n",
    "\n",
    "for i, row in combined_df.iterrows():\n",
    "    full_text = row['model_output']\n",
    "    \n",
    "    code = extract_python_code(full_text)\n",
    "    \n",
    "    if code:\n",
    "        print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
    "        result = run_gurobi_code(code)\n",
    "        objective_values.append(result)\n",
    "        if result is not None:\n",
    "            success_count += 1\n",
    "    else:\n",
    "        print(f\"Warning: No Python code found in row {i+1}\")\n",
    "        objective_values.append(None)\n",
    "\n",
    "combined_df['best_objective'] = objective_values\n",
    "\n",
    "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
    "print(f\"Success: {success_count}/{len(combined_df)}\")\n",
    "\n",
    "print(\"\\nFirst few objective values:\")\n",
    "for i in range(min(5, len(combined_df))):\n",
    "    print(f\"Row {i+1}: Best objective = {objective_values[i]}\")\n",
    "\n",
    "output_file = \"MAMOc_result_5.2.xlsx\"\n",
    "combined_df.to_excel(output_file, index=False)\n",
    "print(f\"\\nResults saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lean_final_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
