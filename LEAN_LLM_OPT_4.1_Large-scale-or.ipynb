{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_classic.chains import RetrievalQA\n",
    "from langchain_classic.agents import initialize_agent, AgentType, Tool\n",
    "import re\n",
    "from datetime import time\n",
    "from langchain_core.messages import HumanMessage\n",
    "import openai\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "from io import StringIO\n",
    "import contextlib\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import List\n",
    "from langchain_classic.chains import create_retrieval_chain\n",
    "from langchain_classic.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "user_api_key = \"Your OpenAI API Key\"  # Replace with your OpenAI API key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm1 = ChatOpenAI(\n",
    "    temperature=0.0, model_name=\"gpt-4\", openai_api_key=user_api_key\n",
    ")\n",
    "\n",
    "loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RefData.csv\", encoding=\"utf-8\")\n",
    "data = loader.load()\n",
    "documents = data\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "vectors = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "retriever = vectors.as_retriever(search_kwargs={'k': 5})\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm1,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    ")\n",
    "qa_tool = Tool(\n",
    "    name=\"FileQA\",\n",
    "    func=qa_chain.invoke,\n",
    "    description=(\n",
    "        \"Use this tool to answer questions about the problem type of the text. \"\n",
    "    ),\n",
    ")\n",
    "\n",
    "few_shot_examples_csv = \"\"\"\n",
    "\n",
    "Query: What is the problem type in operation of the text? Please give the answer directly. Text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1,w_2,w_3.There is an independent demand stream for each of the products. The objective of the company is to decide which demands to be fufilled over a ﬁnite sales horizon [0,10] to maximize the total expected revenue from ﬁxed initial inventories. The on-hand inventories for the three items are c_1,c_2,c_3 respectively. During the sales horizon, replenishment is not allowed and there is no any in-transit inventories. Customers who want to purchase P1,P2,P3 arrive at each period accoring to a Poisson process with a_1,a_2,a_3 the arrival rates respectively. Decision variables y_1,y_2,y_3 correspond to the number of requests that the firm plans to fulfill for product 1,2,3. These variables are all positive integers.\n",
    "\n",
    "Thought: I need to determine the problem type of the text. The Query contains descriptions like '.csv' or 'column'. I'll use the FileQA tool to retrieve the relevant information.\n",
    "\n",
    "Action: FileQA\n",
    "\n",
    "Action Input: \"What is the problem type in operation of the text? text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1, w_2, w_3. ...\"\n",
    "\n",
    "Observation: The problem type of the text is Network Revenue Management.\n",
    "\n",
    "Thought: The problem type Network Revenue Management is in the allowed list [Network Revenue Management, Resource Allocation, Transportation, Facility Location Problem, Assignment Problem, , Others without CSV]. I could get the final answer and finish.\n",
    "\n",
    "Final Answer: Network Revenue Management.\n",
    "\n",
    "---\n",
    "Query: What is the problem type in operation of the text? Please give the answer directly. Text:A supermarket needs to allocate various products, including high-demand items like the Sony Alpha Refrigerator, Sony Bravia XR, and Sony PlayStation 5, across different retail shelves. The product values and space requirements are provided in the \"Products.csv\" dataset. Additionally, the store has multiple shelves, each with a total space limit and specific space constraints for Sony and Apple products, as outlined in the \"Capacity.csv\" file. The goal is to determine the optimal number of units of each Sony product to place on each shelf to maximize total value while ensuring that the space used by Sony products on each shelf does not exceed the brand-specific limits. The decision variables x_ij represent the number of units of product i to be placed on shelf j.\n",
    "\n",
    "Thought: I need to determine the problem type of the text. The Query contains descriptions like '.csv' or 'column'. I'll use the FileQA tool to retrieve the relevant information.\n",
    "\n",
    "Action: FileQA\n",
    "\n",
    "Action Input: \"What is the problem type in operation of the text? Text:A supermarket needs to allocate various products, including high-demand items like the Sony Alpha Refrigerator, Sony Bravia XR, ....\"\n",
    "\n",
    "Observation: The problem type of the text is Inventory Management.\n",
    "\n",
    "Thought: The problem type Inventory Management is not in the allowed list [Network Revenue Management, Resource Allocation, Transportation, Facility Location Problem, Assignment Problem, Others with CSV, Others without CSV]. Therefore, the problem type should be Others with CSV - Inventory management\n",
    "Final Answer: Others with CSV - Inventory management\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "few_shot_examples_without_csv = \"\"\"\n",
    "Query: A book distributor needs to shuffle a bunch of books from two warehouses (supply points: W1, W2) to libraries (demand points: L1, L2), using a pair of sorting centers (transshipment points: C1, C2). W1 has a stash of up to p_1 books per day it can send out. W2 can send out up to p_2 books daily. Library L1 needs a solid d_1 books daily. L2 requires d_2 books daily. Storage at the sorting centers has no cap. Transportation costs: From W1 to C1 is t_11 dollars, to C2 is t_12 dollars. From W2 to C1 is t_21 dollars, and to C2 it__ t_22 dollars. From the centers to the libraries: From C1 to L1, it__l cost t_31 dollars, to L2 it__ t_32 dollars. From C2 to L1, it__ t_41 dollars, to L2 it__ t_42 dollars. The strategy here is all about minimizing transportation spend while making sure those libraries get their books on time. We__l use x_11 and x_12 to track shipments from W1 to C1 and C2, and x_21 and x_22 for shipments from W2. For the books going out to the libraries, y_11 and y_12 will handle the flow from C1 to L1 and L2, and y_21 and y_22 from C2. Variables are all positive integers.\n",
    "\n",
    "Thought: I need to determine the problem type of the text. The Query doesn't contain any descriptions like '.csv' and 'column'. I'll direcrly classify the problem type as 'Others without CSV'.\n",
    "\n",
    "Final Answer: Others without CSV\n",
    "\n",
    "\"\"\"\n",
    "prefix = f\"\"\"I am a helpful assistant that can answer Querys about operation problems. My response must align with one of the following categories: Network Revenue Management, Resource Allocation, Transportation, Facility Location Problem, SBLP, Others with CSV, and Others without CSV. Firstly you need to identify whether the text contains any descriptions like '.csv' and 'column'.\n",
    "\n",
    "Always remember! If the input does not contain any description like '.csv' and 'column', and the values for all the variables are given directly, I will directly classify the problem type as 'Others without CSV'. Like the example {few_shot_examples_without_csv}. \n",
    "\n",
    "However, if the text contains descriptions like '.csv' or 'column', and the values for all the variables are not given directly, I will use the following examples {few_shot_examples_csv} as a guide. And answer the Query by given the answer directly.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "\n",
    "Begin!\n",
    "\n",
    "Query: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "classification_agent = initialize_agent(\n",
    "    tools=[qa_tool],\n",
    "    llm=llm1,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    agent_kwargs={\n",
    "        \"prefix\": prefix,\n",
    "        \"suffix\": suffix,\n",
    "    },\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,  \n",
    ")\n",
    "openai.api_request_timeout = 60  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Scale OR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def retrieve_similar_docs(query,retriever):\n",
    "    \n",
    "    similar_docs = retriever.invoke(query)\n",
    "\n",
    "    results = []\n",
    "    for doc in similar_docs:\n",
    "        results.append({\n",
    "            \"content\": doc.page_content,\n",
    "            \"metadata\": doc.metadata\n",
    "        })\n",
    "    return results\n",
    "\n",
    "\n",
    "def process_dataset_address(dataset_address: str) -> List[Document]:\n",
    "\n",
    "    documents = []\n",
    "    file_addresses = dataset_address.strip().split('\\n')  \n",
    "    for file_idx, file_address in enumerate(file_addresses, start=1):\n",
    "        try:\n",
    "            df = pd.read_csv(file_address.strip())  \n",
    "            file_name = file_address.strip().split('/')[-1]  \n",
    "            for row_idx, row in df.iterrows():\n",
    "                page_content = \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "                documents.append(Document(page_content=page_content))\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_address}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def get_NRM_response(query,dataset_address):\n",
    "    retrieve='product'\n",
    "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_NRM2_MD.csv\", encoding=\"utf-8\")\n",
    "    data = loader.load()\n",
    "    documents = data\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors = FAISS.from_documents(documents, embeddings)\n",
    "    retriever = vectors.as_retriever(search_kwargs={'k': 1})\n",
    "    few_shot_examples = []\n",
    "\n",
    "    similar_results = retrieve_similar_docs(query,retriever)\n",
    "\n",
    "    for i, result in enumerate(similar_results, 1):\n",
    "        content = result['content']\n",
    "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
    "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip()  \n",
    "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
    "        data_address = split_at_address[0].strip()\n",
    "\n",
    "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
    "        label = split_at_label[0].strip()  \n",
    "        Related = split_at_label[1].strip()\n",
    "        information = pd.read_csv(data_address)\n",
    "        information_head = information[:36]\n",
    "\n",
    "        example_data_description = \"\\nHere is the product data:\\n\"\n",
    "        for i, r in information_head.iterrows():\n",
    "            example_data_description += f\"Product {i + 1}: {r['Product Name']}, revenue w_{i + 1} = {r['Revenue']}, demand rate a_{i + 1} = {r['Demand']}, initial inventory c_{i + 1} = {r['Initial Inventory']}\\n\"\n",
    "\n",
    "\n",
    "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        few_shot_examples.append(f\"\"\"\n",
    "\n",
    "Question: Based on the following problem description and data, please formulate a complete mathematical model using real data from retrieval. {problem_description}\n",
    "\n",
    "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Pay attention: 1. If the data to be retrieved is not specified, retrieve the whole dataset instead. 2. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. 3. The final expressions should not be simplified or abbreviated.\n",
    "\n",
    "Action: CSVQA\n",
    "\n",
    "Action Input: Retrieve all the {retrieve} data {Related} to formulate the mathematical model with no simplification or abbreviation. Retrieve the documents in order, row by row. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, retrieve all the data instead. Only present final answer in details of row, instead of giving a sheet format.\n",
    "\n",
    "Observation: {example_data_description}\n",
    "\n",
    "Thought: Now that I have the necessary data, construct the objective function and constraints using the retrieved data as parameters of the formula. Ensure to include any additional detailed constraints present in the problem description. Always pay attention to the variable type. If not mentioned, use nonnegative integer. Do NOT include any explanations, notes, or extra text. Format the expressions strictly in markdown ONLY in this exact format: {label}. Following this example. The expressions should not be simplified or abbreviated. Besides, I need to use the $$ or $ to wrap the mathematical expressions instead of \\[, \\], \\( or \\). I also should avoid using align, align* and other latex environments. Besides, I should also avoid using \\begin, \\end, \\text.\n",
    "\n",
    "Final Answer: \n",
    "{label}\n",
    "\"\"\")\n",
    "\n",
    "    data = []\n",
    "    dfs=[]\n",
    "\n",
    "    file_addresses = dataset_address.strip().split('\\n')\n",
    "    for file_address in file_addresses:\n",
    "        try:\n",
    "            df = pd.read_csv(file_address)  \n",
    "            file_name = file_address.split('/')[-1] \n",
    "            dfs.append((file_name, df))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_address}: {e}\")\n",
    "\n",
    "    for df_index, (file_name, df) in enumerate(dfs):\n",
    "        data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "        for i, r in df.iterrows():\n",
    "            description = \"\"\n",
    "            description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "            data.append(description + \"\\n\")\n",
    "    document=data\n",
    "   \n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors = FAISS.from_texts(document, embeddings)\n",
    "    retriever = vectors.as_retriever(search_kwargs={'k': 1000})\n",
    "    llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4.1', top_p=1,n = 1, openai_api_key=user_api_key)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Retrieve the documents in order, row by row. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, retrieve all the data instead. Only present final answer in details of row, instead of giving a sheet format.\"\n",
    "        \"Context: {context}\"\n",
    "    )\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    question_answer_chain = create_stuff_documents_chain(llm2, prompt)\n",
    "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "    def qa_wrapper(query: str):\n",
    "        return qa_chain.invoke({\"input\": query})['answer']\n",
    "    qa_tool = Tool(\n",
    "        name=\"CSVQA\",\n",
    "        func=qa_wrapper,\n",
    "        description=\"Use this tool to answer Querys based on the provided CSV data and retrieve product data similar to the input query.\"\n",
    "    )\n",
    "\n",
    "    prefix = f\"\"\"You are an assistant that generates a mathematical models based on the user's description and provided CSV data.\n",
    "\n",
    "    Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "    {few_shot_examples}\n",
    "\n",
    "    When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    suffix = \"\"\"\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    User Description: {input}\n",
    "    {agent_scratchpad}\"\"\"\n",
    "\n",
    "    agent2 = initialize_agent(\n",
    "        tools=[qa_tool],\n",
    "        llm=llm2,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        agent_kwargs={\n",
    "            \"prefix\": prefix,\n",
    "            \"suffix\": suffix,\n",
    "        },\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True,\n",
    "    )\n",
    "\n",
    "    result = agent2.invoke(query)\n",
    "\n",
    "    return result['output']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RA_response(query,dataset_address):\n",
    "\n",
    "    retrieve=\"product\"\n",
    "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_RA2_MD.csv\", encoding=\"utf-8\")\n",
    "    data = loader.load()\n",
    "    documents = data\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "    retriever = vectors.as_retriever(search_kwargs={'k': 3})\n",
    "    few_shot_examples = []\n",
    "    similar_results =  retrieve_similar_docs(query,retriever)\n",
    "    for i, result in enumerate(similar_results, 1):\n",
    "        content = result['content']\n",
    "\n",
    "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
    "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip() \n",
    "\n",
    "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
    "        data_address = split_at_address[0].strip()\n",
    "\n",
    "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
    "        label = split_at_label[0].strip()  \n",
    "        Related = split_at_label[1].strip()\n",
    "\n",
    "        datas=data_address.split()\n",
    "        information = []\n",
    "\n",
    "        for data in datas:\n",
    "            information.append(pd.read_csv(data))\n",
    "        example_data_description = \"\\nHere is the data:\\n\"\n",
    "        for df_index, df in enumerate(information):\n",
    "            if df_index == 0:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Capacity\\n\"\n",
    "            elif df_index == 1:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Products\\n\"\n",
    "\n",
    "            for z, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                example_data_description += description + \"\\n\"\n",
    "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        few_shot_examples.append( f\"\"\"\n",
    "Question: Based on the following problem description and data, please formulate a complete mathematical model using real data from retrieval. {problem_description}\n",
    "\n",
    "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Pay attention: 1. If the data to be retrieved is not specified, retrieve the whole dataset instead. 2. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. 3. The final expressions should not be simplified or abbreviated.\n",
    "\n",
    "Action: CSVQA\n",
    "\n",
    "Action Input: Retrieve all the {retrieve} data {Related} to formulate the mathematical model with no simplification or abbreviation. Retrieve the documents in order from top to bottom. Use the retrieved context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, retrieve all the data instead. Only present final answer in details of row, instead of giving a sheet format.\n",
    "\n",
    "Observation: {example_data_description}\n",
    "\n",
    "Thought: Now that I have the necessary data, I would construct the objective function and constraints using the retrieved data as parameters of the formula. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula according to the retrieved 'product id'. Do NOT include any explanations, notes, or extra text. Respond ONLY in this exact format: {label}. Following this example. The expressions should not be simplified or abbreviated. Besides, I need to use the $$ or $ to wrap the mathematical expressions instead of \\[, \\], \\( or \\). I also should avoid using align, align* and other latex environments. Besides, I should also avoid using \\begin, \\end, \\text.\n",
    "\n",
    "Final Answer: \n",
    "{label}\n",
    "\"\"\")\n",
    "\n",
    "    data = []\n",
    "    dfs=[]\n",
    "\n",
    "    file_addresses = dataset_address.strip().split('\\n')\n",
    "    for file_address in file_addresses:\n",
    "        try:\n",
    "            df = pd.read_csv(file_address) \n",
    "            file_name = file_address.split('/')[-1]  \n",
    "            dfs.append((file_name, df))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_address}: {e}\")\n",
    "\n",
    "    for df_index, (file_name, df) in enumerate(dfs):\n",
    "        data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "        if file_name=='products.csv' or file_name=='Products.csv':\n",
    "            for i, r in df.iterrows():\n",
    "                description = f\"Product id: {i+1}; \"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                data.append(description + \"\\n\")\n",
    "        else:\n",
    "            for i, r in df.iterrows():\n",
    "                description = f\"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                data.append(description + \"\\n\")\n",
    "\n",
    "    \n",
    "    documents = [content for content in data]\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors = FAISS.from_texts(documents, embeddings)\n",
    "    retriever = vectors.as_retriever(search_kwargs={'k': 220})\n",
    "    llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4.1',top_p=1,n = 1, openai_api_key=user_api_key)\n",
    "\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Retrieve the documents in order from top to bottom. Use the retrieved context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, retrieve all the data instead.\"\n",
    "        \"Context: {context}\"\n",
    "    )\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    question_answer_chain = create_stuff_documents_chain(llm2, prompt)\n",
    "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "    def qa_wrapper(query: str):\n",
    "        return qa_chain.invoke({\"input\": query})['answer']\n",
    "    qa_tool = Tool(\n",
    "        name=\"CSVQA\",\n",
    "        func=qa_wrapper,\n",
    "        description=\"Use this tool to answer Querys based on the provided CSV data and retrieve product data similar to the input query.\"\n",
    "    )\n",
    "\n",
    "    prefix = f\"\"\"You are an assistant that generates a mathematical models based on the user's description and provided CSV data.\n",
    "\n",
    "    Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "    {few_shot_examples}\n",
    "\n",
    "    When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    suffix = \"\"\"\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    User Description: {input}\n",
    "    {agent_scratchpad}\"\"\"\n",
    "\n",
    "    agent2 = initialize_agent(\n",
    "        tools=[qa_tool],\n",
    "        llm=llm2,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        agent_kwargs={\n",
    "            \"prefix\": prefix,\n",
    "            \"suffix\": suffix,\n",
    "        },\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True,\n",
    "    )\n",
    "\n",
    "    result = agent2.invoke(query)\n",
    "\n",
    "    return result['output']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TP_response(query,dataset_address):\n",
    "    retrieve=\"capacity data and products data, \"\n",
    "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_TP2_MD.csv\", encoding=\"utf-8\")\n",
    "    data = loader.load()\n",
    "    documents = data\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors = FAISS.from_documents(documents, embeddings)\n",
    "    retriever = vectors.as_retriever(search_kwargs={'k': 3})\n",
    "    few_shot_examples = []\n",
    "    similar_results = retrieve_similar_docs(query,retriever)\n",
    "    for i, result in enumerate(similar_results, 1):\n",
    "        content = result['content']\n",
    "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
    "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip()\n",
    "\n",
    "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
    "        data_address = split_at_address[0].strip()\n",
    "\n",
    "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
    "        label = split_at_label[0].strip()  \n",
    "        Related = split_at_label[1].strip()\n",
    "\n",
    "        datas=data_address.split()\n",
    "        information = []\n",
    "\n",
    "        for data in datas:\n",
    "            information.append(pd.read_csv(data))\n",
    "        example_data_description = \"\\nHere is the data:\\n\"\n",
    "        for df_index, df in enumerate(information):\n",
    "            if df_index == 0:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Customer Demand\\n\"\n",
    "            elif df_index == 1:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Supply Capacity\\n\"\n",
    "            elif df_index == 2:\n",
    "                example_data_description += f\"\\nDataFrame {df_index + 1} - Transportation Cost\\n\"\n",
    "\n",
    "            for z, r in df.iterrows():\n",
    "                description = \"\"\n",
    "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "                example_data_description += description + \"\\n\"\n",
    "            retrieve += ', '.join(df.columns)+', '\n",
    "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        few_shot_examples.append( f\"\"\"\n",
    "Question: Based on the following problem description and data, please formulate a complete mathematical model using real data from retrieval. {problem_description}\n",
    "\n",
    "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Pay attention: 1. If the data to be retrieved is not specified, retrieve the whole dataset instead. 2. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. 3. The final expressions should not be simplified or abbreviated.\n",
    "\n",
    "Action: CSVQA\n",
    "\n",
    "Action Input: Retrieve all the {retrieve} data {Related} to formulate the mathematical model with no simplification or abbreviation. Retrieve the documents in order. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, make sure that all the data is retrieved. Only present final answer in details of row, instead of giving a sheet format.\n",
    "\n",
    "Observation: {example_data_description}\n",
    "\n",
    "Thought: Now that I have the necessary data, I would construct the objective function and constraints using the retrieved data as parameters of the formula. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. Do NOT include any explanations, notes, or extra text. Respond ONLY in this exact format: {label}. Following this example. The expressions should not be simplified or abbreviated. Besides, I need to use the $$ or $ to wrap the mathematical expressions instead of \\[, \\], \\( or \\). I also should avoid using align, align* and other latex environments. Besides, I should also avoid using \\begin, \\end, \\text.\n",
    "\n",
    "Final Answer: \n",
    "{label}\n",
    "\"\"\")\n",
    "    data = []\n",
    "    dfs=[]\n",
    "\n",
    "    file_addresses = dataset_address.strip().split('\\n')\n",
    "    for file_address in file_addresses:\n",
    "        try:\n",
    "            df = pd.read_csv(file_address) \n",
    "            file_name = file_address.split('/')[-1] \n",
    "            dfs.append((file_name, df))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_address}: {e}\")\n",
    "\n",
    "    for df_index, (file_name, df) in enumerate(dfs):\n",
    "        data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
    "\n",
    "        for i, r in df.iterrows():\n",
    "            description = \"\"\n",
    "            description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
    "            data.append(description + \"\\n\")\n",
    "\n",
    "    print(data)\n",
    "\n",
    "    documents = [content for content in data]\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors = FAISS.from_texts(documents, embeddings)\n",
    "\n",
    "    retriever = vectors.as_retriever(search_kwargs={'k': 300})\n",
    "\n",
    "    llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4.1', top_p=1,n = 1,openai_api_key=user_api_key)\n",
    "\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Retrieve the documents in order. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, make sure that all the data is retrieved.\"\n",
    "        \"Context: {context}\"\n",
    "    )\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    question_answer_chain = create_stuff_documents_chain(llm2, prompt)\n",
    "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "    def qa_wrapper(query: str):\n",
    "        return qa_chain.invoke({\"input\": query})['answer']\n",
    "    qa_tool = Tool(\n",
    "        name=\"CSVQA\",\n",
    "        func=qa_wrapper,\n",
    "        description=\"Use this tool to answer Querys based on the provided CSV data and retrieve product data similar to the input query.\"\n",
    "    )\n",
    "\n",
    "    prefix = f\"\"\"You are an assistant that generates a mathematical models based on the user's description and provided CSV data.\n",
    "\n",
    "    Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "    {few_shot_examples}\n",
    "\n",
    "    When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    suffix = \"\"\"\n",
    "\n",
    "    Begin!\n",
    "\n",
    "    User Description: {input}\n",
    "    {agent_scratchpad}\"\"\"\n",
    "\n",
    "    agent2 = initialize_agent(\n",
    "        tools=[qa_tool],\n",
    "        llm=llm2,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        agent_kwargs={\n",
    "            \"prefix\": prefix,\n",
    "            \"suffix\": suffix,\n",
    "        },\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True,\n",
    "    )\n",
    "\n",
    "    result = agent2.invoke(query)\n",
    "\n",
    "    return result['output']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AP_response(query,dataset_address):\n",
    "    retrieve=''\n",
    "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_AP2_MD.csv\", encoding=\"utf-8\")\n",
    "    data = loader.load()\n",
    "\n",
    "    documents = data\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors = FAISS.from_documents(documents, embeddings)\n",
    "    retriever = vectors.as_retriever(max_tokens_limit=400,search_kwargs={'k': 1})\n",
    "    few_shot_examples = []\n",
    "    similar_results =  retrieve_similar_docs(query,retriever)\n",
    "    for i, result in enumerate(similar_results, 1):\n",
    "        content = result['content']\n",
    "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
    "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip() \n",
    "\n",
    "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
    "        data_address = split_at_address[0].strip()\n",
    "\n",
    "        file_addresses = data_address.strip().split('\\n')\n",
    "        dfs = []\n",
    "        df_index = 0\n",
    "        example_data_description = \" \"\n",
    "        for file_address in file_addresses:\n",
    "            try:\n",
    "                df = pd.read_csv(file_address) \n",
    "                file_name = file_address.split('/')[-1]  \n",
    "                matrix = df.iloc[:,1:].values\n",
    "                example_data_description +=\"C=\" + np.array_str(matrix)+ \".\"\n",
    "                dfs.append((file_name, df))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_address}: {e}\")\n",
    "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
    "        label = split_at_label[0].strip() \n",
    "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        Related=''\n",
    "        few_shot_examples.append( f\"\"\"\n",
    "Question: Based on the following problem description and data, please formulate a complete mathematical model using real data from retrieval. {problem_description}\n",
    "\n",
    "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Pay attention: 1. If the data to be retrieved is not specified, retrieve the whole dataset instead. 2. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. 3. The final expressions should not be simplified or abbreviated.\n",
    "\n",
    "Action: CSVQA\n",
    "\n",
    "Action Input: Retrieve all the {retrieve} data {Related} to formulate the mathematical model with no simplification or abbreviation. Retrieve the documents in order. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, make sure that all the data is retrieved. Only present final answer in details of row, instead of giving a sheet format.\n",
    "\n",
    "Observation: {example_data_description}\n",
    "\n",
    "Thought: Now that I have the necessary data, I would construct the objective function and constraints using the retrieved data as parameters of the formula. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula according to the retrieved 'product id'. Do NOT include any explanations, notes, or extra text. Respond ONLY in this exact format: {label}. Following this example. The expressions should not be simplified or abbreviated. Besides, I need to use the $$ or $ to wrap the mathematical expressions instead of \\[, \\], \\( or \\). I also should avoid using align, align* and other latex environments. Besides, I should also avoid using \\begin, \\end, \\text.\n",
    "\n",
    "Final Answer: \n",
    "{label}\n",
    "\"\"\")\n",
    "        \n",
    "    data = []\n",
    "    dfs=[]\n",
    "    file_addresses = dataset_address.strip().split('\\n')\n",
    "    df_index = 0\n",
    "    data_description = \" \"\n",
    "    for file_address in file_addresses:\n",
    "        try:\n",
    "            df = pd.read_csv(file_address) \n",
    "            file_name = file_address.split('/')[-1] \n",
    "            matrix = df.iloc[:,1:].values\n",
    "            data_description +=\"C=\" + np.array_str(matrix)+ \".\"\n",
    "            dfs.append((file_name, df))\n",
    "            df_index += 1\n",
    "            dfs.append((file_name, df))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_address}: {e}\")\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors = FAISS.from_texts([data_description], embeddings)\n",
    "\n",
    "    retriever = vectors.as_retriever(max_tokens_limit=400, search_kwargs={'k': 1}) \n",
    "    llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4.1', top_p=1,n = 1,openai_api_key=user_api_key)\n",
    "\n",
    "    system_prompt = (\n",
    "        \"Retrieve the documents in order from top to bottom. Use the retrieved context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, retrieve all the data instead.\"\n",
    "        \"Context: {context}\"\n",
    "    )\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    question_answer_chain = create_stuff_documents_chain(llm2, prompt)\n",
    "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "    def qa_wrapper(query: str):\n",
    "        return qa_chain.invoke({\"input\": query})['answer']\n",
    "    qa_tool = Tool(\n",
    "        name=\"CSVQA\",\n",
    "        func=qa_wrapper,\n",
    "        description=\"Use this tool to answer Querys based on the provided CSV data and retrieve product data similar to the input query.\"\n",
    "    )\n",
    "\n",
    "    prefix = f\"\"\"You are an assistant that generates a mathematical model based on the user's description and provided CSV data.\n",
    "\n",
    "            Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "            {few_shot_examples}\n",
    "\n",
    "            Note: Please retrieve all neccessary information from the CSV file to generate the answer. When you generate the answer, please output required parameters in a whole text, including all vectors and matrices.\n",
    "\n",
    "            When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "    suffix = \"\"\"\n",
    "\n",
    "            Begin!\n",
    "\n",
    "            User Description: {input}\n",
    "            {agent_scratchpad}\"\"\"\n",
    "\n",
    "    agent2 = initialize_agent(\n",
    "        tools=[qa_tool],\n",
    "        llm=llm2,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        agent_kwargs={\n",
    "            \"prefix\": prefix,\n",
    "            \"suffix\": suffix,\n",
    "        },\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "\n",
    "    result = agent2.invoke(query)\n",
    "    output = result['output']\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_FLP_response(query,dataset_address):\n",
    "    retrieve='supplier'\n",
    "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_FLP2_MD.csv\", encoding=\"utf-8\")\n",
    "    data = loader.load()\n",
    "\n",
    "    documents = data\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors = FAISS.from_documents(documents, embeddings)\n",
    "    retriever = vectors.as_retriever(max_tokens_limit=400,search_kwargs={'k': 1})\n",
    "    few_shot_examples = []\n",
    "    similar_results =  retrieve_similar_docs(query,retriever)\n",
    "    for i, result in enumerate(similar_results, 1):\n",
    "        content = result['content']\n",
    "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
    "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip() \n",
    "\n",
    "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
    "        data_address = split_at_address[0].strip()\n",
    "\n",
    "        file_addresses = data_address.strip().split('\\n')\n",
    "        dfs = []\n",
    "        df_index = 0\n",
    "        example_data_description = \" \"\n",
    "        for file_address in file_addresses:\n",
    "            try:\n",
    "                df = pd.read_csv(file_address) \n",
    "                file_name = file_address.split('/')[-1]  \n",
    "                if 'demand' in df.columns:\n",
    "                    result = df['demand'].values.tolist()\n",
    "                    example_data_description += \"d=\" + str(result) + \"\\n\"\n",
    "                elif 'fixed_costs' in df.columns:\n",
    "                    result = df['fixed_costs'].values.tolist()\n",
    "                    example_data_description +=\"c=\" + str(result) + \"\\n\"\n",
    "                elif df_index == 2:\n",
    "                    matrix = df.iloc[:,1:].values\n",
    "                    example_data_description +=\"A=\" + np.array_str(matrix)+ \".\"\n",
    "                else:\n",
    "                    for row_idx, row in df.iterrows():\n",
    "                        example_data_description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "                df_index += 1\n",
    "                dfs.append((file_name, df))\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading file {file_address}: {e}\")\n",
    "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
    "        label = split_at_label[0].strip() \n",
    "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        Related=''\n",
    "\n",
    "        few_shot_examples.append( f\"\"\"\n",
    "Question: Based on the following problem description and data, please formulate a complete mathematical model using real data from retrieval. {problem_description}\n",
    "\n",
    "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Pay attention: 1. If the data to be retrieved is not specified, retrieve the whole dataset instead. 2. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. 3. The final expressions should not be simplified or abbreviated.\n",
    "\n",
    "Action: CSVQA\n",
    "\n",
    "Action Input: Retrieve all the {retrieve} data {Related} to formulate the mathematical model with no simplification or abbreviation. Retrieve the documents in order. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, make sure that all the data is retrieved. Only present final answer in details of row, instead of giving a sheet format.\n",
    "\n",
    "Observation: {example_data_description}\n",
    "\n",
    "Thought: Now that I have the necessary data, I would construct the objective function and constraints using the retrieved data as parameters of the formula. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. Do NOT include any explanations, notes, or extra text. Respond ONLY in this exact format: {label}. Following this example. The expressions should not be simplified or abbreviated. Besides, I need to use the $$ or $ to wrap the mathematical expressions instead of \\[, \\], \\( or \\). I also should avoid using align, align* and other latex environments. Besides, I should also avoid using \\begin, \\end, \\text.\n",
    "\n",
    "Final Answer: \n",
    "{label}\n",
    "\"\"\")\n",
    "\n",
    "    data = []\n",
    "    dfs=[]\n",
    "    file_addresses = dataset_address.strip().split('\\n')\n",
    "    df_index = 0\n",
    "    data_description = \" \"\n",
    "    for file_address in file_addresses:\n",
    "        try:\n",
    "            df = pd.read_csv(file_address) \n",
    "            file_name = file_address.split('/')[-1] \n",
    "            if 'demand' in df.columns:\n",
    "                result = df['demand'].values.tolist()\n",
    "                data_description += \"d=\" + str(result) + \"\\n\"\n",
    "            elif 'fixed_costs' in df.columns:\n",
    "                result = df['fixed_costs'].values.tolist()\n",
    "                data_description +=\"c=\" + str(result) + \"\\n\"\n",
    "            elif df_index == 2:\n",
    "                matrix = df.iloc[:,1:].values\n",
    "                data_description +=\"A=\" + np.array_str(matrix)+ \".\"\n",
    "            else:\n",
    "                for row_idx, row in df.iterrows():\n",
    "                    data_description += \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
    "            df_index += 1\n",
    "            dfs.append((file_name, df))\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file_address}: {e}\")\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors = FAISS.from_texts([data_description], embeddings)\n",
    "\n",
    "    retriever = vectors.as_retriever(max_tokens_limit=400, search_kwargs={'k': 1}) \n",
    "    llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4.1', top_p=1,n = 1, openai_api_key=user_api_key)\n",
    "    \n",
    "    system_prompt = (\n",
    "        \"Retrieve the documents in order. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, make sure that all the data is retrieved.\"\n",
    "        \"Context: {context}\"\n",
    "    )\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "    question_answer_chain = create_stuff_documents_chain(llm2, prompt)\n",
    "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "    def qa_wrapper(query: str):\n",
    "        return qa_chain.invoke({\"input\": query})['answer']\n",
    "    qa_tool = Tool(\n",
    "        name=\"CSVQA\",\n",
    "        func=qa_wrapper,\n",
    "        description=\"Use this tool to answer Querys based on the provided CSV data and retrieve product data similar to the input query.\"\n",
    "    )\n",
    "\n",
    "    prefix = f\"\"\"You are an assistant that generates a mathematical model based on the user's description and provided CSV data.\n",
    "\n",
    "            Please refer to the following example and generate the answer in the same format:\n",
    "\n",
    "            {few_shot_examples}\n",
    "\n",
    "            Note: Please retrieve all neccessary information from the CSV file to generate the answer. When you generate the answer, please output required parameters in a whole text, including all vectors and matrices.\n",
    "\n",
    "            When you need to retrieve information from the CSV file, use the provided tool.\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "    suffix = \"\"\"\n",
    "            Begin!\n",
    "\n",
    "            User Description: {input}\n",
    "            {agent_scratchpad}\"\"\"\n",
    "\n",
    "    agent2 = initialize_agent(\n",
    "        tools=[qa_tool],\n",
    "        llm=llm2,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        agent_kwargs={\n",
    "            \"prefix\": prefix,\n",
    "            \"suffix\": suffix,\n",
    "        },\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "\n",
    "    result = agent2.invoke(query)\n",
    "    output = result['output']\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Others With CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from typing import Union\n",
    "from langchain_classic.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "def escape_braces(text: str) -> str:\n",
    "    return text.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "\n",
    "OTHERS_RAG_PATH = \"Large_Scale_Or_Files/RAG_Example_Others.csv\"\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "Others_docs = CSVLoader(file_path=OTHERS_RAG_PATH, encoding=\"utf-8\").load()\n",
    "Others_store: FAISS = FAISS.from_documents(Others_docs, embeddings)\n",
    "\n",
    "\n",
    "def retrieve_examples(store, query: str, k: int = 1):\n",
    "    return store.as_retriever(search_kwargs={\"k\": k}).invoke(query)\n",
    "\n",
    "def build_few_shot_Other(store, user_query: str, k: int = 1, t='Model'):\n",
    "    \"\"\"\n",
    "    (From your code)\n",
    "    Build few-shot block.\n",
    "    [IMPORTANT]: This function assumes your CSV example file (RAG_Example_Others.csv)\n",
    "    has 'prompt', 'Data_address', 'Label', and 'Label_Code' columns.\n",
    "    You must update your CSV file to match this structure.\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    # retrieve k most-similar reference examples\n",
    "    for doc in retrieve_examples(store, user_query, k=k):\n",
    "        txt = doc.page_content\n",
    "        \n",
    "        try:\n",
    "            if \"prompt:\" not in txt:\n",
    "                parts = re.split(r'(Data_address:|Label:|Label_Code:)', txt, flags=re.IGNORECASE)\n",
    "                prompt_part = parts[0].replace(\"prompt:\", \"\").strip()\n",
    "                data_addr = parts[2].strip()\n",
    "                label_model = parts[4].strip()\n",
    "                label_code = parts[6].strip()\n",
    "                \n",
    "            else:\n",
    "                prompt_part = txt.split(\"Data_address:\")[0].replace(\"prompt:\", \"\").strip()\n",
    "                data_addr = txt.split(\"Data_address:\")[1].split(\"Label:\")[0].strip()\n",
    "                label_model = txt.split(\"Label:\")[1].split(\"Label_Code:\")[0].strip()\n",
    "                label_code = txt.split(\"Label_Code:\")[1].split(\"Related:\")[0].strip() # Assuming \"Related:\" is last\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[build_few_shot_Other Error] Failed to parse example: {e}. Content: {txt[:50]}\")\n",
    "            continue\n",
    "\n",
    "        data_blocks = []\n",
    "        for fp in map(str.strip, data_addr.splitlines()):\n",
    "            if not fp:\n",
    "                continue\n",
    "            try:\n",
    "                header = f\"[{os.path.basename(fp)} | (Example Schema)]\"\n",
    "                rows = \"col1, col2, col3\\n1, 2, 3\\n4, 5, 6\" # Placeholder schema\n",
    "                data_blocks.append(header + \"\\n\" + rows)\n",
    "            except Exception as e:\n",
    "                data_blocks.append(f\"[Could not read example data {fp}: {e}]\")\n",
    "\n",
    "        data_section = \"\\n\".join(data_blocks) if data_blocks else \"[No data found]\"\n",
    "        if t == 'Model':\n",
    "            label_part = label_model\n",
    "            ex = (\n",
    "                \"<EXAMPLE>\\n\"\n",
    "                f\"Question: {prompt_part}\\n\"\n",
    "                \"Thought: I need to create an Abstract Model Plan based on the user's query and the CSV Schema (data structure)\\n\"\n",
    "                \"Final Answer:\\n\"\n",
    "                f\"{label_part}\\n\"\n",
    "                \"</EXAMPLE>\"\n",
    "            )\n",
    "            examples.append(escape_braces(ex))\n",
    "        else:\n",
    "            label_part = label_code\n",
    "            ex = (\n",
    "                \"<EXAMPLE>\\n\"\n",
    "                f\"Question: {prompt_part}\\n\"\n",
    "                \"Thought: I need to generate a single, complete, executable Gurobi Python code block.\\n\"\n",
    "                \"Final Answer:\\n\"\n",
    "                f\"{label_part}\\n\"\n",
    "                \"</EXAMPLE>\"\n",
    "            )\n",
    "            examples.append(escape_braces(ex))\n",
    "        new_example = escape_braces(ex)\n",
    "        print(f\"[build_few_shot_Other] Added example for prompt: {new_example}...\")\n",
    "\n",
    "    return \"\\n\\n\".join(examples)\n",
    "\n",
    "\n",
    "\n",
    "def get_csv_schema(file_paths_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Receives a string with one or more file paths,\n",
    "    parses the paths, and returns the schema for all files.\n",
    "    \"\"\"\n",
    "    paths = re.split(r'[\\s\\n]+', file_paths_string)\n",
    "    all_schema_info = []\n",
    "    for path in paths:\n",
    "        if not path.strip(): continue\n",
    "        try:\n",
    "            try:\n",
    "                df = pd.read_csv(path, nrows=10, encoding='utf-8')\n",
    "            except UnicodeDecodeError:\n",
    "                df = pd.read_csv(path, nrows=10, encoding='gbk')\n",
    "            \n",
    "            schema_info = (\n",
    "                f\"Successfully read first 10 rows from {path}.\\n\"\n",
    "                f\"Columns: {df.columns.to_list()}\\n\\n\"\n",
    "                f\"Data Head:\\n{df.to_string()}\"\n",
    "            )\n",
    "            all_schema_info.append(schema_info)\n",
    "        except Exception as e:\n",
    "            error_info = (\n",
    "                f\"Error reading CSV at {path}: {e}. \"\n",
    "                \"You must formulate the model/code based on the file path and assumed column names.\"\n",
    "            )\n",
    "            all_schema_info.append(error_info)\n",
    "    if not all_schema_info:\n",
    "        return \"Error: No valid file paths were provided.\"\n",
    "    return \"\\n\\n---\\n\\n\".join(all_schema_info)\n",
    "\n",
    "def get_Others_response(user_query: str, dataset_address: str) -> str:\n",
    "    llm2 = ChatOpenAI(\n",
    "    temperature=0.0, model_name=\"gpt-4.1\", openai_api_key=user_api_key\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        print(\"\\n[Gurobi Pipeline Step 1/3]: Getting CSV Scheme...\")\n",
    "\n",
    "        schema = get_csv_schema(dataset_address)        \n",
    "        print(\"\\n[Gurobi Pipeline Step 2/3]: Constructing Abstract Model...\")\n",
    "\n",
    "        few_shot_block_abstract = build_few_shot_Other(Others_store, user_query, k=3, t='Model')\n",
    "        print(f\"[Few-Shot Abstract Examples]:\\n{few_shot_block_abstract}...\")\n",
    "        \n",
    "        abstract_model_template = \"\"\"\n",
    "You are an expert optimization modeler.\n",
    "Your task is to create an \"Abstract Model Plan\" based on the user's query and the CSV Schema (data structure).\n",
    "This plan is *not* Gurobi code or mathematical formulas, but a clear, step-by-step reasoning process in English.\n",
    "\n",
    "[Examples]\n",
    "{few_shot_examples}\n",
    "\n",
    "[Current Task]\n",
    "User Query: {query}\n",
    "\n",
    "CSV Schema:\n",
    "{schema}\n",
    "\n",
    "[Your Output]\n",
    "You must strictly follow this format for your \"Abstract Model Plan\" output:\n",
    "\n",
    "[Abstract Model Plan START]\n",
    "1.  **Analyze Query:** The user wants to {{{{Your analysis}}}}.\n",
    "2.  **Identify Model Type:** Based on the query, this is a {{{{e.g., LP, MIP, Fixed-Charge, Blending}}}} problem.\n",
    "3.  **Define Index Sets:** The primary indices are {{{{e.g., Products, Workers, Sources, Destinations}}}}.\n",
    "4.  **Define Decision Variables:**\n",
    "    -   `x[i]` = {{{{Describe first variable, e.g., 'quantity of product i'}}}}. Type: {{{{GRB.CONTINUOUS / GRB.INTEGER}}}}.\n",
    "    -   `y[i]` = {{{{Describe second variable, e.g., 'if product i is produced'}}}}. Type: {{{{GRB.BINARY}}}}.\n",
    "5.  **Identify Parameters (from Schema):**\n",
    "    -   Objective coefficients (e.g., profit) will come from column(s): {{{{e.g., 'Price', 'Production Cost'}}}}.\n",
    "    -   Constraint coefficients (e.g., resource use) will come from: {{{{e.g., 'Resource 1', 'Available Time'}}}}.\n",
    "    -   Constraint RHS (limits) will come from: {{{{e.g., 'Max Demand'}}}}.\n",
    "6.  **Formulate Objective:** {{{{Describe objective, e.g., 'Maximize sum((schema['Price'] - schema['Cost']) * x[i] - schema['FixedCost'] * y[i])'}}}}.\n",
    "7.  **Formulate Constraints:**\n",
    "    -   Constraint 1 (e.g., Resource Limit): {{{{Describe constraint 1, e.g., 'sum(schema['Resource 1'][i] * x[i]) <= schema['Available']'}}}}.\n",
    "    -   Constraint 2 (e.g., Linking): {{{{Describe constraint 2, e.g., 'x[i] <= M * y[i])'}}}}.\n",
    "    -   ... (Other constraints) ...\n",
    "[Abstract Model Plan END]\n",
    "\"\"\"\n",
    "        abstract_prompt = PromptTemplate(\n",
    "            template=abstract_model_template,\n",
    "            input_variables=[\"query\", \"schema\", \"few_shot_examples\"]\n",
    "        )\n",
    "        \n",
    "        abstract_model_chain = LLMChain(llm=llm2, prompt=abstract_prompt)\n",
    "        \n",
    "        abstract_model_plan = abstract_model_chain.run(\n",
    "            query=user_query,\n",
    "            schema=schema,\n",
    "            few_shot_examples=few_shot_block_abstract\n",
    "        )\n",
    "        print(f\"[Observation]:\\n{abstract_model_plan}\")\n",
    "        \n",
    "        print(\"\\n[Gurobi Pipeline Step 3/3]: Generating Gurobi Code...\")\n",
    "        \n",
    "        few_shot_block_code = build_few_shot_Other(Others_store, user_query, k=3, t='Code')\n",
    "        \n",
    "        code_gen_template = \"\"\"\n",
    "You are an expert Gurobi programmer.\n",
    "Your task is to strictly follow the User Query, CSV Schema, and \"Abstract Model Plan\" to translate them into a single, complete, executable Gurobi Python code block.\n",
    "The code must start with ```python and end with ```.\n",
    "The code must include all necessary imports (`gurobipy`, `pandas`, `numpy`, `sys`, `re`).\n",
    "The code must include a `try...except` block to handle errors.\n",
    "The code must robustly read '{dataset_address}' (if it's multiple paths, read the first).\n",
    "The code must *fully* implement all variables, objectives, and constraints from the \"Abstract Model Plan\".\n",
    "\n",
    "[Examples of the Full Process]\n",
    "{few_shot_examples}\n",
    "\n",
    "[User Query]\n",
    "{query}\n",
    "\n",
    "[CSV Schema]\n",
    "{schema}\n",
    "\n",
    "[Abstract Model Plan]\n",
    "{abstract_plan}\n",
    "\n",
    "[Your Gurobi Code]\n",
    "\"\"\"\n",
    "\n",
    "        code_gen_prompt = PromptTemplate(\n",
    "            template=code_gen_template,\n",
    "            input_variables=[\"query\", \"schema\", \"abstract_plan\", \"dataset_address\", \"few_shot_examples\"]\n",
    "        )\n",
    "        \n",
    "        code_gen_chain = LLMChain(llm=llm2, prompt=code_gen_prompt)\n",
    "        \n",
    "        final_code = code_gen_chain.run(\n",
    "            query=user_query,\n",
    "            schema=schema,\n",
    "            abstract_plan=abstract_model_plan,\n",
    "            dataset_address=dataset_address,\n",
    "            few_shot_examples=few_shot_block_code \n",
    "        )\n",
    "        \n",
    "        if \"```python\" in final_code:\n",
    "            code_block = final_code.split(\"```python\", 1)[1]\n",
    "            if \"```\" in code_block:\n",
    "                code_block = code_block.split(\"```\", 1)[0]\n",
    "            final_answer = \"```python\\n\" + code_block.strip() + \"\\n```\"\n",
    "        else:\n",
    "            if not final_code.strip().startswith(\"import\"):\n",
    "                print(f\"[Warning] Step 3 output was not a valid code block. Output: {final_code[:200]}...\")\n",
    "                final_answer = f\"Error: Code generation failed. LLM returned non-code output:\\n{final_code}\"\n",
    "            else:\n",
    "                print(\"[Warning] Step 3 output missed ```python tag, adding it.\")\n",
    "                final_answer = \"```python\\n\" + final_code.strip() + \"\\n```\"\n",
    "            \n",
    "        print(f\"[Final Answer]:\\n{final_answer}\")\n",
    "        return final_answer\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Gurobi Pipeline Error]: {e}\")\n",
    "        return f\"Error: The Gurobi Code Generation pipeline failed with error: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Others Without CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_others_without_CSV_response(query):\n",
    "    llm = ChatOpenAI(\n",
    "                    temperature=0.0, model_name=\"gpt-4.1\", top_p=1, n = 1, openai_api_key=user_api_key\n",
    "                )\n",
    "\n",
    "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_Others_Without_CSV.csv\", encoding=\"utf-8\")\n",
    "    data = loader.load()\n",
    "\n",
    "    documents = data\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
    "    vectors = FAISS.from_documents(documents, embeddings)\n",
    "\n",
    "    retriever = vectors.as_retriever(search_kwargs={'k': 5})\n",
    "\n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "    )\n",
    "\n",
    "    qa_tool = Tool(\n",
    "        name=\"ORLM_QA\",\n",
    "        func=qa_chain.invoke,\n",
    "        description=(\n",
    "            \"Use this tool to answer Querys.\"\n",
    "            \"Provide the Query as input, and the tool will retrieve the relevant information from the file and use it to answer the Query.\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    few_shot_examples = []\n",
    "    similar_results = retrieve_similar_docs(query,retriever)\n",
    "\n",
    "    for i, result in enumerate(similar_results, 1):\n",
    "        content = result['content']\n",
    "\n",
    "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
    "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip()\n",
    "\n",
    "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
    "        data_address = split_at_address[0].strip()\n",
    "\n",
    "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
    "        label = split_at_label[0].strip() \n",
    "\n",
    "        split_at_type = split_at_address[1].split(\"problem type:\", 1)\n",
    "        Related = split_at_type[0].strip() \n",
    "\n",
    "        selected_problem = split_at_type[1].strip()\n",
    "\n",
    "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "\n",
    "\n",
    "\n",
    "        example = (\n",
    "            \"<EXAMPLE>\\n\"\n",
    "            f\"Question: {problem_description}\\n\\n\"\n",
    "            \"Thought: Read the question and 1) identify the goal (minimize time/cost/crew or maximize throughput/value) and collect per-unit coefficients; 2) define decision variables and pick domains: counts of trips/units/vehicles are nonnegative integers, yes or no choices are binary, divisible flows or weights are nonnegative reals; 3) write the linear objective from the coefficients; 4) add constraints in this order: demand or target (exactly, at least, at most), capacity or supply upper bounds, flow conservation or stage linking across nodes or arcs, and any share or ratio limits rewritten as linear inequalities using the given per-unit rates, plus any minimum or maximum usage; 5) add nonnegativity and the chosen integrality or binary domains; 6) output only the LP: objective first, then constraints line by line with brief labels if needed, then a final line stating the variable domains.\"\n",
    "            \"Final Answer:\\n\"\n",
    "            f\"{label}\\n\"\n",
    "            \"</EXAMPLE>\"\n",
    "        )\n",
    "\n",
    "\n",
    "        example = example.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
    "        few_shot_examples.append(example)\n",
    "#         few_shot_examples.append( \"\"\"\n",
    "# Example (INTEGER trigger):\n",
    "# Question: A factory can run two machine types. How many of each machine should be installed given budget and space limits? Maximize output.\n",
    "# Final Answer: \n",
    "# $\\\\max\\\\; p_1 x_1 + p_2 x_2$\n",
    "# $\\\\text{{s.t. }} a_1 x_1 + a_2 x_2 \\\\le B,\\\\; s_1 x_1 + s_2 x_2 \\\\le S$\n",
    "# $x_1, x_2 \\\\in \\\\mathbb{{Z}}_+.$\n",
    "\n",
    "# Example (MULTI-PERIOD FLOW trigger):\n",
    "# Question: Multi-period production with inventory and backorders. Costs for production/holding/backorder. Initial and terminal conditions given.\n",
    "# Final Answer:\n",
    "# \\textbf{{Indices: }} t\\in T=\\{{1,\\dots,n\\}}. \\\\\n",
    "# \\textbf{{Given: }} d_t,\\ I_0,\\ B_0,\\ \\dots \\\\\n",
    "# \\textbf{{Vars: }} x_t\\ge0,\\ I_t\\ge0,\\ B_t\\ge0. \\\\\n",
    "# \\min \\sum_t (c x_t + h I_t + p B_t) \\\\\n",
    "# \\text{{s.t. }} I_t - B_t = I_{{t-1}} - B_{{t-1}} + x_t - d_t,\\ \\forall t \\\\\n",
    "# I_n \\ge I^{{\\min}},\\ B_n=0.\n",
    "\n",
    "# Example (LOGIC+BINARY trigger):\n",
    "# Question: Choose exactly one option from set P and at least K items from set V, with quantities and budget.\n",
    "# Final Answer:\n",
    "# \\textbf{{Sets: }} i\\in P,\\ j\\in V. \\ \\textbf{{Vars: }} q_i,q_j\\ge0;\\ y_i\\in\\{{0,1\\}}, z_j\\in\\{{0,1\\}}.\\\\\n",
    "# \\max \\sum_j f_j q_j \\\\\n",
    "# \\text{{s.t. }} \\sum_i y_i = 1,\\ \\sum_j z_j \\ge K \\\\\n",
    "# 0\\le q_i \\le M_i y_i,\\ \\forall i;\\ \\ 0\\le q_j \\le M_j z_j,\\ \\forall j \\\\\n",
    "# \\text{{Budget: }} \\sum_i c_i q_i + \\sum_j c_j q_j \\le B.\n",
    "# \"\"\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    prefix = (\n",
    "    f\"{few_shot_examples}\\n\\n\"\n",
    "    \"\"\" \n",
    "    Use the following triggers to identify problem structures and apply the corresponding mathematical formulations.\n",
    "    (1) INTEGER trigger:\n",
    "    Question: A factory can run two machine types. How many of each machine should be installed given budget and space limits? Maximize output.\n",
    "    Final Answer: \n",
    "    $\\\\max\\\\; p_1 x_1 + p_2 x_2$\n",
    "    $\\\\text{{s.t. }} a_1 x_1 + a_2 x_2 \\\\le B,\\\\; s_1 x_1 + s_2 x_2 \\\\le S$\n",
    "    $x_1, x_2 \\\\in \\\\mathbb{{Z}}_+.$\n",
    "    (2) MULTI-PERIOD FLOW trigger:\n",
    "    Question: Multi-period production with inventory and backorders. Costs for production/holding/backorder. Initial and terminal conditions given.\n",
    "    Final Answer:\n",
    "    \\textbf{{Indices: }} t\\in T=\\{{1,\\dots,n\\}}. \\\\\n",
    "    \\textbf{{Given: }} d_t,\\ I_0,\\ B_0,\\ \\dots \\\\\n",
    "    \\textbf{{Vars: }} x_t\\ge0,\\ I_t\\ge0,\\ B_t\\ge0. \\\\\n",
    "    \\min \\sum_t (c x_t + h I_t + p B_t) \\\\\n",
    "    \\text{{s.t. }} I_t - B_t = I_{{t-1}} - B_{{t-1}} + x_t - d_t,\\ \\forall t \\\\\n",
    "    I_n \\ge I^{{\\min}},\\ B_n=0.\n",
    "    (3) LOGIC+BINARY trigger:\n",
    "    Question: Choose exactly one option from set P and at least K items from set V, with quantities and budget.\n",
    "    Final Answer:\n",
    "    \\textbf{{Sets: }} i\\in P,\\ j\\in V. \\ \\textbf{{Vars: }} q_i,q_j\\ge0;\\ y_i\\in\\{{0,1\\}}, z_j\\in\\{{0,1\\}}.\\\\\n",
    "    \\max \\sum_j f_j q_j \\\\\n",
    "    \\text{{s.t. }} \\sum_i y_i = 1,\\ \\sum_j z_j \\ge K \\\\\n",
    "    0\\le q_i \\le M_i y_i,\\ \\forall i;\\ \\ 0\\le q_j \\le M_j z_j,\\ \\forall j \\\\\n",
    "    \\text{{Budget: }} \\sum_i c_i q_i + \\sum_j c_j q_j \\le B.\n",
    "    \"\"\"\n",
    "    \"USER QUESTION:\\n{input}\\n\\n\"\n",
    "    \"TASK:\\n\"\n",
    "    \"- Produce a complete LaTeX optimization model using ONLY information in the question.\\n\"\n",
    "    \"- Use a fixed structure INSIDE LaTeX: Indices/Sets; Given Parameters (convert all tables to arrays); Decision Variables (with domains); Objective; Constraints; Domain lines.\\n\"\n",
    "    \"- For multi-period problems, you MUST include state-balance recurrences and initial/terminal conditions explicitly.\\n\"\n",
    "    \"- Avoid nonlinear forms when possible: rewrite ratios/logic using linear constraints + binaries (big-M) with clearly defined M.\\n\\n\"\n",
    "    \"You should decide VARIABLE–TYPE first!\\n (If not mentioned or ambiguous, integer by default!)\"\n",
    "    \"### FIRST RESPONSE FORMAT (exactly 3 lines) ###\\n\"\n",
    "    \"Thought: <brief>\\n\"\n",
    "    \"Action: ORLM_QA\\n\"\n",
    "    \"Action Input: {input}\\n\\n\"\n",
    "    \"Begin.\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "    suffix = (\n",
    "    \"\\n### AFTER OBSERVATION ###\\n\"\n",
    "    \"Respond with exactly two lines:\\n\"\n",
    "    \"Thought: <variable types: integer/binary/continuous>\\n\"\n",
    "    \"Final Answer: <ONLY LaTeX model. Must include: (i) indices/sets, (ii) parameter definitions (tables->arrays), (iii) explicit domain lines for EVERY variable, (iv) initial/terminal conditions if any. No prose.>\\n\"\n",
    "    \"Do NOT output anything else.\"\n",
    ")\n",
    "\n",
    "\n",
    "    agent = initialize_agent(\n",
    "        tools=[qa_tool],\n",
    "        llm=llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        agent_kwargs={\n",
    "            \"prefix\": prefix,\n",
    "            \"suffix\": suffix,\n",
    "            \"input_variables\": [\"input\"]\n",
    "        },\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True,  # Enable error handling\n",
    "    )\n",
    "\n",
    "    openai.api_request_timeout = 60  \n",
    "    query = query.replace('{','{{').replace('}','}}')\n",
    "    output = agent.run({\"input\": query})\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(output,selected_problem):\n",
    "    llm_code = ChatOpenAI(\n",
    "        temperature=0.0, model_name=\"gpt-4.1\",top_p=1,n = 1, openai_api_key=user_api_key\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in mathematical optimization and Python programming. Your task is to write Python code to solve the provided mathematical optimization model using the Gurobi library. The code should include the definition of the objective function, constraints, and decision variables. Please don't add additional explanations. Please don't include ```python and ```.Below is the provided mathematical optimization model:\n",
    "\n",
    "    Mathematical Optimization Model:\n",
    "    {output}\n",
    "    \"\"\"\n",
    "\n",
    "    if selected_problem == \"Network Revenue Management\" or selected_problem == \"NRM\" or selected_problem == \"Network Revenue Management Problem\":\n",
    "\n",
    "        prompt += \"\"\"\n",
    "For example, here is a simple instance for reference:\n",
    "\n",
    "Mathematical Optimization Model:\n",
    "\n",
    "Objective Function:\n",
    "$\\quad \\quad \\max \\quad \\sum_i A_i \\cdot x_i$\n",
    "Constraints\n",
    "1. Inventory Constraints:\n",
    "$\\quad \\quad x_i \\leq I_i, \\quad \\forall i$\n",
    "2. Demand Constraints:\n",
    "$x_i \\leq d_i, \\quad \\forall i$\n",
    "3. Startup Constraint:\n",
    "$\\sum_i x_i \\geq s$\n",
    "Retrieved Information\n",
    "$\\small I = [7550, 6244]$\n",
    "$\\small A = [149, 389]$\n",
    "$\\small d = [15057, 12474]$\n",
    "$\\small s = 100$\n",
    "\n",
    "The corresponding Python code for this instance is as follows:\n",
    "\n",
    "```python\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Create the model\n",
    "m = gp.Model(\"Product_Optimization\")\n",
    "\n",
    "# Decision variables for the number of units of each product\n",
    "x_1 = m.addVar(vtype=GRB.INTEGER, name=\"x_1\") # Number of units of product 1\n",
    "x_2 = m.addVar(vtype=GRB.INTEGER, name=\"x_2\") # Number of units of product 2\n",
    "\n",
    "# Objective function: Maximize 149 x_1 + 389 x_2\n",
    "m.setObjective(149 * x_1 + 389 * x_2, GRB.MAXIMIZE)\n",
    "\n",
    "# Constraints\n",
    "m.addConstr(x_1 <= 7550, name=\"inventory_constraint_1\")\n",
    "m.addConstr(x_2 <= 6244, name=\"inventory_constraint_2\")\n",
    "m.addConstr(x_1 <= 15057, name=\"demand_constraint_1\")\n",
    "m.addConstr(x_2 <= 12474, name=\"demand_constraint_2\")\n",
    "\n",
    "# Non-negativity constraints are implicitly handled by the integer constraints (x_1, x_2 >= 0)\n",
    "\n",
    "# Solve the model\n",
    "m.optimize()\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "    elif selected_problem == \"Facility Location Problem\" or selected_problem == \"FLP\" or selected_problem == \"Facility Location\":\n",
    "        prompt += \"\"\"\n",
    "For example, here is a simple instance for reference:\n",
    "\n",
    "Mathematical Optimization Model:\n",
    "\n",
    "Objective Function:\n",
    "$\\quad \\quad \\min \\quad \\sum_{i} \\sum_{j} A_{ij} \\cdot x_{ij} + \\sum_{i} c_i \\cdot y_i$\n",
    "\n",
    "Constraints\n",
    "1. Demand Constraint:\n",
    "$\\quad \\quad \\sum_i x_{ij} = d_j, \\quad \\forall j$\n",
    "2. Capacity Constraint:\n",
    "$\\quad \\quad \\sum_j x_{ij} \\leq M \\cdot y_i, \\quad \\forall i$\n",
    "3. Non-negativity:\n",
    "$\\quad \\quad x_{ij} \\geq 0, \\quad \\forall i,j$\n",
    "4. Binary Requirement:\n",
    "$\\quad \\quad y_i \\in \\{0,1\\}, \\quad \\forall i$\n",
    "\n",
    "Retrieved Information\n",
    "$\\small d = [1083, 776, 16214, 553, 17106, 594, 732]$\n",
    "$\\small c = [102.33, 94.92, 91.83, 98.71, 95.73, 99.96, 98.16]$\n",
    "$\\small A = \\begin{bmatrix}\n",
    "1506.22 & 70.90 & 8.44 & 260.27 & 197.47 & 71.71 & 61.19 \\\\  \n",
    "1732.65 & 1780.72 & 567.44 & 448.68 & 29.00 & 1484.91 & 963.92 \\\\  \n",
    "115.66 & 100.76 & 64.68 & 1324.53 & 64.99 & 134.88 & 2102.83 \\\\  \n",
    "1254.78 & 1115.63 & 52.31 & 1036.16 & 892.63 & 1464.04 & 1383.41 \\\\  \n",
    "42.90 & 891.01 & 1013.94 & 1128.72 & 58.91 & 42.89 & 1570.31 \\\\  \n",
    "0.70 & 139.46 & 70.03 & 79.15 & 1482.00 & 0.91 & 110.46 \\\\  \n",
    "1732.30 & 1780.44 & 486.50 & 523.74 & 522.08 & 82.48 & 826.41\n",
    "\\end{bmatrix}$\n",
    "$\\small M = \\sum_j d_j = 1083 + 776 + 16214 + 553 + 17106 + 594 + 732 = 38058 $\n",
    "\n",
    "The corresponding Python code for this instance is as follows:\n",
    "\n",
    "```python\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "d = np.array([1083, 776, 16214, 553, 17106, 594, 732])\n",
    "c = np.array([102.33, 94.92, 91.83, 98.71, 95.73, 99.96, 98.16])\n",
    "A = np.array([[1506.22, 70.90, 8.44, 260.27, 197.47, 71.71, 61.19],  \n",
    "[1732.65, 1780.72, 567.44, 448.68, 29.00, 1484.91, 963.92],  \n",
    "[115.66, 100.76, 64.68, 1324.53, 64.99, 134.88, 2102.83],  \n",
    "[1254.78, 1115.63, 52.31, 1036.16, 892.63, 1464.04, 1383.41],  \n",
    "[42.90, 891.01, 1013.94, 1128.72, 58.91, 42.89, 1570.31],  \n",
    "[0.70, 139.46, 70.03, 79.15, 1482.00, 0.91, 110.46],  \n",
    "[1732.30, 1780.44, 486.50, 523.74, 522.08, 82.48, 826.41]])\n",
    "\n",
    "# Create the model\n",
    "m = gp.Model(\"Optimization_Model\")\n",
    "\n",
    "# Decision variables\n",
    "x = m.addVars(A.shape[0], A.shape[1], lb=0, name=\"x\")\n",
    "y = m.addVars(A.shape[0], vtype=GRB.BINARY, name=\"y\")\n",
    "\n",
    "# Objective function\n",
    "m.setObjective(gp.quicksum(A[i, j]*x[i, j] for i in range(A.shape[0]) for j in range(A.shape[1])) + gp.quicksum(c[i]*y[i] for i in range(A.shape[0])), GRB.MINIMIZE)\n",
    "\n",
    "# Constraints\n",
    "for j in range(A.shape[1]):\n",
    "    m.addConstr(gp.quicksum(x[i, j] for i in range(A.shape[0])) == d[j], name=f\"demand_constraint_{j}\")\n",
    "\n",
    "M = 1000000  # large number\n",
    "for i in range(A.shape[0]):\n",
    "    m.addConstr(-M*y[i] + gp.quicksum(x[i, j] for j in range(A.shape[1])) <= 0, name=f\"M_constraint_{i}\")\n",
    "\n",
    "# Solve the model\n",
    "m.optimize()\n",
    "        \"\"\"\n",
    "\n",
    "    elif selected_problem == \"Assignment Problem\" or selected_problem == \"AP\" or selected_problem == \"Assignment\":\n",
    "        prompt += \"\"\"\n",
    "For example, here is a simple instance for reference:\n",
    "\n",
    "Mathematical Optimization Model:\n",
    "\n",
    "Objective Function:\n",
    "$\\quad \\quad \\min \\quad \\sum_{i=1}^3 \\sum_{j=1}^3 c_{ij} \\cdot x_{ij}$\n",
    "\n",
    "Constraints\n",
    "1. Row Assignment Constraint:\n",
    "$\\quad \\quad \\sum_{j=1}^3 x_{ij} = 1, \\quad \\forall i \\in \\{1,2,3\\}$\n",
    "2. Column Assignment Constraint:\n",
    "$\\quad \\quad \\sum_{i=1}^3 x_{ij} = 1, \\quad \\forall j \\in \\{1,2,3\\}$\n",
    "3. Binary Constraint:\n",
    "$\\quad \\quad x_{ij} \\in \\{0,1\\}, \\quad \\forall i,j$\n",
    "\n",
    "Retrieved Information\n",
    "$\\small c = \\begin{bmatrix}\n",
    "3000 & 3200 & 3100 \\\\\n",
    "2800 & 3300 & 2900 \\\\\n",
    "2900 & 3100 & 3000 \n",
    "\\end{bmatrix}$\n",
    "\n",
    "The corresponding Python code for this instance is as follows:\n",
    "\n",
    "```python\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "c = np.array([\n",
    "    [3000, 3200, 3100],\n",
    "    [2800, 3300, 2900],\n",
    "    [2900, 3100, 3000]\n",
    "])\n",
    "\n",
    "# Create the model\n",
    "m = gp.Model(\"Optimization_Model\")\n",
    "\n",
    "# Decision variables\n",
    "x = m.addVars(c.shape[0], c.shape[1], vtype=GRB.BINARY, name=\"x\")\n",
    "\n",
    "# Objective function\n",
    "m.setObjective(gp.quicksum(c[i, j]*x[i, j] for i in range(c.shape[0]) for j in range(c.shape[1])), GRB.MINIMIZE)\n",
    "\n",
    "# Constraints\n",
    "for i in range(c.shape[0]):\n",
    "    m.addConstr(gp.quicksum(x[i, j] for j in range(c.shape[1])) == 1, name=f\"row_constraint_{i}\")\n",
    "\n",
    "for j in range(c.shape[1]):\n",
    "    m.addConstr(gp.quicksum(x[i, j] for i in range(c.shape[0])) == 1, name=f\"col_constraint_{j}\")\n",
    "\n",
    "# Solve the model\n",
    "m.optimize()\n",
    "\"\"\"\n",
    "\n",
    "    \n",
    "    elif selected_problem == \"Transportation Problem\" or selected_problem == \"TP\" or selected_problem == \"Transportation\":\n",
    "        prompt += \"\"\"\n",
    "For example, here is a simple instance for reference:\n",
    "\n",
    "Mathematical Optimization Model:\n",
    "\n",
    "Objective Function:\n",
    "$\\quad \\quad \\min \\quad \\sum_i \\sum_j c_{ij} \\cdot x_{ij}$\n",
    "\n",
    "Constraints\n",
    "1. Demand Constraint:\n",
    "$\\quad \\quad \\sum_i x_{ij} \\geq d_j, \\quad \\forall j$\n",
    "2. Capacity Constraint:\n",
    "$\\quad \\quad \\sum_j x_{ij} \\leq s_i, \\quad \\forall i$\n",
    "\n",
    "Retrieved Information\n",
    "$\\small d = [94, 39, 65, 435]$\n",
    "$\\small s = [2531, 20, 210, 241]$\n",
    "$\\small c = \\begin{bmatrix}\n",
    "883.91 & 0.04 & 0.03 & 44.45 \\\\\n",
    "543.75 & 23.68 & 23.67 & 447.75 \\\\\n",
    "537.34 & 23.76 & 498.95 & 440.60 \\\\\n",
    "1791.49 & 68.21 & 1432.48 & 1527.76\n",
    "\\end{bmatrix}$\n",
    "\n",
    "The corresponding Python code for this instance is as follows:\n",
    "\n",
    "```python\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Create the model\n",
    "m = gp.Model(\"Optimization\")\n",
    "\n",
    "# Decision variables\n",
    "x_S1_C1 = m.addVar(vtype=GRB.INTEGER, name=\"x_S1_C1\")\n",
    "x_S1_C2 = m.addVar(vtype=GRB.INTEGER, name=\"x_S1_C2\")\n",
    "x_S1_C3 = m.addVar(vtype=GRB.INTEGER, name=\"x_S1_C3\")\n",
    "x_S1_C4 = m.addVar(vtype=GRB.INTEGER, name=\"x_S1_C4\")\n",
    "x_S2_C1 = m.addVar(vtype=GRB.INTEGER, name=\"x_S2_C1\")\n",
    "x_S2_C2 = m.addVar(vtype=GRB.INTEGER, name=\"x_S2_C2\")\n",
    "x_S2_C3 = m.addVar(vtype=GRB.INTEGER, name=\"x_S2_C3\")\n",
    "x_S2_C4 = m.addVar(vtype=GRB.INTEGER, name=\"x_S2_C4\")\n",
    "x_S3_C1 = m.addVar(vtype=GRB.INTEGER, name=\"x_S3_C1\")\n",
    "x_S3_C2 = m.addVar(vtype=GRB.INTEGER, name=\"x_S3_C2\")\n",
    "x_S3_C3 = m.addVar(vtype=GRB.INTEGER, name=\"x_S3_C3\")\n",
    "x_S3_C4 = m.addVar(vtype=GRB.INTEGER, name=\"x_S3_C4\")\n",
    "x_S4_C1 = m.addVar(vtype=GRB.INTEGER, name=\"x_S4_C1\")\n",
    "x_S4_C2 = m.addVar(vtype=GRB.INTEGER, name=\"x_S4_C2\")\n",
    "x_S4_C3 = m.addVar(vtype=GRB.INTEGER, name=\"x_S4_C3\")\n",
    "x_S4_C4 = m.addVar(vtype=GRB.INTEGER, name=\"x_S4_C4\")\n",
    "\n",
    "# Objective function\n",
    "m.setObjective(883.91 * x_S2_C1 + 0.04 * x_S2_C2 + 0.03 * x_S2_C3 + 44.45 * x_S2_C4 + 543.75 * x_S1_C1 + 23.68 * x_S1_C2 + 23.67 * x_S1_C3 + 447.75 * x_S1_C4 + 537.34 * x_S3_C1 + 23.76 * x_S3_C2 + 498.95 * x_S3_C3 + 440.60 * x_S3_C4 + 1791.49 * x_S4_C1 + 68.21 * x_S4_C2 + 1432.48 * x_S4_C3 + 1527.76 * x_S4_C4, GRB.MINIMIZE)\n",
    "\n",
    "# Constraints\n",
    "m.addConstr(x_S1_C1 + x_S2_C1 + x_S3_C1 + x_S4_C1 >= 94, name=\"demand_constraint1\")\n",
    "m.addConstr(x_S1_C2 + x_S2_C2 + x_S3_C2 + x_S4_C2 >= 39, name=\"demand_constraint2\")\n",
    "m.addConstr(x_S1_C3 + x_S2_C3 + x_S3_C3 + x_S4_C3 >= 65, name=\"demand_constraint3\")\n",
    "m.addConstr(x_S1_C4 + x_S2_C4 + x_S3_C4 + x_S4_C4 >= 435, name=\"demand_constraint4\")\n",
    "m.addConstr(x_S1_C1 + x_S1_C2 + x_S1_C3 + x_S1_C4 <= 2531, name=\"capacity_constraint1\")\n",
    "m.addConstr(x_S2_C1 + x_S2_C2 + x_S2_C3 + x_S2_C4 <= 20, name=\"capacity_constraint2\")\n",
    "m.addConstr(x_S3_C1 + x_S3_C2 + x_S3_C3 + x_S3_C4 <= 210, name=\"capacity_constraint3\")\n",
    "m.addConstr(x_S4_C1 + x_S4_C2 + x_S4_C3 + x_S4_C4 <= 241, name=\"capacity_constraint4\")\n",
    "\n",
    "# Solve the model\n",
    "m.optimize()\n",
    "        \"\"\"\n",
    "    \n",
    "    elif selected_problem == \"Resource Allocation\" or selected_problem == \"RA\" or selected_problem == \"Resource Allocation Problem\":\n",
    "        prompt += \"\"\"\n",
    "For example, here is a simple instance for reference:\n",
    "\n",
    "Always remember: If not specified. All the variables are non-negative interger.\n",
    "\n",
    "Mathematical Optimization Model:\n",
    "\n",
    "Objective Function:\n",
    "$\\quad \\quad \\max \\quad \\sum_i \\sum_j p_i \\cdot x_{ij}$\n",
    "\n",
    "Constraints\n",
    "1. Capacity Constraint:\n",
    "$\\quad \\quad \\sum_i a_i \\cdot x_{ij} \\leq c_j, \\quad \\forall j$\n",
    "2. Non-negativity Constraint:\n",
    "$\\quad \\quad x_{ij} \\geq 0, \\quad \\forall i,j$\n",
    "\n",
    "Retrieved Information\n",
    "$\\small p = [321, 309, 767, 300, 763, 318, 871, 522, 300, 275, 858, 593, 126, 460, 685, 443, 700, 522, 940, 598]$\n",
    "$\\small a = [495, 123, 165, 483, 472, 258, 425, 368, 105, 305, 482, 387, 469, 341, 318, 104, 377, 213, 56, 131]$\n",
    "$\\small c = [4466]$\n",
    "\n",
    "The corresponding Python code for this instance is as follows:\n",
    "\n",
    "```python\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Create the model\n",
    "m = gp.Model(\"Optimization_Model\")\n",
    "\n",
    "# Decision variables\n",
    "x = m.addVars(20, vtype=GRB.INTEGER, name=\"x\")\n",
    "\n",
    "# Objective function\n",
    "m.setObjective(sum(x[i]*c[i] for i in range(20)), GRB.MAXIMIZE)\n",
    "\n",
    "# Constraints\n",
    "m.addConstr(sum(x[i]*w[i] for i in range(20)) <= 4466, name=\"capacity_constraint\")\n",
    "\n",
    "# Coefficients for the objective function\n",
    "c = [321, 309, 767, 300, 763, 318, 871, 522, 300, 275, 858, 593, 126, 460, 685, 443, 700, 522, 940, 598]\n",
    "\n",
    "# Coefficients for the capacity constraint\n",
    "w = [495, 123, 165, 483, 472, 258, 425, 368, 105, 305, 482, 387, 469, 341, 318, 104, 377, 213, 56, 131]\n",
    "\n",
    "# Solve the model\n",
    "m.optimize()\n",
    "```\n",
    "\n",
    "-----\n",
    "Here is another simple instance for reference:\n",
    "\n",
    "Objective Function:\n",
    "$\\quad \\quad \\max \\quad \\sum_i p_i \\cdot x_i$\n",
    "\n",
    "Constraints\n",
    "1. Capacity Constraint:\n",
    "$\\quad \\quad \\sum_i a_i \\cdot x_i \\leq 180$\n",
    "2. Dependency Constraint:\n",
    "$\\quad \\quad x_1 \\leq x_3$\n",
    "3. Non-negativity Constraint:\n",
    "$\\quad \\quad x_i \\geq 0, \\quad \\forall i$\n",
    "\n",
    "Retrieved Information\n",
    "$\\small p = [888, 134, 129, 370, 921, 765, 154, 837, 584, 365]$\n",
    "$\\small a = [4, 2, 4, 3, 2, 1, 2, 1, 3, 3]$\n",
    "\n",
    "The corresponding Python code for this instance is as follows:\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Create the model\n",
    "m = gp.Model(\"Optimization_Model\")\n",
    "\n",
    "# Decision variables\n",
    "x = m.addVars(10, vtype=GRB.INTEGER, name=\"x\")\n",
    "\n",
    "# Objective function\n",
    "p = [888, 134, 129, 370, 921, 765, 154, 837, 584, 365]\n",
    "m.setObjective(sum(x[i]*p[i] for i in range(10)), GRB.MAXIMIZE)\n",
    "\n",
    "# Constraints\n",
    "a = [4, 2, 4, 3, 2, 1, 2, 1, 3, 3]\n",
    "m.addConstr(sum(x[i]*a[i] for i in range(10)) <= 180, name=\"capacity_constraint\")\n",
    "m.addConstr(x[0] <= x[2], name=\"dependency_constraint\")\n",
    "\n",
    "# Solve the model\n",
    "m.optimize()\n",
    "        \n",
    "        \"\"\"\n",
    "    else:\n",
    "        prompt += \"\"\"\n",
    "For example, here is a simple instance for reference:\n",
    "\n",
    "Mathematical Optimization Model:\n",
    "Maximize 5x_S + 8x_F\n",
    "Subject to\n",
    "    2x_S + 5x_F <= 200\n",
    "    x_S <= 0.3(x_S + x_F)\n",
    "    x_F >= 10\n",
    "    x_S, x_F _ Z+\n",
    "\n",
    "The corresponding Python code for this instance is as follows:\n",
    "\n",
    "```python\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Create the model\n",
    "m = gp.Model(\"Worker_Optimization\")\n",
    "\n",
    "# Decision variables for the number of seasonal (x_S) and full-time (x_F) workers\n",
    "x_S = m.addVar(vtype=GRB.INTEGER, lb=0, name=\"x_S\")  # Number of seasonal workers\n",
    "x_F = m.addVar(vtype=GRB.INTEGER, lb=0, name=\"x_F\")  # Number of full-time workers\n",
    "\n",
    "# Objective function: Maximize Z = 5x_S + 8x_F\n",
    "m.setObjective(5 * x_S + 8 * x_F, GRB.MAXIMIZE)\n",
    "\n",
    "# Constraints\n",
    "m.addConstr(2 * x_S + 5 * x_F <= 200, name=\"resource_constraint\")\n",
    "m.addConstr(x_S <= 0.3 * (x_S + x_F), name=\"seasonal_ratio_constraint\")\n",
    "m.addConstr(x_F >= 10, name=\"full_time_minimum_constraint\")\n",
    "\n",
    "# Non-negativity constraints are implicitly handled by the integer constraints (x_S, x_F >= 0)\n",
    "\n",
    "# Solve the model\n",
    "m.optimize()\n",
    "```\n",
    "The another example is:\n",
    "\n",
    "Mathematical Optimization Model:\n",
    "Minimize 919x_11 + 556x_12 + 951x_13 + 21x_21 + 640x_22 + 409x_23 + 59x_31 + 786x_32 + 304x_33\n",
    "Subject to\n",
    "    x_11 + x_12 + x_13 = 1\n",
    "    x_21 + x_22 + x_23 = 1\n",
    "    x_31 + x_32 + x_33 = 1\n",
    "    x_11 + x_21 + x_31 = 1\n",
    "    x_12 + x_22 + x_32 = 1\n",
    "    x_13 + x_23 + x_33 = 1\n",
    "    x_11, x_12, x_13, x_21, x_22, x_23, x_31, x_32, x_33 ∈ {{0,1}}\n",
    "\n",
    "The corresponding Python code for this instance is as follows:\n",
    "\n",
    "```python\n",
    "\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "c = np.array([\n",
    "    [919, 556, 951],\n",
    "    [21, 640, 409],\n",
    "    [59, 786, 304]\n",
    "])\n",
    "\n",
    "# Create the model\n",
    "m = gp.Model(\"Optimization_Model\")\n",
    "\n",
    "# Decision variables\n",
    "x = m.addVars(c.shape[0], c.shape[1], vtype=GRB.BINARY, name=\"x\")\n",
    "\n",
    "# Objective function\n",
    "m.setObjective(gp.quicksum(c[i, j]*x[i, j] for i in range(c.shape[0]) for j in range(c.shape[1])), GRB.MINIMIZE)\n",
    "\n",
    "# Constraints\n",
    "for i in range(c.shape[0]):\n",
    "    m.addConstr(gp.quicksum(x[i, j] for j in range(c.shape[1])) == 1, name=f\"row_constraint_{i}\")\n",
    "\n",
    "for j in range(c.shape[1]):\n",
    "    m.addConstr(gp.quicksum(x[i, j] for i in range(c.shape[0])) == 1, name=f\"col_constraint_{j}\")\n",
    "\n",
    "# Solve the model\n",
    "m.optimize() \n",
    "```\n",
    "\"\"\"\n",
    "        prompt += \"\"\"\n",
    "\n",
    "-----  Here is a Capacitated Facility Location (MIP) instance for reference:----- \n",
    "\n",
    "Mathematical Optimization Model:\n",
    "\\[\n",
    "\\begin{{aligned}}\n",
    "\\min\\;& 10000\\,y_1 + 15010\\,y_2 + 12000\\,y_3 \\\\\n",
    "& + 5x_{{11}} + 7x_{{12}} + 3x_{{13}} + 4x_{{14}} \\\\\n",
    "& + 6x_{{21}} + 4x_{{22}} + 5x_{{23}} + 3x_{{24}} \\\\\n",
    "& + 2x_{{31}} + 6x_{{32}} + 7x_{{33}} + 4x_{{34}} \\\\\n",
    "\\text{s.t.}\\;& \\sum_{i=1}^{3} x_{ij} \\ge d_j && \\forall j=1,\\dots,4 \\\\\n",
    "& \\sum_{j=1}^{4} x_{ij} \\le s_i\\,y_i && \\forall i=1,\\dots,3 \\\\\n",
    "& d = \\{100, 150, 200, 120\\} \\\\\n",
    "& s = \\{300, 400, 250\\} \\\\\n",
    "& y_i \\in \\{0,1\\} && \\forall i \\\\\n",
    "& x_{ij} \\ge 0 && \\forall i,j\n",
    "\\end{{aligned}}\n",
    "\\]\n",
    "\n",
    "The corresponding Python code for this instance is as follows:\n",
    "\n",
    "```python\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# Data\n",
    "facilities = [1, 2, 3]\n",
    "customers = [1, 2, 3, 4]\n",
    "\n",
    "# Fixed costs\n",
    "fixed_costs = {1: 10000, 2: 15010, 3: 12000}\n",
    "\n",
    "# Capacities\n",
    "capacities = {1: 300, 2: 400, 3: 250}\n",
    "\n",
    "# Demands\n",
    "demands = {1: 100, 2: 150, 3: 200, 4: 120}\n",
    "\n",
    "# Variable costs\n",
    "var_costs = {\n",
    "    (1, 1): 5, (1, 2): 7, (1, 3): 3, (1, 4): 4,\n",
    "    (2, 1): 6, (2, 2): 4, (2, 3): 5, (2, 4): 3,\n",
    "    (3, 1): 2, (3, 2): 6, (3, 3): 7, (3, 4): 4,\n",
    "}\n",
    "arcs = var_costs.keys()\n",
    "\n",
    "m = gp.Model(\"CFLP_Example\")\n",
    "\n",
    "# Variables\n",
    "y = m.addVars(facilities, vtype=GRB.BINARY, name=\"y\")\n",
    "x = m.addVars(arcs, name=\"x\") # default lb=0\n",
    "\n",
    "# Objective\n",
    "obj_fixed = y.prod(fixed_costs)\n",
    "obj_variable = x.prod(var_costs)\n",
    "m.setObjective(obj_fixed + obj_variable, GRB.MINIMIZE)\n",
    "\n",
    "# Demand Constraints\n",
    "for j in customers:\n",
    "    m.addConstr(x.sum('*', j) >= demands[j], name=f\"demand_{j}\")\n",
    "\n",
    "# Capacity Constraints\n",
    "for i in facilities:\n",
    "    m.addConstr(x.sum(i, '*') <= capacities[i] * y[i], name=f\"capacity_{i}\")\n",
    "    \n",
    "m.optimize()\n",
    "```\n",
    "\n",
    "----- Here is a Traveling Salesperson Problem (TSP) instance for reference: -----\n",
    "\n",
    "Mathematical Optimization Model:\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "\\min \\quad & 15x_{12}+25x_{13}+35x_{14}+18x_{21}+30x_{23}+40x_{24} \\\\\n",
    "& + 28x_{31}+20x_{32}+38x_{34}+45x_{41}+50x_{42}+55x_{43} \\\\\n",
    "\\text{s.t.}\\quad & \\sum_{j\\neq i} x_{ij}=1 && \\forall i=1,\\dots,4 \\\\\n",
    "& \\sum_{i\\neq j} x_{ij}=1 && \\forall j=1,\\dots,4 \\\\\n",
    "& u_i - u_j + 4x_{ij} \\le 3 && \\forall i,j \\in \\{1,\\dots,4\\}, i \\neq j \\\\\n",
    "& 1 \\le u_i \\le 4 && \\forall i=1,\\dots,4 \\\\\n",
    "& x_{ij} \\in \\{0,1\\} && \\forall i \\neq j \\\\\n",
    "& u_i \\in \\mathbb{Z} && \\forall i\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "The corresponding Python code for this instance is as follows:\n",
    "\n",
    "```python\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "n = 4\n",
    "nodes = range(1, n + 1)\n",
    "\n",
    "costs = {\n",
    "    (1, 2): 15, (1, 3): 25, (1, 4): 35,\n",
    "    (2, 1): 18, (2, 3): 30, (2, 4): 40,\n",
    "    (3, 1): 28, (3, 2): 20, (3, 4): 38,\n",
    "    (4, 1): 45, (4, 2): 50, (4, 3): 55,\n",
    "}\n",
    "arcs = costs.keys()\n",
    "\n",
    "m = gp.Model(\"TSP_Example\")\n",
    "\n",
    "# Variables\n",
    "x = m.addVars(arcs, vtype=GRB.BINARY, name=\"x\")\n",
    "u = m.addVars(nodes, vtype=GRB.INTEGER, lb=1, ub=n, name=\"u\")\n",
    "\n",
    "# Objective\n",
    "m.setObjective(x.prod(costs), GRB.MINIMIZE)\n",
    "\n",
    "# Constraints\n",
    "for i in nodes:\n",
    "    m.addConstr(x.sum(i, '*') == 1, name=f\"leave_{i}\")\n",
    "\n",
    "for j in nodes:\n",
    "    m.addConstr(x.sum('*', j) == 1, name=f\"enter_{j}\")\n",
    "\n",
    "# MTZ Subtour Elimination\n",
    "for i, j in arcs:\n",
    "    m.addConstr(u[i] - u[j] + n * x[i, j] <= n - 1, name=f\"MTZ_{i}_{j}\")\n",
    "\n",
    "m.optimize()\n",
    "```\n",
    "----- Here is a Maximum Flow Problem (LP) instance for reference: -----\n",
    "\n",
    "Mathematical Optimization Model:\n",
    "\\[\n",
    "\\begin{aligned}\n",
    "\\max\\;& F \\\\\n",
    "\\text{s.t. } \n",
    "& f_{01}+f_{02} = F && \\text{(Source 0)} \\\\\n",
    "& f_{12}+f_{13}+f_{14} = f_{01} && \\text{(Node 1)} \\\\\n",
    "& f_{23}+f_{24} = f_{02} + f_{12} && \\text{(Node 2)} \\\\\n",
    "& f_{34} = f_{13} + f_{23} && \\text{(Node 3)} \\\\\n",
    "& f_{14}+f_{24}+f_{34} = F && \\text{(Sink 4)} \\\\\n",
    "& f_{01} \\le 25, f_{02} \\le 35 \\\\\n",
    "& f_{12} \\le 12, f_{13} \\le 18, f_{14} \\le 8 \\\\\n",
    "& f_{23} \\le 12, f_{24} \\le 22 \\\\\n",
    "& f_{34} \\le 30 \\\\\n",
    "& f_{ij} \\ge 0, F \\ge 0\n",
    "\\end{aligned}\n",
    "\\]\n",
    "\n",
    "The corresponding Python code for this instance is as follows:\n",
    "\n",
    "```python\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "capacities = {\n",
    "    (0, 1): 25, (0, 2): 35,\n",
    "    (1, 2): 12, (1, 3): 18, (1, 4): 8,\n",
    "    (2, 3): 12, (2, 4): 22,\n",
    "    (3, 4): 30\n",
    "}\n",
    "arcs = capacities.keys()\n",
    "nodes = [0, 1, 2, 3, 4]\n",
    "source = 0\n",
    "sink = 4\n",
    "\n",
    "m = gp.Model(\"MaxFlow_Example\")\n",
    "\n",
    "# Variables\n",
    "f = m.addVars(arcs, name=\"f\") # default lb=0\n",
    "F = m.addVar(name=\"F\", lb=0)\n",
    "\n",
    "# Objective\n",
    "m.setObjective(F, GRB.MAXIMIZE)\n",
    "\n",
    "# Capacity Constraints\n",
    "m.addConstrs((f[i, j] <= capacities[i, j] for i, j in arcs), name=\"cap\")\n",
    "\n",
    "# Balance Constraints\n",
    "# Source\n",
    "m.addConstr(f.sum(source, '*') - f.sum('*', source) == F, name=\"source_balance\")\n",
    "\n",
    "# Sink\n",
    "m.addConstr(f.sum('*', sink) - f.sum(sink, '*') == F, name=\"sink_balance\")\n",
    "\n",
    "# Transshipment nodes\n",
    "for i in [1, 2, 3]:\n",
    "    m.addConstr(f.sum('*', i) - f.sum(i, '*') == 0, name=f\"balance_{i}\")\n",
    "\n",
    "m.optimize()\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        HumanMessage(content=prompt) \n",
    "    ]\n",
    "\n",
    "    response = llm_code.invoke(messages)\n",
    "\n",
    "    print(response.content)\n",
    "\n",
    "    return response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(test, agent):\n",
    "    output_model = []\n",
    "    output_code = []\n",
    "    classification = []\n",
    "    for index, row in test.iterrows():\n",
    "        try:\n",
    "            query = row['Query']\n",
    "            response = agent.invoke(f\"What is the problem type of the text? text:{query}\")\n",
    "            \n",
    "            def extract_problem_type(output_text):\n",
    "                pattern = r'(Network Revenue Management|Network Revenue Management Problem|Resource Allocation|Resource Allocation Problem|Transportation|Transportation Problem|Facility Location Problem|Assignment Problem|AP|Uncapacited Facility Location Problem|NRM|RA|TP|FLP|UFLP|Others without CSV|Sales-Based Linear Programming|SBLP|Others with CSV)'\n",
    "                match = re.search(pattern, output_text, re.IGNORECASE)\n",
    "                return match.group(0) if match else None\n",
    "            \n",
    "            def csv_detect(row):\n",
    "                return 1 if 'Dataset_address' in row.index else 0\n",
    "    \n",
    "            selected_problem = extract_problem_type(response['output'])\n",
    "            classification.append(selected_problem)\n",
    "            \n",
    "            if csv_detect(row):\n",
    "                dataset_address = row['Dataset_address']\n",
    "                if selected_problem == \"Network Revenue Management\" or selected_problem == \"NRM\" or selected_problem == \"Network Revenue Management Problem\":\n",
    "                    print(\"----------Network Revenue Management-----------\")\n",
    "                    output = get_NRM_response(query,dataset_address)\n",
    "                    output_model.append(output)\n",
    "                    code_response = get_code(output,selected_problem)\n",
    "                    output_code.append(code_response)\n",
    "    \n",
    "                elif selected_problem == \"Resource Allocation\" or selected_problem == \"RA\" or selected_problem == \"Resource Allocation Problem\":\n",
    "                    print(\"----------Resource Allocation-----------\")\n",
    "                    output = get_RA_response(query,dataset_address)\n",
    "                    output_model.append(output)\n",
    "                    code_response = get_code(output,selected_problem)\n",
    "                    output_code.append(code_response)\n",
    "    \n",
    "                elif selected_problem == \"Transportation\" or selected_problem == \"TP\" or selected_problem == \"Transportation Problem\":\n",
    "                    print(\"----------Transportation-----------\")\n",
    "                    output = get_TP_response(query,dataset_address)\n",
    "                    output_model.append(output)\n",
    "                    code_response = get_code(output,selected_problem)\n",
    "                    output_code.append(code_response)    \n",
    "    \n",
    "                elif selected_problem == \"Facility Location Problem\" or selected_problem == \"FLP\" or selected_problem == \"Uncapacited Facility Location\" or selected_problem == \"UFLP\":\n",
    "                    print(\"----------Facility Location Problem-----------\")\n",
    "                    output = get_FLP_response(query,dataset_address)\n",
    "                    output_model.append(output)\n",
    "                    code_response = get_code(output,selected_problem)\n",
    "                    output_code.append(code_response)\n",
    "                \n",
    "                elif selected_problem == \"Assignment Problem\" or selected_problem == \"AP\":\n",
    "                    print(\"----------Assignment Problem-----------\")\n",
    "                    output = get_AP_response(query,dataset_address)\n",
    "                    output_model.append(output)\n",
    "                    code_response = get_code(output,selected_problem)\n",
    "                    output_code.append(code_response)\n",
    "                else:\n",
    "                    print(\"----------Others with CSV-----------\")\n",
    "                    output = get_Others_response(query,dataset_address)\n",
    "                    output_model.append(output)\n",
    "                    code_response = get_code(output,selected_problem)\n",
    "                    code_response = \"\" \n",
    "\n",
    "                    if output.strip().startswith(\"```python\"):\n",
    "                        print(\"[INFO] Output is already Gurobi code. Skipping get_code.\")\n",
    "                        code_response = output.strip().replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "                        output_code.append(code_response)\n",
    "                    \n",
    "                    else:\n",
    "                        print(\"[INFO] Output is a Math Model. Calling get_code to convert.\")\n",
    "                        selected_problem = 'Others with CSV'\n",
    "                        code_response = get_code(output, selected_problem) \n",
    "                        output_code.append(code_response)\n",
    "\n",
    "            else:\n",
    "                print(\"----------Others without CSV-----------\")\n",
    "                output = get_others_without_CSV_response(query)\n",
    "                output_model.append(output)\n",
    "                code_response = get_code(output,selected_problem)\n",
    "                output_code.append(code_response)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Connection error: {e}\")\n",
    "            continue\n",
    "        time.sleep(15)\n",
    "    return output_model, output_code,classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_combine_csvs(file_order):\n",
    "    dfs = []\n",
    "    for fname in file_order:\n",
    "        if os.path.exists(fname):\n",
    "            df = pd.read_csv(fname)\n",
    "            dfs.append(df)\n",
    "            print(f\"Read file: {fname} (Row length: {len(df)})\")\n",
    "        else:\n",
    "            print(f\"File doesn't exist: {fname}, already skipped\")\n",
    "    \n",
    "    if not dfs:\n",
    "        raise ValueError(\"No effective files\")\n",
    "    \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def run_gurobi_code(code_str):\n",
    " \n",
    "    try:\n",
    "      \n",
    "        with StringIO() as buf, contextlib.redirect_stdout(buf), contextlib.redirect_stderr(buf):\n",
    "            env = {\n",
    "                '__builtins__': __builtins__,\n",
    "                'gp': gp,\n",
    "                'GRB': GRB\n",
    "            }\n",
    "            \n",
    "           \n",
    "            code_str += \"\\n\\n# Added by executor\\n\"\n",
    "            code_str += \"if hasattr(m, 'status') and m.status == GRB.OPTIMAL:\\n\"\n",
    "            code_str += \"    __result__ = m.ObjVal\\n\"\n",
    "            code_str += \"else:\\n\"\n",
    "            code_str += \"    __result__ = None\\n\"\n",
    "            \n",
    "            \n",
    "            exec(code_str, env)\n",
    "            result = env.get('__result__', None)\n",
    "            \n",
    "     \n",
    "            if 'm' in env:\n",
    "                env['m'].dispose()\n",
    "                del env['m']\n",
    "            \n",
    "            return result\n",
    "    except Exception as e:\n",
    "        print(f\"Execution error: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Large Scale OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('Test_Dataset/Large-scale-or/Large-scale-or-101.csv')\n",
    "test_1=test[:30]\n",
    "test_2=test[30:60]\n",
    "test_3=test[60:80]\n",
    "test_4=test[80:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model, output_code,classification = run_test(test_1,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_1['Query'], 'model_output':output_model, 'code_output':output_code,'classification':classification})\n",
    "output_df.to_csv(\"Large-scale-or-Lean-4.1_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model, output_code,classification = run_test(test_2,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_2['Query'], 'model_output':output_model, 'code_output':output_code,'classification':classification})\n",
    "output_df.to_csv(\"Large-scale-or-Lean-4.1_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model, output_code,classification = run_test(test_3,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_3['Query'], 'model_output':output_model, 'code_output':output_code,'classification':classification})\n",
    "output_df.to_csv(\"Large-scale-or-Lean-4.1_3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model, output_code,classification = run_test(test_4,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_4['Query'], 'model_output':output_model, 'code_output':output_code,'classification':classification})\n",
    "output_df.to_csv(\"Large-scale-or-Lean-4.1_4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order=[\n",
    "    \"Large-scale-or-Lean-4.1_1.csv\",\n",
    "    \"Large-scale-or-Lean-4.1_2.csv\",\n",
    "    \"Large-scale-or-Lean-4.1_3.csv\",\n",
    "    \"Large-scale-or-Lean-4.1_4.csv\"\n",
    "]\n",
    "try:\n",
    "    combined_df = read_and_combine_csvs(file_order)\n",
    "    combined_df.to_csv('Large-scale-or-Lean-4.1_final.csv')\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "except Exception as e:\n",
    "    print(f\"File processing failed: {str(e)}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test NL4OPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_nl4opt = pd.read_excel('Test_Dataset/Small-scale/NL4OPT NEW.xlsx')\n",
    "test_nl4opt1=test_nl4opt[:30]\n",
    "test_nl4opt2=test_nl4opt[30:60]\n",
    "test_nl4opt3=test_nl4opt[60:90]\n",
    "test_nl4opt4=test_nl4opt[90:120]\n",
    "test_nl4opt5=test_nl4opt[120:150]\n",
    "test_nl4opt6=test_nl4opt[150:180]\n",
    "test_nl4opt7=test_nl4opt[180:210]\n",
    "test_nl4opt8=test_nl4opt[210:]\n",
    "test_nl4opt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_nl4opt1, output_code_nl4opt1,classification = run_test(test_nl4opt1,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt1['Query'], 'model_output':output_model_nl4opt1, 'code_output':output_code_nl4opt1})\n",
    "output_df.to_csv(\"NL4OPT_1-30.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_nl4opt2, output_code_nl4opt2,classification = run_test(test_nl4opt2,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt2['Query'], 'model_output':output_model_nl4opt2, 'code_output':output_code_nl4opt2})\n",
    "output_df.to_csv(\"NL4OPT_31-60.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_nl4opt3, output_code_nl4opt3,classification = run_test(test_nl4opt3,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt3['Query'], 'model_output':output_model_nl4opt3, 'code_output':output_code_nl4opt3})\n",
    "output_df.to_csv(\"NL4OPT_61-90.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_nl4opt4, output_code_nl4opt4,classification = run_test(test_nl4opt4,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt4['Query'], 'model_output':output_model_nl4opt4, 'code_output':output_code_nl4opt4})\n",
    "output_df.to_csv(\"NL4OPT_91-120.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_nl4opt5, output_code_nl4opt5,classification = run_test(test_nl4opt5,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt5['Query'], 'model_output':output_model_nl4opt5, 'code_output':output_code_nl4opt5})\n",
    "output_df.to_csv(\"NL4OPT_121-150.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_nl4opt6, output_code_nl4opt6,classification = run_test(test_nl4opt6,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt6['Query'], 'model_output':output_model_nl4opt6, 'code_output':output_code_nl4opt6})\n",
    "output_df.to_csv(\"NL4OPT_151-180.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_nl4opt7, output_code_nl4opt7,classification = run_test(test_nl4opt7,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt7['Query'], 'model_output':output_model_nl4opt7, 'code_output':output_code_nl4opt7})\n",
    "output_df.to_csv(\"NL4OPT_181-210.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_nl4opt8, output_code_nl4opt8,classification = run_test(test_nl4opt8,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_nl4opt8['Query'], 'model_output':output_model_nl4opt8, 'code_output':output_code_nl4opt8})\n",
    "output_df.to_csv(\"NL4OPT_211-245.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order=[\n",
    "    \"NL4OPT_1-30.csv\",\n",
    "    \"NL4OPT_31-60.csv\",\n",
    "    \"NL4OPT_61-90.csv\",\n",
    "    \"NL4OPT_91-120.csv\",\n",
    "    \"NL4OPT_121-150.csv\",\n",
    "    \"NL4OPT_151-180.csv\",\n",
    "    \"NL4OPT_181-210.csv\",\n",
    "    \"NL4OPT_211-245.csv\",\n",
    "]\n",
    "try:\n",
    "    combined_df = read_and_combine_csvs(file_order)\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "except Exception as e:\n",
    "    print(f\"File processing failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "print(\"\\n Running Gurobi Code...\")\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i, row in combined_df.iterrows():\n",
    "    code = row['code_output']\n",
    "    code = re.sub(r'^```python|```$', '', code, flags=re.IGNORECASE).strip()\n",
    "    \n",
    "    print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
    "    result = run_gurobi_code(code)\n",
    "    results.append(result)\n",
    "\n",
    "# Add results column\n",
    "combined_df['objective_value'] = results\n",
    "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
    "print(f\"Success: {len([x for x in results if x is not None])}/{len(results)}\")\n",
    "\n",
    "# Step 3: Save results\n",
    "output_file = \"NL4OPT4.1_result.csv\"\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"Output saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test IndustryOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_industryOR = pd.read_csv('Test_Dataset/Small-scale/IndustryOR_fixedV2.csv')\n",
    "test_industryOR1=test_industryOR[:25]\n",
    "test_industryOR2=test_industryOR[25:50]\n",
    "test_industryOR3=test_industryOR[50:75]\n",
    "test_industryOR4=test_industryOR[75:]\n",
    "test_industryOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_industryOR1, output_code_industryOR1,classification = run_test(test_industryOR1,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_industryOR1['Query'], 'model_output':output_model_industryOR1, 'code_output':output_code_industryOR1})\n",
    "output_df.to_csv(\"IndustryOR_1-25.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_industryOR2, output_code_industryOR2,classification = run_test(test_industryOR2,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_industryOR2['Query'], 'model_output':output_model_industryOR2, 'code_output':output_code_industryOR2})\n",
    "output_df.to_csv(\"IndustryOR_26-50.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_industryOR3, output_code_industryOR3,classification = run_test(test_industryOR3,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_industryOR3['Query'], 'model_output':output_model_industryOR3, 'code_output':output_code_industryOR3})\n",
    "output_df.to_csv(\"IndustryOR_51-75.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_industryOR4, output_code_industryOR4,classification = run_test(test_industryOR4,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_industryOR4['Query'], 'model_output':output_model_industryOR4, 'code_output':output_code_industryOR4})\n",
    "output_df.to_csv(\"IndustryOR_76-100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order=[\n",
    "    \"IndustryOR_1-25.csv\",\n",
    "    \"IndustryOR_26-50.csv\",\n",
    "    \"IndustryOR_51-75.csv\",\n",
    "    \"IndustryOR_76-100.csv\",\n",
    "]\n",
    "try:\n",
    "    combined_df = read_and_combine_csvs(file_order)\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "except Exception as e:\n",
    "    print(f\"File processing failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "print(\"\\n Running Gurobi Code...\")\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i, row in combined_df.iterrows():\n",
    "    code = row['code_output']\n",
    "    code = re.sub(r'^```python|```$', '', code, flags=re.IGNORECASE).strip()\n",
    "    \n",
    "    print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
    "    result = run_gurobi_code(code)\n",
    "    results.append(result)\n",
    "\n",
    "combined_df['objective_value'] = results\n",
    "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
    "print(f\"Success: {len([x for x in results if x is not None])}/{len(results)}\")\n",
    "\n",
    "output_file = \"IndustryOR_result.csv\"\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"Output saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MAMOe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_MAMOe = pd.read_csv('Test_Dataset/Small-scale/MAMO_EasyLP_fixed.csv')\n",
    "test_MAMOe1=test_MAMOe[:100]\n",
    "test_MAMOe2=test_MAMOe[100:200]\n",
    "test_MAMOe3=test_MAMOe[200:300]\n",
    "test_MAMOe4=test_MAMOe[300:400]\n",
    "test_MAMOe5=test_MAMOe[400:500]\n",
    "test_MAMOe6=test_MAMOe[500:600]\n",
    "test_MAMOe7=test_MAMOe[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_model_MAMOe1, output_code_MAMOe1,classification = run_test(test_MAMOe1,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe1['Query'], 'model_output':output_model_MAMOe1, 'code_output':output_code_MAMOe1})\n",
    "output_df.to_csv(\"4.1MAMOe1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOe2, output_code_MAMOe2,classification = run_test(test_MAMOe2,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe2['Query'], 'model_output':output_model_MAMOe2, 'code_output':output_code_MAMOe2})\n",
    "output_df.to_csv(\"4.1MAMOe2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOe3, output_code_MAMOe3,classification = run_test(test_MAMOe3,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe3['Query'], 'model_output':output_model_MAMOe3, 'code_output':output_code_MAMOe3})\n",
    "output_df.to_csv(\"4.1MAMOe3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOe4, output_code_MAMOe4,classification = run_test(test_MAMOe4,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe4['Query'], 'model_output':output_model_MAMOe4, 'code_output':output_code_MAMOe4})\n",
    "output_df.to_csv(\"4.1MAMOe4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOe5, output_code_MAMOe5,classification = run_test(test_MAMOe5,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe5['Query'], 'model_output':output_model_MAMOe5, 'code_output':output_code_MAMOe5})\n",
    "output_df.to_csv(\"4.1MAMOe5.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOe6, output_code_MAMOe6,classification = run_test(test_MAMOe6,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe6['Query'], 'model_output':output_model_MAMOe6, 'code_output':output_code_MAMOe6})\n",
    "output_df.to_csv(\"4.1MAMOe6.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOe7, output_code_MAMOe7,classification = run_test(test_MAMOe7,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOe7['Query'], 'model_output':output_model_MAMOe7, 'code_output':output_code_MAMOe7})\n",
    "output_df.to_csv(\"4.1MAMOe7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order=[\n",
    "    \"4.1MAMOe1.csv\",\n",
    "    \"4.1MAMOe2.csv\",\n",
    "    \"4.1MAMOe3.csv\",\n",
    "    \"4.1MAMOe4.csv\",\n",
    "    \"4.1MAMOe5.csv\",\n",
    "    \"4.1MAMOe6.csv\",\n",
    "    \"4.1MAMOe7.csv\",\n",
    "]\n",
    "try:\n",
    "    combined_df = read_and_combine_csvs(file_order)\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "except Exception as e:\n",
    "    print(f\"File processing failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "print(\"\\n Running Gurobi Code...\")\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i, row in combined_df.iterrows():\n",
    "    code = row['code_output']\n",
    "    code = re.sub(r'^```python|```$', '', code, flags=re.IGNORECASE).strip()\n",
    "    \n",
    "    print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
    "    result = run_gurobi_code(code)\n",
    "    results.append(result)\n",
    "\n",
    "combined_df['objective_value'] = results\n",
    "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
    "print(f\"Success: {len([x for x in results if x is not None])}/{len(results)}\")\n",
    "\n",
    "output_file = \"MAMOe4.1_result.csv\"\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"Output saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MAMOc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_MAMOc = pd.read_csv('Test_Dataset/Small-scale/MAMO_ComplexLP_fixed.csv')\n",
    "test_MAMOc1=test_MAMOc[:25]\n",
    "test_MAMOc2=test_MAMOc[25:50]\n",
    "test_MAMOc3=test_MAMOc[50:75]\n",
    "test_MAMOc4=test_MAMOc[75:100]\n",
    "test_MAMOc5=test_MAMOc[100:125]\n",
    "test_MAMOc6=test_MAMOc[125:150]\n",
    "test_MAMOc7=test_MAMOc[150:175]\n",
    "test_MAMOc8=test_MAMOc[175:]\n",
    "test_MAMOc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOc1, output_code_MAMOc1,classification = run_test(test_MAMOc1,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc1['Query'], 'model_output':output_model_MAMOc1, 'code_output':output_code_MAMOc1})\n",
    "output_df.to_csv(\"4.1MAMOc_1-25.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOc2, output_code_MAMOc2,classification = run_test(test_MAMOc2,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc2['Query'], 'model_output':output_model_MAMOc2, 'code_output':output_code_MAMOc2})\n",
    "output_df.to_csv(\"4.1MAMOc_26-50.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOc3, output_code_MAMOc3,classification = run_test(test_MAMOc3,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc3['Query'], 'model_output':output_model_MAMOc3, 'code_output':output_code_MAMOc3})\n",
    "output_df.to_csv(\"4.1MAMOc_51-75.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOc4, output_code_MAMOc4,classification = run_test(test_MAMOc4,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc4['Query'], 'model_output':output_model_MAMOc4, 'code_output':output_code_MAMOc4})\n",
    "output_df.to_csv(\"4.1MAMOc_76-100.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOc5, output_code_MAMOc5,classification = run_test(test_MAMOc5,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc5['Query'], 'model_output':output_model_MAMOc5, 'code_output':output_code_MAMOc5})\n",
    "output_df.to_csv(\"4.1MAMOc_101-125.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOc6, output_code_MAMOc6,classification = run_test(test_MAMOc6,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc6['Query'], 'model_output':output_model_MAMOc6, 'code_output':output_code_MAMOc6})\n",
    "output_df.to_csv(\"4.1MAMOc_126-150.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOc7, output_code_MAMOc7,classification = run_test(test_MAMOc7,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc7['Query'], 'model_output':output_model_MAMOc7, 'code_output':output_code_MAMOc7})\n",
    "output_df.to_csv(\"4.1MAMOc_151-175.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_MAMOc8, output_code_MAMOc8,classification = run_test(test_MAMOc8,classification_agent)\n",
    "output_df = pd.DataFrame({'Query': test_MAMOc8['Query'], 'model_output':output_model_MAMOc8, 'code_output':output_code_MAMOc8})\n",
    "output_df.to_csv(\"4.1MAMOc_176-202.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_order=[\n",
    "    \"4.1MAMOc_1-25.csv\",\n",
    "    \"4.1MAMOc_26-50.csv\",\n",
    "    \"4.1MAMOc_51-75.csv\",\n",
    "    \"4.1MAMOc_76-100.csv\",\n",
    "    \"4.1MAMOc_101-125.csv\",\n",
    "    \"4.1MAMOc_126-150.csv\",\n",
    "    \"4.1MAMOc_151-175.csv\",\n",
    "    \"4.1MAMOc_176-202.csv\",\n",
    "]\n",
    "try:\n",
    "    combined_df = read_and_combine_csvs(file_order)\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "except Exception as e:\n",
    "    print(f\"File processing failed: {str(e)}\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "print(\"\\n Running Gurobi Code...\")\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i, row in combined_df.iterrows():\n",
    "    code = row['code_output']\n",
    "    code = re.sub(r'^```python|```$', '', code, flags=re.IGNORECASE).strip()\n",
    "    \n",
    "    print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
    "    result = run_gurobi_code(code)\n",
    "    results.append(result)\n",
    "\n",
    "combined_df['objective_value'] = results\n",
    "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
    "print(f\"Success: {len([x for x in results if x is not None])}/{len(results)}\")\n",
    "\n",
    "output_file = \"MAMOc4.1_result.csv\"\n",
    "combined_df.to_csv(output_file, index=False)\n",
    "print(f\"Output saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
