{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Environment Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders.csv_loader import CSVLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.agents import initialize_agent, AgentType, Tool\n",
        "import re\n",
        "from datetime import time\n",
        "from langchain.schema import HumanMessage\n",
        "import openai\n",
        "import requests\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import sys\n",
        "import time\n",
        "from io import StringIO\n",
        "import contextlib\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "from langchain.schema import Document\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from typing import List\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "user_api_key = \"YOUR_OPENAI_API_KEY\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "langchain_api_key = os.getenv('LANGCHAIN_API_KEY')\n",
        "langchain_tracing_v2 = os.getenv('LANGCHAIN_TRACING_V2', 'true')\n",
        "langchain_endpoint = os.getenv('LANGCHAIN_ENDPOINT', 'https://api.smith.langchain.com')\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = langchain_tracing_v2\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = langchain_endpoint\n",
        "os.environ['LANGCHAIN_API_KEY'] = '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'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Main Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "\n",
        "llm1 = ChatOpenAI(\n",
        "    temperature=0.0, model_name=\"gpt-4\", openai_api_key=user_api_key\n",
        ")\n",
        "\n",
        "loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RefData.csv\", encoding=\"utf-8\")\n",
        "data = loader.load()\n",
        "documents = data\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "vectors = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "retriever = vectors.as_retriever(search_kwargs={'k': 5})\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm1,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        ")\n",
        "qa_tool = Tool(\n",
        "    name=\"FileQA\",\n",
        "    func=qa_chain.invoke,\n",
        "    description=(\n",
        "        \"Use this tool to answer questions about the problem type of the text. \"\n",
        "    ),\n",
        ")\n",
        "\n",
        "few_shot_examples_csv = \"\"\"\n",
        "\n",
        "Query: What is the problem type in operation of the text? Please give the answer directly. Text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1,w_2,w_3.There is an independent demand stream for each of the products. The objective of the company is to decide which demands to be fufilled over a ﬁnite sales horizon [0,10] to maximize the total expected revenue from ﬁxed initial inventories. The on-hand inventories for the three items are c_1,c_2,c_3 respectively. During the sales horizon, replenishment is not allowed and there is no any in-transit inventories. Customers who want to purchase P1,P2,P3 arrive at each period accoring to a Poisson process with a_1,a_2,a_3 the arrival rates respectively. Decision variables y_1,y_2,y_3 correspond to the number of requests that the firm plans to fulfill for product 1,2,3. These variables are all positive integers.\n",
        "\n",
        "Thought: I need to determine the problem type of the text. The Query contains descriptions like '.csv' or 'column'. I'll use the FileQA tool to retrieve the relevant information.\n",
        "\n",
        "Action: FileQA\n",
        "\n",
        "Action Input: \"What is the problem type in operation of the text? text:There are three best-selling items (P1, P2, P3) on Amazon with the profit w_1, w_2, w_3. ...\"\n",
        "\n",
        "Observation: The problem type of the text is Network Revenue Management.\n",
        "\n",
        "Thought: The problem type Network Revenue Management is in the allowed list [Network Revenue Management, Resource Allocation, Transportation, Facility Location Problem, Assignment Problem]. I could get the final answer and finish.\n",
        "\n",
        "Final Answer: Network Revenue Management.\n",
        "\n",
        "---\n",
        "Query: What is the problem type in operation of the text? Please give the answer directly. Text:A supermarket needs to allocate various products, including high-demand items like the Sony Alpha Refrigerator, Sony Bravia XR, and Sony PlayStation 5, across different retail shelves. The product values and space requirements are provided in the \"Products.csv\" dataset. Additionally, the store has multiple shelves, each with a total space limit and specific space constraints for Sony and Apple products, as outlined in the \"Capacity.csv\" file. The goal is to determine the optimal number of units of each Sony product to place on each shelf to maximize total value while ensuring that the space used by Sony products on each shelf does not exceed the brand-specific limits. The decision variables x_ij represent the number of units of product i to be placed on shelf j.\n",
        "\n",
        "Thought: I need to determine the problem type of the text. The Query contains descriptions like '.csv' or 'column'. I'll use the FileQA tool to retrieve the relevant information.\n",
        "\n",
        "Action: FileQA\n",
        "\n",
        "Action Input: \"What is the problem type in operation of the text? Text:A supermarket needs to allocate various products, including high-demand items like the Sony Alpha Refrigerator, Sony Bravia XR, ....\"\n",
        "\n",
        "Observation: The problem type of the text is Inventory Management.\n",
        "\n",
        "Thought: The problem type Inventory Management is not in the allowed list [Network Revenue Management, Resource Allocation, Transportation, Facility Location Problem, Assignment Problem]. I need to review the query again and classify it to a type in the allowed list. According to the text, the problem type should be Resource Allocation. \n",
        "\n",
        "Final Answer: Resource Allocation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "few_shot_examples_without_csv = \"\"\"\n",
        "Query: A book distributor needs to shuffle a bunch of books from two warehouses (supply points: W1, W2) to libraries (demand points: L1, L2), using a pair of sorting centers (transshipment points: C1, C2). W1 has a stash of up to p_1 books per day it can send out. W2 can send out up to p_2 books daily. Library L1 needs a solid d_1 books daily. L2 requires d_2 books daily. Storage at the sorting centers has no cap. Transportation costs: From W1 to C1 is t_11 dollars, to C2 is t_12 dollars. From W2 to C1 is t_21 dollars, and to C2 it__ t_22 dollars. From the centers to the libraries: From C1 to L1, it__l cost t_31 dollars, to L2 it__ t_32 dollars. From C2 to L1, it__ t_41 dollars, to L2 it__ t_42 dollars. The strategy here is all about minimizing transportation spend while making sure those libraries get their books on time. We__l use x_11 and x_12 to track shipments from W1 to C1 and C2, and x_21 and x_22 for shipments from W2. For the books going out to the libraries, y_11 and y_12 will handle the flow from C1 to L1 and L2, and y_21 and y_22 from C2. Variables are all positive integers.\n",
        "\n",
        "Thought: I need to determine the problem type of the text. The Query doesn't contain any descriptions like '.csv' and 'column'. I'll direcrly classify the problem type as 'Others without CSV'.\n",
        "\n",
        "Final Answer: Others without CSV\n",
        "\n",
        "\"\"\"\n",
        "prefix = f\"\"\"I am a helpful assistant that can answer Querys about operation problems. My response must align with one of the following categories: Network Revenue Management, Resource Allocation, Transportation, Facility Location Problem, SBLP, Others with CSV, and Others without CSV. Firstly you need to identify whether the text contains any descriptions like '.csv' and 'column'.\n",
        "\n",
        "Always remember! If the input does not contain any description like '.csv' and 'column', and the values for all the variables are given directly, I will directly classify the problem type as 'Others without CSV'. Like the example {few_shot_examples_without_csv}. \n",
        "\n",
        "However, if the text contains descriptions like '.csv' or 'column', and the values for all the variables are not given directly, I will use the following examples {few_shot_examples_csv} as a guide. And answer the Query by given the answer directly.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "suffix = \"\"\"\n",
        "\n",
        "Begin!\n",
        "\n",
        "Query: {input}\n",
        "{agent_scratchpad}\"\"\"\n",
        "\n",
        "classification_agent = initialize_agent(\n",
        "    tools=[qa_tool],\n",
        "    llm=llm1,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    agent_kwargs={\n",
        "        \"prefix\": prefix,\n",
        "        \"suffix\": suffix,\n",
        "    },\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,  \n",
        ")\n",
        "openai.api_request_timeout = 60  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Large Scale OR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NRM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def retrieve_similar_docs(query,retriever):\n",
        "    \n",
        "    similar_docs = retriever.get_relevant_documents(query)\n",
        "\n",
        "    results = []\n",
        "    for doc in similar_docs:\n",
        "        results.append({\n",
        "            \"content\": doc.page_content,\n",
        "            \"metadata\": doc.metadata\n",
        "        })\n",
        "    return results\n",
        "\n",
        "\n",
        "def process_dataset_address(dataset_address: str) -> List[Document]:\n",
        "\n",
        "    documents = []\n",
        "    file_addresses = dataset_address.strip().split('\\n')  \n",
        "    for file_idx, file_address in enumerate(file_addresses, start=1):\n",
        "        try:\n",
        "            df = pd.read_csv(file_address.strip())  \n",
        "            file_name = file_address.strip().split('/')[-1]  \n",
        "            for row_idx, row in df.iterrows():\n",
        "                page_content = \", \".join([f\"{col} = {row[col]}\" for col in df.columns])\n",
        "                documents.append(Document(page_content=page_content))\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {file_address}: {e}\")\n",
        "            continue\n",
        "    \n",
        "    return documents\n",
        "\n",
        "def get_NRM_response(query,dataset_address):\n",
        "    retrieve='product'\n",
        "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_NRM2_MD.csv\", encoding=\"utf-8\")\n",
        "    data = loader.load()\n",
        "    documents = data\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_documents(documents, embeddings)\n",
        "    retriever = vectors.as_retriever(search_kwargs={'k': 1})\n",
        "    few_shot_examples = []\n",
        "\n",
        "    similar_results = retrieve_similar_docs(query,retriever)\n",
        "\n",
        "    for i, result in enumerate(similar_results, 1):\n",
        "        content = result['content']\n",
        "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
        "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip()  \n",
        "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
        "        data_address = split_at_address[0].strip()\n",
        "\n",
        "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
        "        label = split_at_label[0].strip()  \n",
        "        Related = split_at_label[1].strip()\n",
        "        information = pd.read_csv(data_address)\n",
        "        information_head = information[:36]\n",
        "\n",
        "        example_data_description = \"\\nHere is the product data:\\n\"\n",
        "        for i, r in information_head.iterrows():\n",
        "            example_data_description += f\"Product {i + 1}: {r['Product Name']}, revenue w_{i + 1} = {r['Revenue']}, demand rate a_{i + 1} = {r['Demand']}, initial inventory c_{i + 1} = {r['Initial Inventory']}\\n\"\n",
        "\n",
        "\n",
        "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
        "        few_shot_examples.append(f\"\"\"\n",
        "\n",
        "Question: Based on the following problem description and data, please formulate a complete mathematical model using real data from retrieval. {problem_description}\n",
        "\n",
        "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Pay attention: 1. If the data to be retrieved is not specified, retrieve the whole dataset instead. 2. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. 3. The final expressions should not be simplified or abbreviated.\n",
        "\n",
        "Action: CSVQA\n",
        "\n",
        "Action Input: Retrieve all the {retrieve} data {Related} to formulate the mathematical model with no simplification or abbreviation. Retrieve the documents in order, row by row. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, retrieve all the data instead. Only present final answer in details of row, instead of giving a sheet format.\n",
        "\n",
        "Observation: {example_data_description}\n",
        "\n",
        "Thought: Now that I have the necessary data, construct the objective function and constraints using the retrieved data as parameters of the formula. Ensure to include any additional detailed constraints present in the problem description. Always pay attention to the variable type. If not mentioned, use nonnegative integer. Do NOT include any explanations, notes, or extra text. Format the expressions strictly in markdown ONLY in this exact format: {label}. Following this example. The expressions should not be simplified or abbreviated. Besides, I need to use the $$ or $ to wrap the mathematical expressions instead of \\[, \\], \\( or \\). I also should avoid using align, align* and other latex environments. Besides, I should also avoid using \\begin, \\end, \\text.\n",
        "\n",
        "Final Answer: \n",
        "{label}\n",
        "\"\"\")\n",
        "\n",
        "    data = []\n",
        "    dfs=[]\n",
        "\n",
        "    file_addresses = dataset_address.strip().split('\\n')\n",
        "    for file_address in file_addresses:\n",
        "        try:\n",
        "            df = pd.read_csv(file_address)  \n",
        "            file_name = file_address.split('/')[-1] \n",
        "            dfs.append((file_name, df))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file {file_address}: {e}\")\n",
        "\n",
        "    for df_index, (file_name, df) in enumerate(dfs):\n",
        "        data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
        "\n",
        "        for i, r in df.iterrows():\n",
        "            description = \"\"\n",
        "            description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
        "            data.append(description + \"\\n\")\n",
        "    document=data\n",
        "   \n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_texts(document, embeddings)\n",
        "    retriever = vectors.as_retriever(search_kwargs={'k': 1000})\n",
        "    llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4.1', top_p=1,n = 1, openai_api_key=user_api_key)\n",
        "\n",
        "    system_prompt = (\n",
        "        \"Retrieve the documents in order, row by row. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, retrieve all the data instead. Only present final answer in details of row, instead of giving a sheet format.\"\n",
        "        \"Context: {context}\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            (\"human\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "    question_answer_chain = create_stuff_documents_chain(llm2, prompt)\n",
        "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "    def qa_wrapper(query: str):\n",
        "        return qa_chain.invoke({\"input\": query})['answer']\n",
        "    qa_tool = Tool(\n",
        "        name=\"CSVQA\",\n",
        "        func=qa_wrapper,\n",
        "        description=\"Use this tool to answer Querys based on the provided CSV data and retrieve product data similar to the input query.\"\n",
        "    )\n",
        "\n",
        "    prefix = f\"\"\"You are an assistant that generates a mathematical models based on the user's description and provided CSV data.\n",
        "\n",
        "    Please refer to the following example and generate the answer in the same format:\n",
        "\n",
        "    {few_shot_examples}\n",
        "\n",
        "    When you need to retrieve information from the CSV file, use the provided tool.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    suffix = \"\"\"\n",
        "\n",
        "    Begin!\n",
        "\n",
        "    User Description: {input}\n",
        "    {agent_scratchpad}\"\"\"\n",
        "\n",
        "    agent2 = initialize_agent(\n",
        "        tools=[qa_tool],\n",
        "        llm=llm2,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        agent_kwargs={\n",
        "            \"prefix\": prefix,\n",
        "            \"suffix\": suffix,\n",
        "        },\n",
        "        verbose=True,\n",
        "        handle_parsing_errors=True,\n",
        "    )\n",
        "\n",
        "    result = agent2.invoke(query)\n",
        "\n",
        "    return result['output']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_RA_response(query,dataset_address):\n",
        "\n",
        "    retrieve=\"product\"\n",
        "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_RA2_MD.csv\", encoding=\"utf-8\")\n",
        "    data = loader.load()\n",
        "    documents = data\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "    retriever = vectors.as_retriever(search_kwargs={'k': 3})\n",
        "    few_shot_examples = []\n",
        "    similar_results =  retrieve_similar_docs(query,retriever)\n",
        "    for i, result in enumerate(similar_results, 1):\n",
        "        content = result['content']\n",
        "\n",
        "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
        "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip() \n",
        "\n",
        "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
        "        data_address = split_at_address[0].strip()\n",
        "\n",
        "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
        "        label = split_at_label[0].strip()  \n",
        "        Related = split_at_label[1].strip()\n",
        "\n",
        "        datas=data_address.split()\n",
        "        information = []\n",
        "\n",
        "        for data in datas:\n",
        "            information.append(pd.read_csv(data))\n",
        "        example_data_description = \"\\nHere is the data:\\n\"\n",
        "        for df_index, df in enumerate(information):\n",
        "            if df_index == 0:\n",
        "                example_data_description += f\"\\nDataFrame {df_index + 1} - Capacity\\n\"\n",
        "            elif df_index == 1:\n",
        "                example_data_description += f\"\\nDataFrame {df_index + 1} - Products\\n\"\n",
        "\n",
        "            for z, r in df.iterrows():\n",
        "                description = \"\"\n",
        "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
        "                example_data_description += description + \"\\n\"\n",
        "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
        "        few_shot_examples.append( f\"\"\"\n",
        "Question: Based on the following problem description and data, please formulate a complete mathematical model using real data from retrieval. {problem_description}\n",
        "\n",
        "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Pay attention: 1. If the data to be retrieved is not specified, retrieve the whole dataset instead. 2. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. 3. The final expressions should not be simplified or abbreviated.\n",
        "\n",
        "Action: CSVQA\n",
        "\n",
        "Action Input: Retrieve all the {retrieve} data {Related} to formulate the mathematical model with no simplification or abbreviation. Retrieve the documents in order from top to bottom. Use the retrieved context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, retrieve all the data instead. Only present final answer in details of row, instead of giving a sheet format.\n",
        "\n",
        "Observation: {example_data_description}\n",
        "\n",
        "Thought: Now that I have the necessary data, I would construct the objective function and constraints using the retrieved data as parameters of the formula. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula according to the retrieved 'product id'. Do NOT include any explanations, notes, or extra text. Respond ONLY in this exact format: {label}. Following this example. The expressions should not be simplified or abbreviated. Besides, I need to use the $$ or $ to wrap the mathematical expressions instead of \\[, \\], \\( or \\). I also should avoid using align, align* and other latex environments. Besides, I should also avoid using \\begin, \\end, \\text.\n",
        "\n",
        "Final Answer: \n",
        "{label}\n",
        "\"\"\")\n",
        "\n",
        "    data = []\n",
        "    dfs=[]\n",
        "\n",
        "    file_addresses = dataset_address.strip().split('\\n')\n",
        "    for file_address in file_addresses:\n",
        "        try:\n",
        "            df = pd.read_csv(file_address) \n",
        "            file_name = file_address.split('/')[-1]  \n",
        "            dfs.append((file_name, df))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file {file_address}: {e}\")\n",
        "\n",
        "    for df_index, (file_name, df) in enumerate(dfs):\n",
        "        data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
        "\n",
        "        if file_name=='products.csv' or file_name=='Products.csv':\n",
        "            for i, r in df.iterrows():\n",
        "                description = f\"Product id: {i+1}; \"\n",
        "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
        "                data.append(description + \"\\n\")\n",
        "        else:\n",
        "            for i, r in df.iterrows():\n",
        "                description = f\"\"\n",
        "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
        "                data.append(description + \"\\n\")\n",
        "\n",
        "    \n",
        "    documents = [content for content in data]\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_texts(documents, embeddings)\n",
        "    retriever = vectors.as_retriever(search_kwargs={'k': 220})\n",
        "    llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4.1',top_p=1,n = 1, openai_api_key=user_api_key)\n",
        "\n",
        "\n",
        "    system_prompt = (\n",
        "        \"Retrieve the documents in order from top to bottom. Use the retrieved context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, retrieve all the data instead.\"\n",
        "        \"Context: {context}\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            (\"human\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "    question_answer_chain = create_stuff_documents_chain(llm2, prompt)\n",
        "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "    def qa_wrapper(query: str):\n",
        "        return qa_chain.invoke({\"input\": query})['answer']\n",
        "    qa_tool = Tool(\n",
        "        name=\"CSVQA\",\n",
        "        func=qa_wrapper,\n",
        "        description=\"Use this tool to answer Querys based on the provided CSV data and retrieve product data similar to the input query.\"\n",
        "    )\n",
        "\n",
        "    prefix = f\"\"\"You are an assistant that generates a mathematical models based on the user's description and provided CSV data.\n",
        "\n",
        "    Please refer to the following example and generate the answer in the same format:\n",
        "\n",
        "    {few_shot_examples}\n",
        "\n",
        "    When you need to retrieve information from the CSV file, use the provided tool.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    suffix = \"\"\"\n",
        "\n",
        "    Begin!\n",
        "\n",
        "    User Description: {input}\n",
        "    {agent_scratchpad}\"\"\"\n",
        "\n",
        "    agent2 = initialize_agent(\n",
        "        tools=[qa_tool],\n",
        "        llm=llm2,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        agent_kwargs={\n",
        "            \"prefix\": prefix,\n",
        "            \"suffix\": suffix,\n",
        "        },\n",
        "        verbose=True,\n",
        "        handle_parsing_errors=True,\n",
        "    )\n",
        "\n",
        "    result = agent2.invoke(query)\n",
        "\n",
        "    return result['output']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_TP_response(query,dataset_address):\n",
        "    retrieve=\"capacity data and products data, \"\n",
        "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_TP2_MD.csv\", encoding=\"utf-8\")\n",
        "    data = loader.load()\n",
        "    documents = data\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_documents(documents, embeddings)\n",
        "    retriever = vectors.as_retriever(search_kwargs={'k': 3})\n",
        "    few_shot_examples = []\n",
        "    similar_results = retrieve_similar_docs(query,retriever)\n",
        "    for i, result in enumerate(similar_results, 1):\n",
        "        content = result['content']\n",
        "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
        "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip()\n",
        "\n",
        "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
        "        data_address = split_at_address[0].strip()\n",
        "\n",
        "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
        "        label = split_at_label[0].strip()  \n",
        "        Related = split_at_label[1].strip()\n",
        "\n",
        "        datas=data_address.split()\n",
        "        information = []\n",
        "\n",
        "        for data in datas:\n",
        "            information.append(pd.read_csv(data))\n",
        "        example_data_description = \"\\nHere is the data:\\n\"\n",
        "        for df_index, df in enumerate(information):\n",
        "            if df_index == 0:\n",
        "                example_data_description += f\"\\nDataFrame {df_index + 1} - Customer Demand\\n\"\n",
        "            elif df_index == 1:\n",
        "                example_data_description += f\"\\nDataFrame {df_index + 1} - Supply Capacity\\n\"\n",
        "            elif df_index == 2:\n",
        "                example_data_description += f\"\\nDataFrame {df_index + 1} - Transportation Cost\\n\"\n",
        "\n",
        "            for z, r in df.iterrows():\n",
        "                description = \"\"\n",
        "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
        "                example_data_description += description + \"\\n\"\n",
        "            retrieve += ', '.join(df.columns)+', '\n",
        "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
        "        few_shot_examples.append( f\"\"\"\n",
        "Question: Based on the following problem description and data, please formulate a complete mathematical model using real data from retrieval. {problem_description}\n",
        "\n",
        "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Pay attention: 1. If the data to be retrieved is not specified, retrieve the whole dataset instead. 2. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. 3. The final expressions should not be simplified or abbreviated.\n",
        "\n",
        "Action: CSVQA\n",
        "\n",
        "Action Input: Retrieve all the {retrieve} data {Related} to formulate the mathematical model with no simplification or abbreviation. Retrieve the documents in order. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, make sure that all the data is retrieved. Only present final answer in details of row, instead of giving a sheet format.\n",
        "\n",
        "Observation: {example_data_description}\n",
        "\n",
        "Thought: Now that I have the necessary data, I would construct the objective function and constraints using the retrieved data as parameters of the formula. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. Do NOT include any explanations, notes, or extra text. Respond ONLY in this exact format: {label}. Following this example. The expressions should not be simplified or abbreviated. Besides, I need to use the $$ or $ to wrap the mathematical expressions instead of \\[, \\], \\( or \\). I also should avoid using align, align* and other latex environments. Besides, I should also avoid using \\begin, \\end, \\text.\n",
        "\n",
        "Final Answer: \n",
        "{label}\n",
        "\"\"\")\n",
        "    data = []\n",
        "    dfs=[]\n",
        "\n",
        "    file_addresses = dataset_address.strip().split('\\n')\n",
        "    for file_address in file_addresses:\n",
        "        try:\n",
        "            df = pd.read_csv(file_address) \n",
        "            file_name = file_address.split('/')[-1] \n",
        "            dfs.append((file_name, df))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file {file_address}: {e}\")\n",
        "\n",
        "    for df_index, (file_name, df) in enumerate(dfs):\n",
        "        data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
        "\n",
        "        for i, r in df.iterrows():\n",
        "            description = \"\"\n",
        "            description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
        "            data.append(description + \"\\n\")\n",
        "\n",
        "    print(data)\n",
        "\n",
        "    documents = [content for content in data]\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_texts(documents, embeddings)\n",
        "\n",
        "    retriever = vectors.as_retriever(search_kwargs={'k': 300})\n",
        "\n",
        "    llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4.1', top_p=1,n = 1,openai_api_key=user_api_key)\n",
        "\n",
        "\n",
        "    system_prompt = (\n",
        "        \"Retrieve the documents in order. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, make sure that all the data is retrieved.\"\n",
        "        \"Context: {context}\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            (\"human\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "    question_answer_chain = create_stuff_documents_chain(llm2, prompt)\n",
        "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "    def qa_wrapper(query: str):\n",
        "        return qa_chain.invoke({\"input\": query})['answer']\n",
        "    qa_tool = Tool(\n",
        "        name=\"CSVQA\",\n",
        "        func=qa_wrapper,\n",
        "        description=\"Use this tool to answer Querys based on the provided CSV data and retrieve product data similar to the input query.\"\n",
        "    )\n",
        "\n",
        "    prefix = f\"\"\"You are an assistant that generates a mathematical models based on the user's description and provided CSV data.\n",
        "\n",
        "    Please refer to the following example and generate the answer in the same format:\n",
        "\n",
        "    {few_shot_examples}\n",
        "\n",
        "    When you need to retrieve information from the CSV file, use the provided tool.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    suffix = \"\"\"\n",
        "\n",
        "    Begin!\n",
        "\n",
        "    User Description: {input}\n",
        "    {agent_scratchpad}\"\"\"\n",
        "\n",
        "    agent2 = initialize_agent(\n",
        "        tools=[qa_tool],\n",
        "        llm=llm2,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        agent_kwargs={\n",
        "            \"prefix\": prefix,\n",
        "            \"suffix\": suffix,\n",
        "        },\n",
        "        verbose=True,\n",
        "        handle_parsing_errors=True,\n",
        "    )\n",
        "\n",
        "    result = agent2.invoke(query)\n",
        "\n",
        "    return result['output']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_AP_response(query,dataset_address):\n",
        "    retrieve=''\n",
        "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_AP2_MD.csv\", encoding=\"utf-8\")\n",
        "    data = loader.load()\n",
        "\n",
        "    documents = data\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_documents(documents, embeddings)\n",
        "    retriever = vectors.as_retriever(max_tokens_limit=400,search_kwargs={'k': 1})\n",
        "    few_shot_examples = []\n",
        "    similar_results =  retrieve_similar_docs(query,retriever)\n",
        "    for i, result in enumerate(similar_results, 1):\n",
        "        content = result['content']\n",
        "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
        "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip() \n",
        "\n",
        "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
        "        data_address = split_at_address[0].strip()\n",
        "\n",
        "        file_addresses = data_address.strip().split('\\n')\n",
        "        dfs = []\n",
        "        df_index = 0\n",
        "        example_data_description = \" \"\n",
        "        for file_address in file_addresses:\n",
        "            try:\n",
        "                df = pd.read_csv(file_address) \n",
        "                file_name = file_address.split('/')[-1]  \n",
        "                matrix = df.iloc[:,1:].values\n",
        "                example_data_description +=\"C=\" + np.array_str(matrix)+ \".\"\n",
        "                dfs.append((file_name, df))\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading file {file_address}: {e}\")\n",
        "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
        "        label = split_at_label[0].strip() \n",
        "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
        "        Related=''\n",
        "        few_shot_examples.append( f\"\"\"\n",
        "Question: Based on the following problem description and data, please formulate a complete mathematical model using real data from retrieval. {problem_description}\n",
        "\n",
        "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Pay attention: 1. If the data to be retrieved is not specified, retrieve the whole dataset instead. 2. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. 3. The final expressions should not be simplified or abbreviated.\n",
        "\n",
        "Action: CSVQA\n",
        "\n",
        "Action Input: Retrieve all the {retrieve} data {Related} to formulate the mathematical model with no simplification or abbreviation. Retrieve the documents in order. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, make sure that all the data is retrieved. Only present final answer in details of row, instead of giving a sheet format.\n",
        "\n",
        "Observation: {example_data_description}\n",
        "\n",
        "Thought: Now that I have the necessary data, I would construct the objective function and constraints using the retrieved data as parameters of the formula. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula according to the retrieved 'product id'. Do NOT include any explanations, notes, or extra text. Respond ONLY in this exact format: {label}. Following this example. The expressions should not be simplified or abbreviated. Besides, I need to use the $$ or $ to wrap the mathematical expressions instead of \\[, \\], \\( or \\). I also should avoid using align, align* and other latex environments. Besides, I should also avoid using \\begin, \\end, \\text.\n",
        "\n",
        "Final Answer: \n",
        "{label}\n",
        "\"\"\")\n",
        "        \n",
        "    data = []\n",
        "    dfs=[]\n",
        "    file_addresses = dataset_address.strip().split('\\n')\n",
        "    df_index = 0\n",
        "    data_description = \" \"\n",
        "    for file_address in file_addresses:\n",
        "        try:\n",
        "            df = pd.read_csv(file_address) \n",
        "            file_name = file_address.split('/')[-1] \n",
        "            matrix = df.iloc[:,1:].values\n",
        "            data_description +=\"C=\" + np.array_str(matrix)+ \".\"\n",
        "            dfs.append((file_name, df))\n",
        "            df_index += 1\n",
        "            dfs.append((file_name, df))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file {file_address}: {e}\")\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_texts([data_description], embeddings)\n",
        "\n",
        "    retriever = vectors.as_retriever(max_tokens_limit=400, search_kwargs={'k': 1}) \n",
        "    llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4.1', top_p=1,n = 1,openai_api_key=user_api_key)\n",
        "\n",
        "    system_prompt = (\n",
        "        \"Retrieve the documents in order from top to bottom. Use the retrieved context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, retrieve all the data instead.\"\n",
        "        \"Context: {context}\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            (\"human\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "    question_answer_chain = create_stuff_documents_chain(llm2, prompt)\n",
        "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "    def qa_wrapper(query: str):\n",
        "        return qa_chain.invoke({\"input\": query})['answer']\n",
        "    qa_tool = Tool(\n",
        "        name=\"CSVQA\",\n",
        "        func=qa_wrapper,\n",
        "        description=\"Use this tool to answer Querys based on the provided CSV data and retrieve product data similar to the input query.\"\n",
        "    )\n",
        "\n",
        "    prefix = f\"\"\"You are an assistant that generates a mathematical model based on the user's description and provided CSV data.\n",
        "\n",
        "            Please refer to the following example and generate the answer in the same format:\n",
        "\n",
        "            {few_shot_examples}\n",
        "\n",
        "            Note: Please retrieve all neccessary information from the CSV file to generate the answer. When you generate the answer, please output required parameters in a whole text, including all vectors and matrices.\n",
        "\n",
        "            When you need to retrieve information from the CSV file, use the provided tool.\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "    suffix = \"\"\"\n",
        "\n",
        "            Begin!\n",
        "\n",
        "            User Description: {input}\n",
        "            {agent_scratchpad}\"\"\"\n",
        "\n",
        "    agent2 = initialize_agent(\n",
        "        tools=[qa_tool],\n",
        "        llm=llm2,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        agent_kwargs={\n",
        "            \"prefix\": prefix,\n",
        "            \"suffix\": suffix,\n",
        "        },\n",
        "        verbose=True,\n",
        "        handle_parsing_errors=True\n",
        "    )\n",
        "\n",
        "    result = agent2.invoke(query)\n",
        "    output = result['output']\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_FLP_response(query,dataset_address):\n",
        "    retrieve='supplier'\n",
        "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_FLP2_MD.csv\", encoding=\"utf-8\")\n",
        "    data = loader.load()\n",
        "\n",
        "    documents = data\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_documents(documents, embeddings)\n",
        "    retriever = vectors.as_retriever(max_tokens_limit=400,search_kwargs={'k': 1})\n",
        "    few_shot_examples = []\n",
        "    similar_results =  retrieve_similar_docs(query,retriever)\n",
        "    for i, result in enumerate(similar_results, 1):\n",
        "        content = result['content']\n",
        "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
        "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip() \n",
        "\n",
        "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
        "        data_address = split_at_address[0].strip()\n",
        "\n",
        "        file_addresses = data_address.strip().split('\\n')\n",
        "        dfs = []\n",
        "        df_index = 0\n",
        "        example_data_description = \" \"\n",
        "        for file_address in file_addresses:\n",
        "            try:\n",
        "                df = pd.read_csv(file_address) \n",
        "                file_name = file_address.split('/')[-1]  \n",
        "                if df_index == 0:\n",
        "                    result = df['demand'].values.tolist()\n",
        "                    example_data_description += \"d=\" + str(result) + \"\\n\"\n",
        "                elif df_index == 1:\n",
        "                    result = df['fixed_costs'].values.tolist()\n",
        "                    example_data_description +=\"c=\" + str(result) + \"\\n\"\n",
        "                elif df_index == 2:\n",
        "                    matrix = df.iloc[:,1:].values\n",
        "                    example_data_description +=\"A=\" + np.array_str(matrix)+ \".\"\n",
        "                df_index += 1\n",
        "                dfs.append((file_name, df))\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading file {file_address}: {e}\")\n",
        "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
        "        label = split_at_label[0].strip() \n",
        "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
        "        Related=''\n",
        "\n",
        "        few_shot_examples.append( f\"\"\"\n",
        "Question: Based on the following problem description and data, please formulate a complete mathematical model using real data from retrieval. {problem_description}\n",
        "\n",
        "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. Pay attention: 1. If the data to be retrieved is not specified, retrieve the whole dataset instead. 2. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. 3. The final expressions should not be simplified or abbreviated.\n",
        "\n",
        "Action: CSVQA\n",
        "\n",
        "Action Input: Retrieve all the {retrieve} data {Related} to formulate the mathematical model with no simplification or abbreviation. Retrieve the documents in order. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, make sure that all the data is retrieved. Only present final answer in details of row, instead of giving a sheet format.\n",
        "\n",
        "Observation: {example_data_description}\n",
        "\n",
        "Thought: Now that I have the necessary data, I would construct the objective function and constraints using the retrieved data as parameters of the formula. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. Do NOT include any explanations, notes, or extra text. Respond ONLY in this exact format: {label}. Following this example. The expressions should not be simplified or abbreviated. Besides, I need to use the $$ or $ to wrap the mathematical expressions instead of \\[, \\], \\( or \\). I also should avoid using align, align* and other latex environments. Besides, I should also avoid using \\begin, \\end, \\text.\n",
        "\n",
        "Final Answer: \n",
        "{label}\n",
        "\"\"\")\n",
        "\n",
        "    data = []\n",
        "    dfs=[]\n",
        "    file_addresses = dataset_address.strip().split('\\n')\n",
        "    df_index = 0\n",
        "    data_description = \" \"\n",
        "    for file_address in file_addresses:\n",
        "        try:\n",
        "            df = pd.read_csv(file_address) \n",
        "            file_name = file_address.split('/')[-1] \n",
        "            if df_index == 0:\n",
        "                result = df['demand'].values.tolist()\n",
        "                data_description += \"d=\" + str(result) + \"\\n\"\n",
        "            elif df_index == 1:\n",
        "                result = df['fixed_costs'].values.tolist()\n",
        "                data_description +=\"c=\" + str(result) + \"\\n\"\n",
        "            elif df_index == 2:\n",
        "                matrix = df.iloc[:,1:].values\n",
        "                data_description +=\"A=\" + np.array_str(matrix)+ \"\\n\"\n",
        "            df_index += 1\n",
        "            dfs.append((file_name, df))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file {file_address}: {e}\")\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_texts([data_description], embeddings)\n",
        "\n",
        "    retriever = vectors.as_retriever(max_tokens_limit=400, search_kwargs={'k': 1}) \n",
        "    llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4.1', top_p=1,n = 1, openai_api_key=user_api_key)\n",
        "    \n",
        "    system_prompt = (\n",
        "        \"Retrieve the documents in order. Use the given context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, make sure that all the data is retrieved.\"\n",
        "        \"Context: {context}\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            (\"human\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "    question_answer_chain = create_stuff_documents_chain(llm2, prompt)\n",
        "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "    def qa_wrapper(query: str):\n",
        "        return qa_chain.invoke({\"input\": query})['answer']\n",
        "    qa_tool = Tool(\n",
        "        name=\"CSVQA\",\n",
        "        func=qa_wrapper,\n",
        "        description=\"Use this tool to answer Querys based on the provided CSV data and retrieve product data similar to the input query.\"\n",
        "    )\n",
        "\n",
        "    prefix = f\"\"\"You are an assistant that generates a mathematical model based on the user's description and provided CSV data.\n",
        "\n",
        "            Please refer to the following example and generate the answer in the same format:\n",
        "\n",
        "            {few_shot_examples}\n",
        "\n",
        "            Note: Please retrieve all neccessary information from the CSV file to generate the answer. When you generate the answer, please output required parameters in a whole text, including all vectors and matrices.\n",
        "\n",
        "            When you need to retrieve information from the CSV file, use the provided tool.\n",
        "\n",
        "            \"\"\"\n",
        "\n",
        "    suffix = \"\"\"\n",
        "            Begin!\n",
        "\n",
        "            User Description: {input}\n",
        "            {agent_scratchpad}\"\"\"\n",
        "\n",
        "    agent2 = initialize_agent(\n",
        "        tools=[qa_tool],\n",
        "        llm=llm2,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        agent_kwargs={\n",
        "            \"prefix\": prefix,\n",
        "            \"suffix\": suffix,\n",
        "        },\n",
        "        verbose=True,\n",
        "        handle_parsing_errors=True\n",
        "    )\n",
        "\n",
        "    result = agent2.invoke(query)\n",
        "    output = result['output']\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Others With CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_Others_response(query,dataset_address):\n",
        "\n",
        "    retrieve=\"all data\"\n",
        "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_Others.csv\", encoding=\"utf-8\")\n",
        "    data = loader.load()\n",
        "\n",
        "    # Each line is a document\n",
        "    documents = data\n",
        "\n",
        "    # Create embeddings and vector store\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "    # Create a retriever\n",
        "    retriever = vectors.as_retriever(search_kwargs={'k': 3})\n",
        "    few_shot_examples = []\n",
        "    similar_results =  retrieve_similar_docs(query,retriever)\n",
        "    for i, result in enumerate(similar_results, 1):\n",
        "        content = result['content']\n",
        "\n",
        "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
        "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip() \n",
        "\n",
        "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
        "        data_address = split_at_address[0].strip()\n",
        "\n",
        "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
        "        label = split_at_label[0].strip()  \n",
        "        Related = split_at_label[1].strip()\n",
        "\n",
        "        datas=data_address.split()\n",
        "        information = []\n",
        "\n",
        "        for data in datas:\n",
        "            information.append(pd.read_csv(data))\n",
        "        example_data_description = \"\\nHere is the data:\\n\"\n",
        "        for df_index, df in enumerate(information):\n",
        "            for z, r in df.iterrows():\n",
        "                description = \"\"\n",
        "                description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
        "                example_data_description += description + \"\\n\"\n",
        "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
        "        few_shot_examples.append( f\"\"\"\n",
        "Question: Based on the following problem description and data, please formulate a complete mathematical model using real data from retrieval. {problem_description}\n",
        "\n",
        "Thought: I need to formulate the objective function and constraints of the linear programming model based on the user's description and the provided data. I should retrieve the relevant information from the CSV file. If the data to be retrieved is not specified, retrieve the whole dataset instead. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula. The final expressions should not be simplified or abbreviated.\n",
        "\n",
        "Action: CSVQA\n",
        "\n",
        "Action Input: Retrieve all the {retrieve} data related to {Related} to formulate the mathematical model with no simplification or abbreviation.\n",
        "\n",
        "Observation: \n",
        "\n",
        "Thought: Now that I have the necessary data, I would construct the objective function and constraints using the retrieved data as parameters of the formula. I should pay attention if there is further detailed constraint in the problem description. If so, I should generate additional constraint formula according to the retrieved 'product id'.  Respond ONLY in this exact format: {label}. Do NOT include any explanations, notes, or extra text. The expressions should not be simplified or abbreviated. \n",
        "\n",
        "Final Answer: \n",
        "{label}\n",
        "\"\"\")\n",
        "\n",
        "    data = []\n",
        "    dfs=[]\n",
        "\n",
        "    file_addresses = dataset_address.strip().split('\\n')\n",
        "    for file_address in file_addresses:\n",
        "        try:\n",
        "            df = pd.read_csv(file_address) \n",
        "            file_name = file_address.split('/')[-1]  \n",
        "            dfs.append((file_name, df))\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file {file_address}: {e}\")\n",
        "\n",
        "    for df_index, (file_name, df) in enumerate(dfs):\n",
        "        data.append(f\"\\nDataFrame {df_index + 1} - {file_name}:\\n\")\n",
        "        for i, r in df.iterrows():\n",
        "            description = f\"\"\n",
        "            description += \", \".join([f\"{col} = {r[col]}\" for col in df.columns])\n",
        "            data.append(description + \"\\n\")\n",
        "\n",
        "    \n",
        "    documents = [content for content in data]\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_texts(documents, embeddings)\n",
        "    retriever = vectors.as_retriever(search_kwargs={'k': 220})\n",
        "    llm2 = ChatOpenAI(temperature=0.0, model_name='gpt-4.1', openai_api_key=user_api_key)\n",
        "\n",
        "\n",
        "    system_prompt = (\n",
        "        \"Retrieve the documents in order from top to bottom. Use the retrieved context to answer the question. If mention a certain kind of product, retrieve all the relavant product information detail judging by its product name. If not mention a certain kind of product, retrieve all the data instead.\"\n",
        "        \"Context: {context}\"\n",
        "    )\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\"system\", system_prompt),\n",
        "            (\"human\", \"{input}\"),\n",
        "        ]\n",
        "    )\n",
        "    question_answer_chain = create_stuff_documents_chain(llm2, prompt)\n",
        "    qa_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
        "    def qa_wrapper(query: str):\n",
        "        return qa_chain.invoke({\"input\": query})\n",
        "    qa_tool = Tool(\n",
        "        name=\"CSVQA\",\n",
        "        func=qa_wrapper,\n",
        "        description=\"Use this tool to answer Querys based on the provided CSV data and retrieve product data similar to the input query.\"\n",
        "    )\n",
        "\n",
        "    prefix = f\"\"\"You are an assistant that generates a mathematical models based on the user's description and provided CSV data.\n",
        "\n",
        "    Please refer to the following example and generate the answer in the same format:\n",
        "\n",
        "    {few_shot_examples}\n",
        "\n",
        "    When you need to retrieve information from the CSV file, use the provided tool.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    suffix = \"\"\"\n",
        "\n",
        "    Begin!\n",
        "\n",
        "    User Description: {input}\n",
        "    {agent_scratchpad}\"\"\"\n",
        "\n",
        "    agent2 = initialize_agent(\n",
        "        tools=[qa_tool],\n",
        "        llm=llm2,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        agent_kwargs={\n",
        "            \"prefix\": prefix,\n",
        "            \"suffix\": suffix,\n",
        "        },\n",
        "        verbose=True,\n",
        "        handle_parsing_errors=True,\n",
        "    )\n",
        "\n",
        "    result = agent2.invoke(query)\n",
        "\n",
        "    return result['output']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Others Without CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_others_without_CSV_response(query):\n",
        "    llm = ChatOpenAI(\n",
        "                    temperature=0.0, model_name=\"gpt-4.1\", top_p=1, n = 1, openai_api_key=user_api_key\n",
        "                )\n",
        "\n",
        "    loader = CSVLoader(file_path=\"Large_Scale_Or_Files/RAG_Example_Others_Without_CSV.csv\", encoding=\"utf-8\")\n",
        "    data = loader.load()\n",
        "\n",
        "    documents = data\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=user_api_key)\n",
        "    vectors = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "    retriever = vectors.as_retriever(search_kwargs={'k': 5})\n",
        "\n",
        "    \n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "    )\n",
        "\n",
        "    qa_tool = Tool(\n",
        "        name=\"ORLM_QA\",\n",
        "        func=qa_chain.invoke,\n",
        "        description=(\n",
        "            \"Use this tool to answer Querys.\"\n",
        "            \"Provide the Query as input, and the tool will retrieve the relevant information from the file and use it to answer the Query.\"\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    few_shot_examples = []\n",
        "    similar_results = retrieve_similar_docs(query,retriever)\n",
        "\n",
        "    for i, result in enumerate(similar_results, 1):\n",
        "        content = result['content']\n",
        "\n",
        "        split_at_formulation = content.split(\"Data_address:\", 1)\n",
        "        problem_description = split_at_formulation[0].replace(\"prompt:\", \"\").strip()\n",
        "\n",
        "        split_at_address = split_at_formulation[1].split(\"Label:\", 1)\n",
        "        data_address = split_at_address[0].strip()\n",
        "\n",
        "        split_at_label = split_at_address[1].split(\"Related:\", 1)\n",
        "        label = split_at_label[0].strip() \n",
        "\n",
        "        split_at_type = split_at_address[1].split(\"problem type:\", 1)\n",
        "        Related = split_at_type[0].strip() \n",
        "\n",
        "        selected_problem = split_at_type[1].strip()\n",
        "\n",
        "        label = label.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
        "\n",
        "        example = f\"\"\"\n",
        "\n",
        "Query: {problem_description}\n",
        "\n",
        "Thought: I need to formulate the mathematical model for this problem. I'll use the ORLM_QA tool to retrieve the most similar use case and learn the method and formulation for generating the answer (label) for user's query. Always note whether to add additional integer constraints (or real number) is decided according to the realistic significance of the problem and the characteristics of the variables.\n",
        "\n",
        "Action: ORLM_QA\n",
        "\n",
        "Action Input: {problem_description}\n",
        "\n",
        "Observation: \n",
        "\n",
        "Thought: Respond ONLY in this exact format: {label}. Do NOT include any explanations, notes, or extra text. The expressions should not be simplified or abbreviated. Just give the formula, no need to generate final answer. Add default constraints that the variables are nonnegative integers, or nonnegative real numbers if specified in the query.\n",
        "\n",
        "Final Answer: \n",
        "{label}\n",
        "\n",
        "\"\"\"\n",
        "        example = example.replace(\"{\", \"{{\").replace(\"}\", \"}}\")\n",
        "        few_shot_examples.append(example)\n",
        "\n",
        "    prefix = f\"\"\"You are a helpful assistant that can answer Querys about operation problems. \n",
        "\n",
        "    Use the following examples as a guide. Always use the ORLM_QA tool when you need to retrieve information from the file:\n",
        "\n",
        "    {few_shot_examples}\n",
        "\n",
        "    When you need to find information from the file, use the provided tools.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    suffix = \"\"\"\n",
        "\n",
        "    Begin!\n",
        "\n",
        "    Query: {input}\n",
        "    {agent_scratchpad}\"\"\"\n",
        "\n",
        "    agent = initialize_agent(\n",
        "        tools=[qa_tool],\n",
        "        llm=llm,\n",
        "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "        agent_kwargs={\n",
        "            \"prefix\": prefix,\n",
        "            \"suffix\": suffix,\n",
        "        },\n",
        "        verbose=True,\n",
        "        handle_parsing_errors=True,  # Enable error handling\n",
        "    )\n",
        "\n",
        "    openai.api_request_timeout = 60  \n",
        "    query = query.replace('{','{{').replace('}','}}')\n",
        "    output = agent.invoke(query)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Code Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_code(output,selected_problem):\n",
        "    llm_code = ChatOpenAI(\n",
        "        temperature=0.0, model_name=\"gpt-4.1\",top_p=1,n = 1, openai_api_key=user_api_key\n",
        "    )\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    You are an expert in mathematical optimization and Python programming. Your task is to write Python code to solve the provided mathematical optimization model using the Gurobi library. The code should include the definition of the objective function, constraints, and decision variables. Please don't add additional explanations. Please don't include ```python and ```.Below is the provided mathematical optimization model:\n",
        "\n",
        "    Mathematical Optimization Model:\n",
        "    {output}\n",
        "    \"\"\"\n",
        "\n",
        "    if selected_problem == \"Network Revenue Management\" or selected_problem == \"NRM\" or selected_problem == \"Network Revenue Management Problem\":\n",
        "\n",
        "        prompt += \"\"\"\n",
        "For example, here is a simple instance for reference:\n",
        "\n",
        "Mathematical Optimization Model:\n",
        "\n",
        "Objective Function:\n",
        "$\\quad \\quad \\max \\quad \\sum_i A_i \\cdot x_i$\n",
        "Constraints\n",
        "1. Inventory Constraints:\n",
        "$\\quad \\quad x_i \\leq I_i, \\quad \\forall i$\n",
        "2. Demand Constraints:\n",
        "$x_i \\leq d_i, \\quad \\forall i$\n",
        "3. Startup Constraint:\n",
        "$\\sum_i x_i \\geq s$\n",
        "Retrieved Information\n",
        "$\\small I = [7550, 6244]$\n",
        "$\\small A = [149, 389]$\n",
        "$\\small d = [15057, 12474]$\n",
        "$\\small s = 100$\n",
        "\n",
        "The corresponding Python code for this instance is as follows:\n",
        "\n",
        "```python\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "\n",
        "# Create the model\n",
        "m = gp.Model(\"Product_Optimization\")\n",
        "\n",
        "# Decision variables for the number of units of each product\n",
        "x_1 = m.addVar(vtype=GRB.INTEGER, name=\"x_1\") # Number of units of product 1\n",
        "x_2 = m.addVar(vtype=GRB.INTEGER, name=\"x_2\") # Number of units of product 2\n",
        "\n",
        "# Objective function: Maximize 149 x_1 + 389 x_2\n",
        "m.setObjective(149 * x_1 + 389 * x_2, GRB.MAXIMIZE)\n",
        "\n",
        "# Constraints\n",
        "m.addConstr(x_1 <= 7550, name=\"inventory_constraint_1\")\n",
        "m.addConstr(x_2 <= 6244, name=\"inventory_constraint_2\")\n",
        "m.addConstr(x_1 <= 15057, name=\"demand_constraint_1\")\n",
        "m.addConstr(x_2 <= 12474, name=\"demand_constraint_2\")\n",
        "\n",
        "# Non-negativity constraints are implicitly handled by the integer constraints (x_1, x_2 >= 0)\n",
        "\n",
        "# Solve the model\n",
        "m.optimize()\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "    elif selected_problem == \"Facility Location Problem\" or selected_problem == \"FLP\" or selected_problem == \"Facility Location\":\n",
        "        prompt += \"\"\"\n",
        "For example, here is a simple instance for reference:\n",
        "\n",
        "Mathematical Optimization Model:\n",
        "\n",
        "Objective Function:\n",
        "$\\quad \\quad \\min \\quad \\sum_{i} \\sum_{j} A_{ij} \\cdot x_{ij} + \\sum_{i} c_i \\cdot y_i$\n",
        "\n",
        "Constraints\n",
        "1. Demand Constraint:\n",
        "$\\quad \\quad \\sum_i x_{ij} = d_j, \\quad \\forall j$\n",
        "2. Capacity Constraint:\n",
        "$\\quad \\quad \\sum_j x_{ij} \\leq M \\cdot y_i, \\quad \\forall i$\n",
        "3. Non-negativity:\n",
        "$\\quad \\quad x_{ij} \\geq 0, \\quad \\forall i,j$\n",
        "4. Binary Requirement:\n",
        "$\\quad \\quad y_i \\in \\{0,1\\}, \\quad \\forall i$\n",
        "\n",
        "Retrieved Information\n",
        "$\\small d = [1083, 776, 16214, 553, 17106, 594, 732]$\n",
        "$\\small c = [102.33, 94.92, 91.83, 98.71, 95.73, 99.96, 98.16]$\n",
        "$\\small A = \\begin{bmatrix}\n",
        "1506.22 & 70.90 & 8.44 & 260.27 & 197.47 & 71.71 & 61.19 \\\\  \n",
        "1732.65 & 1780.72 & 567.44 & 448.68 & 29.00 & 1484.91 & 963.92 \\\\  \n",
        "115.66 & 100.76 & 64.68 & 1324.53 & 64.99 & 134.88 & 2102.83 \\\\  \n",
        "1254.78 & 1115.63 & 52.31 & 1036.16 & 892.63 & 1464.04 & 1383.41 \\\\  \n",
        "42.90 & 891.01 & 1013.94 & 1128.72 & 58.91 & 42.89 & 1570.31 \\\\  \n",
        "0.70 & 139.46 & 70.03 & 79.15 & 1482.00 & 0.91 & 110.46 \\\\  \n",
        "1732.30 & 1780.44 & 486.50 & 523.74 & 522.08 & 82.48 & 826.41\n",
        "\\end{bmatrix}$\n",
        "$\\small M = \\sum_j d_j = 1083 + 776 + 16214 + 553 + 17106 + 594 + 732 = 38058 $\n",
        "\n",
        "\n",
        "The corresponding Python code for this instance is as follows:\n",
        "\n",
        "```python\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "d = np.array([1083, 776, 16214, 553, 17106, 594, 732])\n",
        "c = np.array([102.33, 94.92, 91.83, 98.71, 95.73, 99.96, 98.16])\n",
        "A = np.array([[1506.22, 70.90, 8.44, 260.27, 197.47, 71.71, 61.19],  \n",
        "[1732.65, 1780.72, 567.44, 448.68, 29.00, 1484.91, 963.92],  \n",
        "[115.66, 100.76, 64.68, 1324.53, 64.99, 134.88, 2102.83],  \n",
        "[1254.78, 1115.63, 52.31, 1036.16, 892.63, 1464.04, 1383.41],  \n",
        "[42.90, 891.01, 1013.94, 1128.72, 58.91, 42.89, 1570.31],  \n",
        "[0.70, 139.46, 70.03, 79.15, 1482.00, 0.91, 110.46],  \n",
        "[1732.30, 1780.44, 486.50, 523.74, 522.08, 82.48, 826.41]])\n",
        "\n",
        "# Create the model\n",
        "m = gp.Model(\"Optimization_Model\")\n",
        "\n",
        "# Decision variables\n",
        "x = m.addVars(A.shape[0], A.shape[1], lb=0, name=\"x\")\n",
        "y = m.addVars(A.shape[0], vtype=GRB.BINARY, name=\"y\")\n",
        "\n",
        "# Objective function\n",
        "m.setObjective(gp.quicksum(A[i, j]*x[i, j] for i in range(A.shape[0]) for j in range(A.shape[1])) + gp.quicksum(c[i]*y[i] for i in range(A.shape[0])), GRB.MINIMIZE)\n",
        "\n",
        "# Constraints\n",
        "for j in range(A.shape[1]):\n",
        "    m.addConstr(gp.quicksum(x[i, j] for i in range(A.shape[0])) == d[j], name=f\"demand_constraint_{j}\")\n",
        "\n",
        "M = 1000000  # large number\n",
        "for i in range(A.shape[0]):\n",
        "    m.addConstr(-M*y[i] + gp.quicksum(x[i, j] for j in range(A.shape[1])) <= 0, name=f\"M_constraint_{i}\")\n",
        "\n",
        "# Solve the model\n",
        "m.optimize()\n",
        "        \"\"\"\n",
        "\n",
        "    elif selected_problem == \"Assignment Problem\" or selected_problem == \"AP\" or selected_problem == \"Assignment\":\n",
        "        prompt += \"\"\"\n",
        "For example, here is a simple instance for reference:\n",
        "\n",
        "Mathematical Optimization Model:\n",
        "\n",
        "Objective Function:\n",
        "$\\quad \\quad \\min \\quad \\sum_{i=1}^3 \\sum_{j=1}^3 c_{ij} \\cdot x_{ij}$\n",
        "\n",
        "Constraints\n",
        "1. Row Assignment Constraint:\n",
        "$\\quad \\quad \\sum_{j=1}^3 x_{ij} = 1, \\quad \\forall i \\in \\{1,2,3\\}$\n",
        "2. Column Assignment Constraint:\n",
        "$\\quad \\quad \\sum_{i=1}^3 x_{ij} = 1, \\quad \\forall j \\in \\{1,2,3\\}$\n",
        "3. Binary Constraint:\n",
        "$\\quad \\quad x_{ij} \\in \\{0,1\\}, \\quad \\forall i,j$\n",
        "\n",
        "Retrieved Information\n",
        "$\\small c = \\begin{bmatrix}\n",
        "3000 & 3200 & 3100 \\\\\n",
        "2800 & 3300 & 2900 \\\\\n",
        "2900 & 3100 & 3000 \n",
        "\\end{bmatrix}$\n",
        "\n",
        "The corresponding Python code for this instance is as follows:\n",
        "\n",
        "```python\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "c = np.array([\n",
        "    [3000, 3200, 3100],\n",
        "    [2800, 3300, 2900],\n",
        "    [2900, 3100, 3000]\n",
        "])\n",
        "\n",
        "# Create the model\n",
        "m = gp.Model(\"Optimization_Model\")\n",
        "\n",
        "# Decision variables\n",
        "x = m.addVars(c.shape[0], c.shape[1], vtype=GRB.BINARY, name=\"x\")\n",
        "\n",
        "# Objective function\n",
        "m.setObjective(gp.quicksum(c[i, j]*x[i, j] for i in range(c.shape[0]) for j in range(c.shape[1])), GRB.MINIMIZE)\n",
        "\n",
        "# Constraints\n",
        "for i in range(c.shape[0]):\n",
        "    m.addConstr(gp.quicksum(x[i, j] for j in range(c.shape[1])) == 1, name=f\"row_constraint_{i}\")\n",
        "\n",
        "for j in range(c.shape[1]):\n",
        "    m.addConstr(gp.quicksum(x[i, j] for i in range(c.shape[0])) == 1, name=f\"col_constraint_{j}\")\n",
        "\n",
        "# Solve the model\n",
        "m.optimize()\n",
        "\"\"\"\n",
        "\n",
        "    \n",
        "    elif selected_problem == \"Transportation Problem\" or selected_problem == \"TP\" or selected_problem == \"Transportation\":\n",
        "        prompt += \"\"\"\n",
        "For example, here is a simple instance for reference:\n",
        "\n",
        "Mathematical Optimization Model:\n",
        "\n",
        "Objective Function:\n",
        "$\\quad \\quad \\min \\quad \\sum_i \\sum_j c_{ij} \\cdot x_{ij}$\n",
        "\n",
        "Constraints\n",
        "1. Demand Constraint:\n",
        "$\\quad \\quad \\sum_i x_{ij} \\geq d_j, \\quad \\forall j$\n",
        "2. Capacity Constraint:\n",
        "$\\quad \\quad \\sum_j x_{ij} \\leq s_i, \\quad \\forall i$\n",
        "\n",
        "Retrieved Information\n",
        "$\\small d = [94, 39, 65, 435]$\n",
        "$\\small s = [2531, 20, 210, 241]$\n",
        "$\\small c = \\begin{bmatrix}\n",
        "883.91 & 0.04 & 0.03 & 44.45 \\\\\n",
        "543.75 & 23.68 & 23.67 & 447.75 \\\\\n",
        "537.34 & 23.76 & 498.95 & 440.60 \\\\\n",
        "1791.49 & 68.21 & 1432.48 & 1527.76\n",
        "\\end{bmatrix}$\n",
        "\n",
        "The corresponding Python code for this instance is as follows:\n",
        "\n",
        "```python\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "\n",
        "# Create the model\n",
        "m = gp.Model(\"Optimization\")\n",
        "\n",
        "# Decision variables\n",
        "x_S1_C1 = m.addVar(vtype=GRB.INTEGER, name=\"x_S1_C1\")\n",
        "x_S1_C2 = m.addVar(vtype=GRB.INTEGER, name=\"x_S1_C2\")\n",
        "x_S1_C3 = m.addVar(vtype=GRB.INTEGER, name=\"x_S1_C3\")\n",
        "x_S1_C4 = m.addVar(vtype=GRB.INTEGER, name=\"x_S1_C4\")\n",
        "x_S2_C1 = m.addVar(vtype=GRB.INTEGER, name=\"x_S2_C1\")\n",
        "x_S2_C2 = m.addVar(vtype=GRB.INTEGER, name=\"x_S2_C2\")\n",
        "x_S2_C3 = m.addVar(vtype=GRB.INTEGER, name=\"x_S2_C3\")\n",
        "x_S2_C4 = m.addVar(vtype=GRB.INTEGER, name=\"x_S2_C4\")\n",
        "x_S3_C1 = m.addVar(vtype=GRB.INTEGER, name=\"x_S3_C1\")\n",
        "x_S3_C2 = m.addVar(vtype=GRB.INTEGER, name=\"x_S3_C2\")\n",
        "x_S3_C3 = m.addVar(vtype=GRB.INTEGER, name=\"x_S3_C3\")\n",
        "x_S3_C4 = m.addVar(vtype=GRB.INTEGER, name=\"x_S3_C4\")\n",
        "x_S4_C1 = m.addVar(vtype=GRB.INTEGER, name=\"x_S4_C1\")\n",
        "x_S4_C2 = m.addVar(vtype=GRB.INTEGER, name=\"x_S4_C2\")\n",
        "x_S4_C3 = m.addVar(vtype=GRB.INTEGER, name=\"x_S4_C3\")\n",
        "x_S4_C4 = m.addVar(vtype=GRB.INTEGER, name=\"x_S4_C4\")\n",
        "\n",
        "# Objective function\n",
        "m.setObjective(883.91 * x_S2_C1 + 0.04 * x_S2_C2 + 0.03 * x_S2_C3 + 44.45 * x_S2_C4 + 543.75 * x_S1_C1 + 23.68 * x_S1_C2 + 23.67 * x_S1_C3 + 447.75 * x_S1_C4 + 537.34 * x_S3_C1 + 23.76 * x_S3_C2 + 498.95 * x_S3_C3 + 440.60 * x_S3_C4 + 1791.49 * x_S4_C1 + 68.21 * x_S4_C2 + 1432.48 * x_S4_C3 + 1527.76 * x_S4_C4, GRB.MINIMIZE)\n",
        "\n",
        "# Constraints\n",
        "m.addConstr(x_S1_C1 + x_S2_C1 + x_S3_C1 + x_S4_C1 >= 94, name=\"demand_constraint1\")\n",
        "m.addConstr(x_S1_C2 + x_S2_C2 + x_S3_C2 + x_S4_C2 >= 39, name=\"demand_constraint2\")\n",
        "m.addConstr(x_S1_C3 + x_S2_C3 + x_S3_C3 + x_S4_C3 >= 65, name=\"demand_constraint3\")\n",
        "m.addConstr(x_S1_C4 + x_S2_C4 + x_S3_C4 + x_S4_C4 >= 435, name=\"demand_constraint4\")\n",
        "m.addConstr(x_S1_C1 + x_S1_C2 + x_S1_C3 + x_S1_C4 <= 2531, name=\"capacity_constraint1\")\n",
        "m.addConstr(x_S2_C1 + x_S2_C2 + x_S2_C3 + x_S2_C4 <= 20, name=\"capacity_constraint2\")\n",
        "m.addConstr(x_S3_C1 + x_S3_C2 + x_S3_C3 + x_S3_C4 <= 210, name=\"capacity_constraint3\")\n",
        "m.addConstr(x_S4_C1 + x_S4_C2 + x_S4_C3 + x_S4_C4 <= 241, name=\"capacity_constraint4\")\n",
        "\n",
        "# Solve the model\n",
        "m.optimize()\n",
        "        \"\"\"\n",
        "    \n",
        "    elif selected_problem == \"Resource Allocation\" or selected_problem == \"RA\" or selected_problem == \"Resource Allocation Problem\":\n",
        "        prompt += \"\"\"\n",
        "For example, here is a simple instance for reference:\n",
        "\n",
        "Always remember: If not specified. All the variables are non-negative interger.\n",
        "\n",
        "Mathematical Optimization Model:\n",
        "\n",
        "Objective Function:\n",
        "$\\quad \\quad \\max \\quad \\sum_i \\sum_j p_i \\cdot x_{ij}$\n",
        "\n",
        "Constraints\n",
        "1. Capacity Constraint:\n",
        "$\\quad \\quad \\sum_i a_i \\cdot x_{ij} \\leq c_j, \\quad \\forall j$\n",
        "2. Non-negativity Constraint:\n",
        "$\\quad \\quad x_{ij} \\geq 0, \\quad \\forall i,j$\n",
        "\n",
        "Retrieved Information\n",
        "$\\small p = [321, 309, 767, 300, 763, 318, 871, 522, 300, 275, 858, 593, 126, 460, 685, 443, 700, 522, 940, 598]$\n",
        "$\\small a = [495, 123, 165, 483, 472, 258, 425, 368, 105, 305, 482, 387, 469, 341, 318, 104, 377, 213, 56, 131]$\n",
        "$\\small c = [4466]$\n",
        "\n",
        "The corresponding Python code for this instance is as follows:\n",
        "\n",
        "```python\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "\n",
        "# Create the model\n",
        "m = gp.Model(\"Optimization_Model\")\n",
        "\n",
        "# Decision variables\n",
        "x = m.addVars(20, vtype=GRB.INTEGER, name=\"x\")\n",
        "\n",
        "# Objective function\n",
        "m.setObjective(sum(x[i]*c[i] for i in range(20)), GRB.MAXIMIZE)\n",
        "\n",
        "# Constraints\n",
        "m.addConstr(sum(x[i]*w[i] for i in range(20)) <= 4466, name=\"capacity_constraint\")\n",
        "\n",
        "# Coefficients for the objective function\n",
        "c = [321, 309, 767, 300, 763, 318, 871, 522, 300, 275, 858, 593, 126, 460, 685, 443, 700, 522, 940, 598]\n",
        "\n",
        "# Coefficients for the capacity constraint\n",
        "w = [495, 123, 165, 483, 472, 258, 425, 368, 105, 305, 482, 387, 469, 341, 318, 104, 377, 213, 56, 131]\n",
        "\n",
        "# Solve the model\n",
        "m.optimize()\n",
        "```\n",
        "\n",
        "-----\n",
        "Here is another simple instance for reference:\n",
        "\n",
        "Objective Function:\n",
        "$\\quad \\quad \\max \\quad \\sum_i p_i \\cdot x_i$\n",
        "\n",
        "Constraints\n",
        "1. Capacity Constraint:\n",
        "$\\quad \\quad \\sum_i a_i \\cdot x_i \\leq 180$\n",
        "2. Dependency Constraint:\n",
        "$\\quad \\quad x_1 \\leq x_3$\n",
        "3. Non-negativity Constraint:\n",
        "$\\quad \\quad x_i \\geq 0, \\quad \\forall i$\n",
        "\n",
        "Retrieved Information\n",
        "$\\small p = [888, 134, 129, 370, 921, 765, 154, 837, 584, 365]$\n",
        "$\\small a = [4, 2, 4, 3, 2, 1, 2, 1, 3, 3]$\n",
        "\n",
        "The corresponding Python code for this instance is as follows:\n",
        "\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "\n",
        "# Create the model\n",
        "m = gp.Model(\"Optimization_Model\")\n",
        "\n",
        "# Decision variables\n",
        "x = m.addVars(10, vtype=GRB.INTEGER, name=\"x\")\n",
        "\n",
        "# Objective function\n",
        "p = [888, 134, 129, 370, 921, 765, 154, 837, 584, 365]\n",
        "m.setObjective(sum(x[i]*p[i] for i in range(10)), GRB.MAXIMIZE)\n",
        "\n",
        "# Constraints\n",
        "a = [4, 2, 4, 3, 2, 1, 2, 1, 3, 3]\n",
        "m.addConstr(sum(x[i]*a[i] for i in range(10)) <= 180, name=\"capacity_constraint\")\n",
        "m.addConstr(x[0] <= x[2], name=\"dependency_constraint\")\n",
        "\n",
        "# Solve the model\n",
        "m.optimize()\n",
        "        \n",
        "        \"\"\"\n",
        "    else:\n",
        "        prompt += \"\"\"\n",
        "For example, here is a simple instance for reference:\n",
        "\n",
        "Mathematical Optimization Model:\n",
        "Maximize 5x_S + 8x_F\n",
        "Subject to\n",
        "    2x_S + 5x_F <= 200\n",
        "    x_S <= 0.3(x_S + x_F)\n",
        "    x_F >= 10\n",
        "    x_S, x_F _ Z+\n",
        "\n",
        "The corresponding Python code for this instance is as follows:\n",
        "\n",
        "```python\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "\n",
        "# Create the model\n",
        "m = gp.Model(\"Worker_Optimization\")\n",
        "\n",
        "# Decision variables for the number of seasonal (x_S) and full-time (x_F) workers\n",
        "x_S = m.addVar(vtype=GRB.INTEGER, lb=0, name=\"x_S\")  # Number of seasonal workers\n",
        "x_F = m.addVar(vtype=GRB.INTEGER, lb=0, name=\"x_F\")  # Number of full-time workers\n",
        "\n",
        "# Objective function: Maximize Z = 5x_S + 8x_F\n",
        "m.setObjective(5 * x_S + 8 * x_F, GRB.MAXIMIZE)\n",
        "\n",
        "# Constraints\n",
        "m.addConstr(2 * x_S + 5 * x_F <= 200, name=\"resource_constraint\")\n",
        "m.addConstr(x_S <= 0.3 * (x_S + x_F), name=\"seasonal_ratio_constraint\")\n",
        "m.addConstr(x_F >= 10, name=\"full_time_minimum_constraint\")\n",
        "\n",
        "# Non-negativity constraints are implicitly handled by the integer constraints (x_S, x_F >= 0)\n",
        "\n",
        "# Solve the model\n",
        "m.optimize()\n",
        "```\n",
        "The another example is:\n",
        "\n",
        "Mathematical Optimization Model:\n",
        "Minimize 919x_11 + 556x_12 + 951x_13 + 21x_21 + 640x_22 + 409x_23 + 59x_31 + 786x_32 + 304x_33\n",
        "Subject to\n",
        "    x_11 + x_12 + x_13 = 1\n",
        "    x_21 + x_22 + x_23 = 1\n",
        "    x_31 + x_32 + x_33 = 1\n",
        "    x_11 + x_21 + x_31 = 1\n",
        "    x_12 + x_22 + x_32 = 1\n",
        "    x_13 + x_23 + x_33 = 1\n",
        "    x_11, x_12, x_13, x_21, x_22, x_23, x_31, x_32, x_33 ∈ {{0,1}}\n",
        "\n",
        "\n",
        "The corresponding Python code for this instance is as follows:\n",
        "\n",
        "```python\n",
        "\n",
        "import gurobipy as gp\n",
        "from gurobipy import GRB\n",
        "import numpy as np\n",
        "\n",
        "# Data\n",
        "c = np.array([\n",
        "    [919, 556, 951],\n",
        "    [21, 640, 409],\n",
        "    [59, 786, 304]\n",
        "])\n",
        "\n",
        "# Create the model\n",
        "m = gp.Model(\"Optimization_Model\")\n",
        "\n",
        "# Decision variables\n",
        "x = m.addVars(c.shape[0], c.shape[1], vtype=GRB.BINARY, name=\"x\")\n",
        "\n",
        "# Objective function\n",
        "m.setObjective(gp.quicksum(c[i, j]*x[i, j] for i in range(c.shape[0]) for j in range(c.shape[1])), GRB.MINIMIZE)\n",
        "\n",
        "# Constraints\n",
        "for i in range(c.shape[0]):\n",
        "    m.addConstr(gp.quicksum(x[i, j] for j in range(c.shape[1])) == 1, name=f\"row_constraint_{i}\")\n",
        "\n",
        "for j in range(c.shape[1]):\n",
        "    m.addConstr(gp.quicksum(x[i, j] for i in range(c.shape[0])) == 1, name=f\"col_constraint_{j}\")\n",
        "\n",
        "# Solve the model\n",
        "m.optimize() \n",
        "```\n",
        "\"\"\"\n",
        "    messages = [\n",
        "        HumanMessage(content=prompt) \n",
        "    ]\n",
        "\n",
        "    response = llm_code(messages)\n",
        "\n",
        "    return response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_test(test, agent):\n",
        "    output_model = []\n",
        "    output_code = []\n",
        "    for index, row in test.iterrows():\n",
        "        try:\n",
        "            query = row['Query']\n",
        "            response = agent.invoke(f\"What is the problem type of the text? text:{query}\")\n",
        "            \n",
        "            def extract_problem_type(output_text):\n",
        "                pattern = r'(Network Revenue Management|Network Revenue Management Problem|Resource Allocation|Resource Allocation Problem|Transportation|Transportation Problem|Facility Location Problem|Assignment Problem|AP|Uncapacited Facility Location Problem|NRM|RA|TP|FLP|UFLP|Others without CSV|Sales-Based Linear Programming|SBLP|Others with CSV)'\n",
        "                match = re.search(pattern, output_text, re.IGNORECASE)\n",
        "                return match.group(0) if match else None\n",
        "            \n",
        "            def csv_detect(row):\n",
        "                return 1 if 'Dataset_address' in row.index else 0\n",
        "    \n",
        "            selected_problem = extract_problem_type(response['output'])\n",
        "            \n",
        "            if csv_detect(row):\n",
        "                dataset_address = row['Dataset_address']\n",
        "                if selected_problem == \"Network Revenue Management\" or selected_problem == \"NRM\" or selected_problem == \"Network Revenue Management Problem\":\n",
        "                    print(\"----------Network Revenue Management-----------\")\n",
        "                    output = get_NRM_response(query,dataset_address)\n",
        "                    output_model.append(output)\n",
        "                    code_response = get_code(output,selected_problem)\n",
        "                    output_code.append(code_response)\n",
        "    \n",
        "                elif selected_problem == \"Resource Allocation\" or selected_problem == \"RA\" or selected_problem == \"Resource Allocation Problem\":\n",
        "                    print(\"----------Resource Allocation-----------\")\n",
        "                    output = get_RA_response(query,dataset_address)\n",
        "                    output_model.append(output)\n",
        "                    code_response = get_code(output,selected_problem)\n",
        "                    output_code.append(code_response)\n",
        "    \n",
        "                elif selected_problem == \"Transportation\" or selected_problem == \"TP\" or selected_problem == \"Transportation Problem\":\n",
        "                    print(\"----------Transportation-----------\")\n",
        "                    output = get_TP_response(query,dataset_address)\n",
        "                    output_model.append(output)\n",
        "                    code_response = get_code(output,selected_problem)\n",
        "                    output_code.append(code_response)    \n",
        "    \n",
        "                elif selected_problem == \"Facility Location Problem\" or selected_problem == \"FLP\" or selected_problem == \"Uncapacited Facility Location\" or selected_problem == \"UFLP\":\n",
        "                    print(\"----------Facility Location Problem-----------\")\n",
        "                    output = get_FLP_response(query,dataset_address)\n",
        "                    output_model.append(output)\n",
        "                    code_response = get_code(output,selected_problem)\n",
        "                    output_code.append(code_response)\n",
        "                \n",
        "                elif selected_problem == \"Assignment Problem\" or selected_problem == \"AP\":\n",
        "                    print(\"----------Assignment Problem-----------\")\n",
        "                    output = get_AP_response(query,dataset_address)\n",
        "                    output_model.append(output)\n",
        "                    code_response = get_code(output,selected_problem)\n",
        "                    output_code.append(code_response)\n",
        "                else:\n",
        "                    print(\"----------Others with CSV-----------\")\n",
        "                    output = get_Others_response(query,dataset_address)\n",
        "                    output_model.append(output)\n",
        "                    code_response = get_code(output,selected_problem)\n",
        "                    output_code.append(code_response)\n",
        "    \n",
        "            else:\n",
        "                print(\"----------Others without CSV-----------\")\n",
        "                output = get_others_without_CSV_response(query)\n",
        "                output_model.append(output)\n",
        "                code_response = get_code(output,selected_problem)\n",
        "                output_code.append(code_response)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Connection error: {e}\")\n",
        "            continue\n",
        "        time.sleep(15)\n",
        "    return output_model, output_code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_and_combine_csvs(file_order):\n",
        "    dfs = []\n",
        "    for fname in file_order:\n",
        "        if os.path.exists(fname):\n",
        "            df = pd.read_csv(fname)\n",
        "            dfs.append(df)\n",
        "            print(f\"Read file: {fname} (Row length: {len(df)})\")\n",
        "        else:\n",
        "            print(f\"File doesn't exist: {fname}, already skipped\")\n",
        "    \n",
        "    if not dfs:\n",
        "        raise ValueError(\"No effective files\")\n",
        "    \n",
        "    return pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "def run_gurobi_code(code_str):\n",
        " \n",
        "    try:\n",
        "      \n",
        "        with StringIO() as buf, contextlib.redirect_stdout(buf), contextlib.redirect_stderr(buf):\n",
        "            env = {\n",
        "                '__builtins__': __builtins__,\n",
        "                'gp': gp,\n",
        "                'GRB': GRB\n",
        "            }\n",
        "            \n",
        "           \n",
        "            code_str += \"\\n\\n# Added by executor\\n\"\n",
        "            code_str += \"if hasattr(m, 'status') and m.status == GRB.OPTIMAL:\\n\"\n",
        "            code_str += \"    __result__ = m.ObjVal\\n\"\n",
        "            code_str += \"else:\\n\"\n",
        "            code_str += \"    __result__ = None\\n\"\n",
        "            \n",
        "            \n",
        "            exec(code_str, env)\n",
        "            result = env.get('__result__', None)\n",
        "            \n",
        "     \n",
        "            if 'm' in env:\n",
        "                env['m'].dispose()\n",
        "                del env['m']\n",
        "            \n",
        "            return result\n",
        "    except Exception as e:\n",
        "        print(f\"Execution error: {str(e)}\")\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Large Scale OR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test NRM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testnrm = pd.read_csv('Test_Dataset/Large-scale-or/final_large_scale_OR_New.csv')\n",
        "testnrm_1 = testnrm[9:18]\n",
        "testnrm_2 = testnrm[18:26]\n",
        "testnrm_3 = testnrm[26:34]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "scrolled": true
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output_model_nrm1, output_code_nrm1 \u001b[38;5;241m=\u001b[39m \u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestnrm_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mclassification_agent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m output_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuery\u001b[39m\u001b[38;5;124m'\u001b[39m: testnrm_1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuery\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_output\u001b[39m\u001b[38;5;124m'\u001b[39m:output_model_nrm1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode_output\u001b[39m\u001b[38;5;124m'\u001b[39m:output_code_nrm1})\n\u001b[1;32m      3\u001b[0m output_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrm1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "Cell \u001b[0;32mIn[12], line 23\u001b[0m, in \u001b[0;36mrun_test\u001b[0;34m(test, agent)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selected_problem \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNetwork Revenue Management\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m selected_problem \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNRM\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m selected_problem \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNetwork Revenue Management Problem\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----------Network Revenue Management-----------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mget_NRM_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataset_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     output_model\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     25\u001b[0m     code_response \u001b[38;5;241m=\u001b[39m get_code(output,selected_problem)\n",
            "Cell \u001b[0;32mIn[4], line 156\u001b[0m, in \u001b[0;36mget_NRM_response\u001b[0;34m(query, dataset_address)\u001b[0m\n\u001b[1;32m    137\u001b[0m suffix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    138\u001b[0m \n\u001b[1;32m    139\u001b[0m \u001b[38;5;124mBegin!\u001b[39m\n\u001b[1;32m    140\u001b[0m \n\u001b[1;32m    141\u001b[0m \u001b[38;5;124mUser Description: \u001b[39m\u001b[38;5;132;01m{input}\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;132;01m{agent_scratchpad}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    144\u001b[0m agent2 \u001b[38;5;241m=\u001b[39m initialize_agent(\n\u001b[1;32m    145\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[qa_tool],\n\u001b[1;32m    146\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm2,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     handle_parsing_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    154\u001b[0m )\n\u001b[0;32m--> 156\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain/chains/base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain/chains/base.py:157\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 157\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain/agents/agent.py:1620\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1620\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1628\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1629\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1630\u001b[0m         )\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain/agents/agent.py:1326\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1319\u001b[0m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1326\u001b[0m         [\n\u001b[1;32m   1327\u001b[0m             a\n\u001b[1;32m   1328\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1329\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1330\u001b[0m                 color_mapping,\n\u001b[1;32m   1331\u001b[0m                 inputs,\n\u001b[1;32m   1332\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1333\u001b[0m                 run_manager,\n\u001b[1;32m   1334\u001b[0m             )\n\u001b[1;32m   1335\u001b[0m         ]\n\u001b[1;32m   1336\u001b[0m     )\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain/agents/agent.py:1326\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1319\u001b[0m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1326\u001b[0m         [\n\u001b[1;32m   1327\u001b[0m             a\n\u001b[1;32m   1328\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1329\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1330\u001b[0m                 color_mapping,\n\u001b[1;32m   1331\u001b[0m                 inputs,\n\u001b[1;32m   1332\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1333\u001b[0m                 run_manager,\n\u001b[1;32m   1334\u001b[0m             )\n\u001b[1;32m   1335\u001b[0m         ]\n\u001b[1;32m   1336\u001b[0m     )\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain/agents/agent.py:1411\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[0;32m-> 1411\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\n\u001b[1;32m   1413\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain/agents/agent.py:1433\u001b[0m, in \u001b[0;36mAgentExecutor._perform_agent_action\u001b[0;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[1;32m   1431\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1432\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[0;32m-> 1433\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_run_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1441\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_agent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain_core/tools/base.py:774\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[1;32m    773\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[1;32m    775\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[1;32m    776\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain_core/tools/base.py:743\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[0;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[1;32m    742\u001b[0m         tool_kwargs \u001b[38;5;241m=\u001b[39m tool_kwargs \u001b[38;5;241m|\u001b[39m {config_param: config}\n\u001b[0;32m--> 743\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain_core/tools/simple.py:105\u001b[0m, in \u001b[0;36mTool._run\u001b[0;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m    104\u001b[0m         kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync invocation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
            "Cell \u001b[0;32mIn[4], line 120\u001b[0m, in \u001b[0;36mget_NRM_response.<locals>.qa_wrapper\u001b[0;34m(query)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mqa_wrapper\u001b[39m(query: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mqa_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py:5430\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5423\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m   5424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5425\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5428\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5429\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5431\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5432\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5433\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5434\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py:3047\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3045\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3046\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3047\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3048\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3049\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain_core/runnables/passthrough.py:511\u001b[0m, in \u001b[0;36mRunnableAssign.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    510\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m--> 511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py:1940\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[1;32m   1937\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m   1938\u001b[0m         output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m-> 1940\u001b[0m             \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1942\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[43m                \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1944\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1945\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1947\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1948\u001b[0m         )\n\u001b[1;32m   1949\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1950\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain_core/runnables/config.py:428\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    427\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain_core/runnables/passthrough.py:497\u001b[0m, in \u001b[0;36mRunnableAssign._invoke\u001b[0;34m(self, value, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe input to RunnablePassthrough.assign() must be a dict.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)  \u001b[38;5;66;03m# noqa: TRY004\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalue,\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    502\u001b[0m }\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py:3774\u001b[0m, in \u001b[0;36mRunnableParallel.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3770\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3771\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[1;32m   3772\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3773\u001b[0m         ]\n\u001b[0;32m-> 3774\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: future\u001b[38;5;241m.\u001b[39mresult() \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3775\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3776\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py:3774\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m get_executor_for_config(config) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m   3770\u001b[0m         futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   3771\u001b[0m             executor\u001b[38;5;241m.\u001b[39msubmit(_invoke_step, step, \u001b[38;5;28minput\u001b[39m, config, key)\n\u001b[1;32m   3772\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key, step \u001b[38;5;129;01min\u001b[39;00m steps\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   3773\u001b[0m         ]\n\u001b[0;32m-> 3774\u001b[0m         output \u001b[38;5;241m=\u001b[39m {key: \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, future \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(steps, futures)}\n\u001b[1;32m   3775\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3776\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
            "File \u001b[0;32m~/miniforge3/envs/test_agent/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "output_model_nrm1, output_code_nrm1 = run_test(testnrm_1,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': testnrm_1['Query'], 'model_output':output_model_nrm1, 'code_output':output_code_nrm1})\n",
        "output_df.to_csv(\"nrm1.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "output_model_nrm2, output_code_nrm2 = run_test(testnrm_2,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': testnrm_2['Query'], 'model_output':output_model_nrm2, 'code_output':output_code_nrm2})\n",
        "output_df.to_csv(\"nrm2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "output_model_nrm3, output_code_nrm3 = run_test(testnrm_3,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': testnrm_3['Query'], 'model_output':output_model_nrm3, 'code_output':output_code_nrm3})\n",
        "output_df.to_csv(\"nrm3.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_order=[\n",
        "    \"nrm1.csv\",\n",
        "    \"nrm2.csv\",\n",
        "    \"nrm3.csv\"\n",
        "]\n",
        "try:\n",
        "    combined_df = read_and_combine_csvs(file_order)\n",
        "    print(f\"Total rows: {len(combined_df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"File processing failed: {str(e)}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "print(\"\\n Running Gurobi Code...\")\n",
        "results = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i, row in combined_df.iterrows():\n",
        "    code = row['code_output']\n",
        "    code = re.sub(r'^```python|```$', '', code, flags=re.IGNORECASE).strip()\n",
        "    \n",
        "    print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
        "    result = run_gurobi_code(code)\n",
        "    results.append(result)\n",
        "\n",
        "combined_df['objective_value'] = results\n",
        "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
        "print(f\"Success: {len([x for x in results if x is not None])}/{len(results)}\")\n",
        "\n",
        "output_file = \"nrm_result.csv\"\n",
        "combined_df.to_csv(output_file, index=False)\n",
        "print(f\"Output saved to: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test RA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "testra = pd.read_csv('Test_Dataset/Large-scale-or/final_large_scale_OR_New.csv')\n",
        "testra_1 = testra[34:42]\n",
        "testra_2 = testra[42:50]\n",
        "testra_3 = testra[50:57]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_ra1, output_code_ra1 = run_test(testra_1,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': testra_1['Query'], 'model_output':output_model_ra1, 'code_output':output_code_ra1})\n",
        "output_df.to_csv(\"ra1.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "output_model_ra2, output_code_ra2 = run_test(testra_2,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': testra_2['Query'], 'model_output':output_model_ra2, 'code_output':output_code_ra2})\n",
        "output_df.to_csv(\"ra2.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "output_model_ra3, output_code_ra3 = run_test(testra_3,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': testra_3['Query'], 'model_output':output_model_ra3, 'code_output':output_code_ra3})\n",
        "output_df.to_csv(\"ra3.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_order=[\n",
        "    \"ra1.csv\",\n",
        "    \"ra2.csv\",\n",
        "    \"ra3.csv\"\n",
        "]\n",
        "try:\n",
        "    combined_df = read_and_combine_csvs(file_order)\n",
        "    print(f\"Total rows: {len(combined_df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"File processing failed: {str(e)}\")\n",
        "    sys.exit(1)\n",
        "    \n",
        "print(\"\\n Running Gurobi Code...\")\n",
        "results = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i, row in combined_df.iterrows():\n",
        "    code = row['code_output']\n",
        "    code = re.sub(r'^```python|```$', '', code, flags=re.IGNORECASE).strip()\n",
        "    \n",
        "    print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
        "    result = run_gurobi_code(code)\n",
        "    results.append(result)\n",
        "\n",
        "combined_df['objective_value'] = results\n",
        "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
        "print(f\"Success: {len([x for x in results if x is not None])}/{len(results)}\")\n",
        "\n",
        "output_file = \"ra_result.csv\"\n",
        "combined_df.to_csv(output_file, index=False)\n",
        "print(f\"Output saved to: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test TP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "testtp = pd.read_csv('Test_Dataset/Large-scale-or/final_large_scale_OR_New.csv')\n",
        "testtp = testtp[:9]\n",
        "testtp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_tp, output_code_tp = run_test(testtp,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': testtp['Query'], 'model_output':output_model_tp, 'code_output':output_code_tp})\n",
        "output_df.to_csv(\"tp.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_order=[\n",
        "    \"tp.csv\",\n",
        "]\n",
        "try:\n",
        "    combined_df = read_and_combine_csvs(file_order)\n",
        "    print(f\"Total rows: {len(combined_df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"File processing failed: {str(e)}\")\n",
        "    sys.exit(1)\n",
        "    \n",
        "print(\"\\n Running Gurobi Code...\")\n",
        "results = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i, row in combined_df.iterrows():\n",
        "    code = row['code_output']\n",
        "    code = re.sub(r'^```python|```$', '', code, flags=re.IGNORECASE).strip()\n",
        "    \n",
        "    print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
        "    result = run_gurobi_code(code)\n",
        "    results.append(result)\n",
        "\n",
        "combined_df['objective_value'] = results\n",
        "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
        "print(f\"Success: {len([x for x in results if x is not None])}/{len(results)}\")\n",
        "\n",
        "output_file = \"tp_result.csv\"\n",
        "combined_df.to_csv(output_file, index=False)\n",
        "print(f\"Output saved to: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test AP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testap = pd.read_csv('Test_Dataset/Large-scale-or/final_large_scale_OR_New.csv')\n",
        "testap = testap[66:]\n",
        "testap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "output_model_ap, output_code_ap = run_test(testap,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': testap['Query'], 'model_output':output_model_ap, 'code_output':output_code_ap})\n",
        "output_df.to_csv(\"ap.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_order=[\n",
        "    \"ap.csv\",\n",
        "]\n",
        "try:\n",
        "    combined_df = read_and_combine_csvs(file_order)\n",
        "    print(f\"Total rows: {len(combined_df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"File processing failed: {str(e)}\")\n",
        "    sys.exit(1)\n",
        "    \n",
        "print(\"\\n Running Gurobi Code...\")\n",
        "results = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i, row in combined_df.iterrows():\n",
        "    code = row['code_output']\n",
        "    code = re.sub(r'^```python|```$', '', code, flags=re.IGNORECASE).strip()\n",
        "    \n",
        "    print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
        "    result = run_gurobi_code(code)\n",
        "    results.append(result)\n",
        "\n",
        "combined_df['objective_value'] = results\n",
        "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
        "print(f\"Success: {len([x for x in results if x is not None])}/{len(results)}\")\n",
        "\n",
        "output_file = \"ap_result.csv\"\n",
        "combined_df.to_csv(output_file, index=False)\n",
        "print(f\"Output saved to: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test FLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testflp = pd.read_csv('Test_Dataset/Large-scale-or/final_large_scale_OR_New.csv')\n",
        "testflp = testflp[57:66]\n",
        "testflp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "output_model_flp, output_code_flp = run_test(testflp,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': testflp['Query'], 'model_output':output_model_flp, 'code_output':output_code_flp})\n",
        "output_df.to_csv(\"flp.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "file_order=[\n",
        "    \"flp.csv\",\n",
        "]\n",
        "try:\n",
        "    combined_df = read_and_combine_csvs(file_order)\n",
        "    print(f\"Total rows: {len(combined_df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"File processing failed: {str(e)}\")\n",
        "    sys.exit(1)\n",
        "    \n",
        "print(\"\\n Running Gurobi Code...\")\n",
        "results = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i, row in combined_df.iterrows():\n",
        "    code = row['code_output']\n",
        "    code = re.sub(r'^```python|```$', '', code, flags=re.IGNORECASE).strip()\n",
        "    \n",
        "    print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
        "    result = run_gurobi_code(code)\n",
        "    results.append(result)\n",
        "\n",
        "combined_df['objective_value'] = results\n",
        "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
        "print(f\"Success: {len([x for x in results if x is not None])}/{len(results)}\")\n",
        "\n",
        "output_file = \"flp_result.csv\"\n",
        "combined_df.to_csv(output_file, index=False)\n",
        "print(f\"Output saved to: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Small-Scale Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test NL4OPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "test_nl4opt = pd.read_csv('Test_Dataset/Small-scale/NL4OPT.csv')\n",
        "test_nl4opt1=test_nl4opt[:30]\n",
        "test_nl4opt2=test_nl4opt[30:60]\n",
        "test_nl4opt3=test_nl4opt[60:90]\n",
        "test_nl4opt4=test_nl4opt[90:120]\n",
        "test_nl4opt5=test_nl4opt[120:150]\n",
        "test_nl4opt6=test_nl4opt[150:180]\n",
        "test_nl4opt7=test_nl4opt[180:210]\n",
        "test_nl4opt8=test_nl4opt[210:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_nl4opt1, output_code_nl4opt1 = run_test(test_nl4opt1,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_nl4opt1['Query'], 'model_output':output_model_nl4opt1, 'code_output':output_code_nl4opt1})\n",
        "output_df.to_csv(\"NL4OPT_1-30.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        }
      },
      "outputs": [],
      "source": [
        "output_model_nl4opt2, output_code_nl4opt2 = run_test(test_nl4opt2,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_nl4opt2['Query'], 'model_output':output_model_nl4opt2, 'code_output':output_code_nl4opt2})\n",
        "output_df.to_csv(\"NL4OPT_31-60.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_nl4opt3, output_code_nl4opt3 = run_test(test_nl4opt3,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_nl4opt3['Query'], 'model_output':output_model_nl4opt3, 'code_output':output_code_nl4opt3})\n",
        "output_df.to_csv(\"NL4OPT_61-90.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_nl4opt4, output_code_nl4opt4 = run_test(test_nl4opt4,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_nl4opt4['Query'], 'model_output':output_model_nl4opt4, 'code_output':output_code_nl4opt4})\n",
        "output_df.to_csv(\"NL4OPT_91-120.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_nl4opt5, output_code_nl4opt5 = run_test(test_nl4opt5,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_nl4opt5['Query'], 'model_output':output_model_nl4opt5, 'code_output':output_code_nl4opt5})\n",
        "output_df.to_csv(\"NL4OPT_121-150.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_nl4opt6, output_code_nl4opt6 = run_test(test_nl4opt6,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_nl4opt6['Query'], 'model_output':output_model_nl4opt6, 'code_output':output_code_nl4opt6})\n",
        "output_df.to_csv(\"NL4OPT_151-180.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_nl4opt7, output_code_nl4opt7 = run_test(test_nl4opt7,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_nl4opt7['Query'], 'model_output':output_model_nl4opt7, 'code_output':output_code_nl4opt7})\n",
        "output_df.to_csv(\"NL4OPT_181-210.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_nl4opt8, output_code_nl4opt8 = run_test(test_nl4opt8,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_nl4opt8['Query'], 'model_output':output_model_nl4opt8, 'code_output':output_code_nl4opt8})\n",
        "output_df.to_csv(\"NL4OPT_211-245.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_order=[\n",
        "    \"NL4OPT_1-30.csv\",\n",
        "    \"NL4OPT_31-60.csv\",\n",
        "    \"NL4OPT_61-90.csv\",\n",
        "    \"NL4OPT_91-120.csv\",\n",
        "    \"NL4OPT_121-150.csv\",\n",
        "    \"NL4OPT_151-180.csv\",\n",
        "    \"NL4OPT_181-210.csv\",\n",
        "    \"NL4OPT_211-245.csv\",\n",
        "]\n",
        "try:\n",
        "    combined_df = read_and_combine_csvs(file_order)\n",
        "    print(f\"Total rows: {len(combined_df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"File processing failed: {str(e)}\")\n",
        "    sys.exit(1)\n",
        "    \n",
        "print(\"\\n Running Gurobi Code...\")\n",
        "results = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i, row in combined_df.iterrows():\n",
        "    code = row['code_output']\n",
        "    code = re.sub(r'^```python|```$', '', code, flags=re.IGNORECASE).strip()\n",
        "    \n",
        "    print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
        "    result = run_gurobi_code(code)\n",
        "    results.append(result)\n",
        "\n",
        "# Add results column\n",
        "combined_df['objective_value'] = results\n",
        "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
        "print(f\"Success: {len([x for x in results if x is not None])}/{len(results)}\")\n",
        "\n",
        "# Step 3: Save results\n",
        "output_file = \"NL4OPT_result.csv\"\n",
        "combined_df.to_csv(output_file, index=False)\n",
        "print(f\"Output saved to: {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test IndustryOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_industryOR = pd.read_csv('Test_Dataset/Small-scale/IndustryOR.csv', encoding='gbk')\n",
        "test_industryOR1=test_industryOR[:25]\n",
        "test_industryOR2=test_industryOR[25:50]\n",
        "test_industryOR3=test_industryOR[50:75]\n",
        "test_industryOR4=test_industryOR[75:]\n",
        "test_industryOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_industryOR1, output_code_industryOR1 = run_test(test_industryOR1,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_industryOR1['Query'], 'model_output':output_model_industryOR1, 'code_output':output_code_industryOR1})\n",
        "output_df.to_csv(\"IndustryOR_1-25.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_industryOR2, output_code_industryOR2 = run_test(test_industryOR2,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_industryOR2['Query'], 'model_output':output_model_industryOR2, 'code_output':output_code_industryOR2})\n",
        "output_df.to_csv(\"IndustryOR_26-50.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_industryOR3, output_code_industryOR3 = run_test(test_industryOR3,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_industryOR3['Query'], 'model_output':output_model_industryOR3, 'code_output':output_code_industryOR3})\n",
        "output_df.to_csv(\"IndustryOR_51-75.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output_model_industryOR4, output_code_industryOR4 = run_test(test_industryOR4,classification_agent)\n",
        "output_df = pd.DataFrame({'Query': test_industryOR4['Query'], 'model_output':output_model_industryOR4, 'code_output':output_code_industryOR4})\n",
        "output_df.to_csv(\"IndustryOR_76-100.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_order=[\n",
        "    \"IndustryOR_1-25.csv\",\n",
        "    \"IndustryOR_26-50.csv\",\n",
        "    \"IndustryOR_51-75.csv\",\n",
        "    \"IndustryOR_76-100.csv\",\n",
        "]\n",
        "try:\n",
        "    combined_df = read_and_combine_csvs(file_order)\n",
        "    print(f\"Total rows: {len(combined_df)}\")\n",
        "except Exception as e:\n",
        "    print(f\"File processing failed: {str(e)}\")\n",
        "    sys.exit(1)\n",
        "    \n",
        "print(\"\\n Running Gurobi Code...\")\n",
        "results = []\n",
        "start_time = time.time()\n",
        "\n",
        "for i, row in combined_df.iterrows():\n",
        "    code = row['code_output']\n",
        "    code = re.sub(r'^```python|```$', '', code, flags=re.IGNORECASE).strip()\n",
        "    \n",
        "    print(f\"Processing row {i+1}/{len(combined_df)}...\", end='\\r')\n",
        "    result = run_gurobi_code(code)\n",
        "    results.append(result)\n",
        "\n",
        "combined_df['objective_value'] = results\n",
        "print(f\"\\nCode execution completed! Time used: {time.time()-start_time:.2f} seconds\")\n",
        "print(f\"Success: {len([x for x in results if x is not None])}/{len(results)}\")\n",
        "\n",
        "output_file = \"IndustryOR_result.csv\"\n",
        "combined_df.to_csv(output_file, index=False)\n",
        "print(f\"Output saved to: {output_file}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "test_agent",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
